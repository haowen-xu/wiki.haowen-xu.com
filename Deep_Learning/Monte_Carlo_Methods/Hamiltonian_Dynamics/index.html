<!DOCTYPE html><html lang="en"><head><meta name="generator" content="Hexo 3.9.0"><meta charset="utf-8"><title>Hamiltonian Dynamics | My Research Wiki</title><meta name="keywords" content="Hamiltonian Dynamics"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=1"><meta name="description" content="Problem StatementTo sample from \(\pi(q)\), where \(\pi(q)\) is not easy to sample from, but given a sample \(q\), the density of \(\pi(q)\) is easy to evaluate, or at least the unnormalized density \"><meta property="og:type" content="article"><meta property="og:title" content="Hamiltonian Dynamics"><meta property="og:url" content="https://wiki.haowen-xu.com/Deep_Learning/Monte_Carlo_Methods/Hamiltonian_Dynamics/index.html"><meta property="og:site_name" content="My Research Wiki"><meta property="og:description" content="Problem StatementTo sample from \(\pi(q)\), where \(\pi(q)\) is not easy to sample from, but given a sample \(q\), the density of \(\pi(q)\) is easy to evaluate, or at least the unnormalized density \"><meta property="og:locale" content="en"><meta property="og:updated_time" content="2020-06-01T12:15:59.008Z"><meta name="twitter:card" content="summary"><meta name="twitter:title" content="Hamiltonian Dynamics"><meta name="twitter:description" content="Problem StatementTo sample from \(\pi(q)\), where \(\pi(q)\) is not easy to sample from, but given a sample \(q\), the density of \(\pi(q)\) is easy to evaluate, or at least the unnormalized density \"><link rel="alternate" href="/atom.xml" title="My Research Wiki" type="application/atom+xml"><link rel="icon" href="/favicon.ico"><link rel="stylesheet" href="/libs/font-awesome/css/font-awesome.min.css"><link rel="stylesheet" href="/libs/open-sans/styles.css"><link rel="stylesheet" href="/libs/source-code-pro/styles.css"><link rel="stylesheet" href="/css/style.css"><script src="/libs/jquery/2.1.3/jquery.min.js"></script><script src="/libs/jquery/plugins/cookie/1.4.1/jquery.cookie.js"></script><link rel="stylesheet" href="/libs/lightgallery/css/lightgallery.min.css"><link rel="stylesheet" href="/libs/justified-gallery/justifiedGallery.min.css"></head></html><body><div id="container"><header id="header"><div id="header-main" class="header-inner"><div class="outer"><a href="/" id="logo"><i class="logo"></i> <span class="site-title">My Research Wiki</span></a><nav id="main-nav"><a class="main-nav-link" href="/">Home</a> <a class="main-nav-link" href="/archives">Archives</a> <a class="main-nav-link" href="/categories">Categories</a></nav><div id="search-form-wrap"><form class="search-form"><input type="text" class="ins-search-input search-form-input" placeholder="Search"> <button type="submit" class="search-form-submit"></button></form><div class="ins-search"><div class="ins-search-mask"></div><div class="ins-search-container"><div class="ins-input-wrapper"><input type="text" class="ins-search-input" placeholder="Type something..."> <span class="ins-close ins-selectable"><i class="fa fa-times-circle"></i></span></div><div class="ins-section-wrapper"><div class="ins-section-container"></div></div></div></div><script>window.INSIGHT_CONFIG={TRANSLATION:{POSTS:"Posts",PAGES:"Pages",CATEGORIES:"Categories",TAGS:"Tags",UNTITLED:"(Untitled)"},ROOT_URL:"/",CONTENT_URL:"/content.json"}</script><script src="/js/insight.js"></script></div></div></div><div id="main-nav-mobile" class="header-sub header-inner"><table class="menu outer"><tr><td><a class="main-nav-link" href="/">Home</a></td><td><a class="main-nav-link" href="/archives">Archives</a></td><td><a class="main-nav-link" href="/categories">Categories</a></td><td><div class="search-form"><input type="text" class="ins-search-input search-form-input" placeholder="Search"></div></td></tr></table></div></header><div class="outer"><aside id="sidebar"><div class="widget-wrap" id="categories"><h3 class="widget-title"><span>categories</span> &nbsp; <a id="allExpand" href="#"><i class="fa fa-angle-double-down fa-2x"></i></a></h3><ul class="unstyled" id="tree"><li class="directory open"><a href="#" data-role="directory"><i class="fa fa-folder-open"></i> &nbsp; Deep Learning</a><ul class="unstyled" id="tree"><li class="directory"><a href="#" data-role="directory"><i class="fa fa-folder"></i> &nbsp; CV</a><ul class="unstyled" id="tree"><li class="file"><a href="/Deep_Learning/CV/Image_Segmentation/">Image Segmentation</a></li></ul></li><li class="directory"><a href="#" data-role="directory"><i class="fa fa-folder"></i> &nbsp; Confronting Partition Function</a><ul class="unstyled" id="tree"><li class="file"><a href="/Deep_Learning/Confronting_Partition_Function/Overview/">Overview</a></li><li class="file"><a href="/Deep_Learning/Confronting_Partition_Function/Contrastive_Divergence/">Contrastive Divergence</a></li><li class="file"><a href="/Deep_Learning/Confronting_Partition_Function/Score_Matching/">Score Matching</a></li><li class="file"><a href="/Deep_Learning/Confronting_Partition_Function/Softmax_Speedup/">Softmax Speedup</a></li></ul></li><li class="directory"><a href="#" data-role="directory"><i class="fa fa-folder"></i> &nbsp; Energy Based Models</a><ul class="unstyled" id="tree"><li class="file"><a href="/Deep_Learning/Energy_Based_Models/Overview/">Overview</a></li><li class="file"><a href="/Deep_Learning/Energy_Based_Models/Energy_Function_in_Probabilistic_Models/">Energy Function in Probabilistic Models</a></li><li class="file"><a href="/Deep_Learning/Energy_Based_Models/Restricted_Boltzmann_Machine/">Restricted Boltzmann Machine</a></li></ul></li><li class="directory"><a href="#" data-role="directory"><i class="fa fa-folder"></i> &nbsp; Evaluation</a><ul class="unstyled" id="tree"><li class="file"><a href="/Deep_Learning/Evaluation/Evaluation_Metrics/">Evaluation Metrics</a></li><li class="file"><a href="/Deep_Learning/Evaluation/Visualizing_High_Dimensional_Space/">Visualizing High Dimensional Space</a></li></ul></li><li class="directory"><a href="#" data-role="directory"><i class="fa fa-folder"></i> &nbsp; Generative Adversarial Nets</a><ul class="unstyled" id="tree"><li class="file"><a href="/Deep_Learning/Generative_Adversarial_Nets/Overview/">Overview</a></li><li class="file"><a href="/Deep_Learning/Generative_Adversarial_Nets/f-GAN/">f-GAN</a></li><li class="file"><a href="/Deep_Learning/Generative_Adversarial_Nets/Energy_GAN/">Energy GAN</a></li></ul></li><li class="directory"><a href="#" data-role="directory"><i class="fa fa-folder"></i> &nbsp; Graph Neural Networks</a><ul class="unstyled" id="tree"><li class="file"><a href="/Deep_Learning/Graph_Neural_Networks/Node_Embedding/">Node Embedding</a></li><li class="file"><a href="/Deep_Learning/Graph_Neural_Networks/Graph_Convolution_Network/">Graph Convolution Network</a></li><li class="file"><a href="/Deep_Learning/Graph_Neural_Networks/Graph_Auto_Encoder/">Graph Auto-Encoder</a></li></ul></li><li class="directory"><a href="#" data-role="directory"><i class="fa fa-folder"></i> &nbsp; Information Theoretical</a><ul class="unstyled" id="tree"><li class="file"><a href="/Deep_Learning/Information_Theoretical/KL-Divergence/">KL-Divergence</a></li><li class="file"><a href="/Deep_Learning/Information_Theoretical/Mutual_Information/">Mutual Information</a></li></ul></li><li class="directory open"><a href="#" data-role="directory"><i class="fa fa-folder-open"></i> &nbsp; Monte Carlo Methods</a><ul class="unstyled" id="tree"><li class="file"><a href="/Deep_Learning/Monte_Carlo_Methods/Overview/">Overview</a></li><li class="file"><a href="/Deep_Learning/Monte_Carlo_Methods/Monte_Carlo_Integration/">Monte Carlo Integration</a></li><li class="file"><a href="/Deep_Learning/Monte_Carlo_Methods/Accept_Reject_Sampling/">Accept-Reject Sampling</a></li><li class="file"><a href="/Deep_Learning/Monte_Carlo_Methods/Markov_Chain/">Markov Chain</a></li><li class="file"><a href="/Deep_Learning/Monte_Carlo_Methods/Metropolis_Hastings_Algorithm/">Metropolis-Hastings Algorithm</a></li><li class="file"><a href="/Deep_Learning/Monte_Carlo_Methods/Gibbs_Sampler/">Gibbs Sampler</a></li><li class="file active"><a href="/Deep_Learning/Monte_Carlo_Methods/Hamiltonian_Dynamics/">Hamiltonian Dynamics</a></li><li class="file"><a href="/Deep_Learning/Monte_Carlo_Methods/Langevin_Dynamics/">Langevin Dynamics</a></li></ul></li><li class="directory"><a href="#" data-role="directory"><i class="fa fa-folder"></i> &nbsp; Optimization</a><ul class="unstyled" id="tree"><li class="file"><a href="/Deep_Learning/Optimization/Gradient_Tricks/">Gradient Tricks</a></li><li class="file"><a href="/Deep_Learning/Optimization/Loss_Surface_and_Generalization/">Loss Surface and Generalization</a></li><li class="file"><a href="/Deep_Learning/Optimization/Stochastic_Gradient_Descent/">Stochastic Gradient descent</a></li></ul></li><li class="directory"><a href="#" data-role="directory"><i class="fa fa-folder"></i> &nbsp; Variational Autoencoder</a><ul class="unstyled" id="tree"><li class="file"><a href="/Deep_Learning/Variational_Autoencoder/Overview/">Overview</a></li><li class="file"><a href="/Deep_Learning/Variational_Autoencoder/Sequential_VAE/">Sequential VAE</a></li><li class="file"><a href="/Deep_Learning/Variational_Autoencoder/Gradient_Estimators_for_Variational_Inference/">Gradient Estimators for Variational Inference</a></li><li class="file"><a href="/Deep_Learning/Variational_Autoencoder/Theoretical_Facts/">Theoretical Facts about VAEs</a></li></ul></li></ul></li><li class="directory"><a href="#" data-role="directory"><i class="fa fa-folder"></i> &nbsp; Mathematics</a><ul class="unstyled" id="tree"><li class="directory"><a href="#" data-role="directory"><i class="fa fa-folder"></i> &nbsp; Analysis</a><ul class="unstyled" id="tree"><li class="file"><a href="/Mathematics/Analysis/Linear_Space_vs_Functional_Space/">Linear space vs functional space</a></li></ul></li><li class="directory"><a href="#" data-role="directory"><i class="fa fa-folder"></i> &nbsp; Calculus</a><ul class="unstyled" id="tree"><li class="file"><a href="/Mathematics/Calculus/Calculus_of_Variations/">Calculus of Variations</a></li></ul></li><li class="directory"><a href="#" data-role="directory"><i class="fa fa-folder"></i> &nbsp; Differential Equations</a><ul class="unstyled" id="tree"><li class="file"><a href="/Mathematics/Differential_Equations/Probability_Distribution_Equations/">Differential Equations on Probability Distributions</a></li></ul></li><li class="directory"><a href="#" data-role="directory"><i class="fa fa-folder"></i> &nbsp; Optimization</a><ul class="unstyled" id="tree"><li class="file"><a href="/Mathematics/Optimization/Convex_Optimization/">Convex Optimization</a></li></ul></li></ul></li><li class="directory"><a href="#" data-role="directory"><i class="fa fa-folder"></i> &nbsp; Research Work</a><ul class="unstyled" id="tree"><li class="file"><a href="/Research_Work/Reading_List/">Reading List</a></li><li class="file"><a href="/Research_Work/Tracking_the_Concepts/">Tracking the Concepts</a></li><li class="file"><a href="/Research_Work/Directions_to_Explore/">Directions to Explore</a></li></ul></li></ul></div><script>$(document).ready(function(){var r="fa-folder-open",i="fa-folder",l="fa-angle-double-down",d="fa-angle-double-up";$(document).on("click",'#categories a[data-role="directory"]',function(a){a.preventDefault();var e=$(this).children(".fa"),s=e.hasClass(r),l=$(this).siblings("ul");e.removeClass(r).removeClass(i),s?(void 0!==l&&l.slideUp({duration:100}),e.addClass(i)):(void 0!==l&&l.slideDown({duration:100}),e.addClass(r))}),$('#categories a[data-role="directory"]').bind("contextmenu",function(a){a.preventDefault();var e=$(this).children(".fa"),s=e.hasClass(r),l=$(this).siblings("ul"),d=$.merge(l.find("li ul"),l),o=$.merge(l.find(".fa"),e);o.removeClass(r).removeClass(i),s?(d.slideUp({duration:100}),o.addClass(i)):(d.slideDown({duration:100}),o.addClass(r))}),$(document).on("click","#allExpand",function(a){a.preventDefault();var e=$(this).children(".fa"),s=e.hasClass(l);e.removeClass(l).removeClass(d),s?($("#sidebar .fa.fa-folder").removeClass("fa-folder").addClass("fa-folder-open"),$("#categories li ul").slideDown({duration:100}),e.addClass(d)):($("#sidebar .fa.fa-folder-open").removeClass("fa-folder-open").addClass("fa-folder"),$("#categories li ul").slideUp({duration:100}),e.addClass(l))})})</script><div id="toTop" class="fa fa-angle-up"></div></aside><section id="main"><article id="post-Deep_Learning/Monte_Carlo_Methods/Hamiltonian_Dynamics" class="article article-type-post" itemscope itemprop="blogPost"><div class="article-inner"><header class="article-header"><div class="article-meta"><div class="article-category"><i class="fa fa-folder"></i> <a class="article-category-link" href="/categories/Deep-Learning/">Deep Learning</a><i class="fa fa-angle-right"></i><a class="article-category-link" href="/categories/Deep-Learning/Monte-Carlo-Methods/">Monte Carlo Methods</a></div><div class="article-date"><i class="fa fa-calendar"></i> <a href="/Deep_Learning/Monte_Carlo_Methods/Hamiltonian_Dynamics/"><time datetime="2019-10-19T07:09:00.000Z" itemprop="datePublished">2019-10-19</time></a></div><div class="article-meta-button"><a href="https://github.com/haowen-xu/research-notes/raw/master/source/_posts/Deep_Learning/Monte_Carlo_Methods/Hamiltonian_Dynamics.md">Source</a></div><div class="article-meta-button"><a href="https://github.com/haowen-xu/research-notes/edit/master/source/_posts/Deep_Learning/Monte_Carlo_Methods/Hamiltonian_Dynamics.md">Edit</a></div><div class="article-meta-button"><a href="https://github.com/haowen-xu/research-notes/commits/master/source/_posts/Deep_Learning/Monte_Carlo_Methods/Hamiltonian_Dynamics.md">History</a></div></div><h1 class="article-title" itemprop="name">Hamiltonian Dynamics</h1></header><div class="article-entry" itemprop="articleBody"><h2 id="problem-statement">Problem Statement</h2><p>To sample from <span class="math inline">\(\pi(q)\)</span>, where <span class="math inline">\(\pi(q)\)</span> is not easy to sample from, but given a sample <span class="math inline">\(q\)</span>, the density of <span class="math inline">\(\pi(q)\)</span> is easy to evaluate, or at least the <em>unnormalized density</em> <span class="math inline">\(\tilde{\pi}(q)\)</span> is easy to calculate.</p><p><em>Note: as a convention of the Hamiltonian Monte Carlo method literature, the notations for vectors and matrices are not bold.</em></p><h2 id="hamiltonian-dynamics">Hamiltonian Dynamics</h2><h3 id="basic-elements">Basic Elements</h3><p>The Hamiltonian Monte Carlo method uses Hamiltonian dynamics system to derive the transition kernel <span class="math inline">\(T\)</span>. It auguments the state space <span class="math inline">\(q\)</span> with a momentum <span class="math inline">\(p\)</span>, forming the extended <em>phase space</em> <span class="math inline">\((q, p)\)</span>. A Hamiltonian system is then constructed for this phase space, with Hamiltonian function <span class="math inline">\(H(q,p)\)</span>, <em>i.e.</em>, the total energy of this system.</p><p>The density for the phase space, <span class="math inline">\(\pi(q,p)\)</span> is then given by: <span class="math display">\[ \begin{align} \pi(q, p) &amp;= \exp\left( -H(q,p) \right) \end{align} \]</span> satisfying <span class="math inline">\(\int \pi(q,p)\,dp = \pi(q)\)</span>.</p><p>Since <span class="math inline">\(H(q,p)\)</span> is the energy function of a Hamiltonian system, it can further be decomposed into kinetic and potential energies: <span class="math display">\[ \begin{align} H(q,p) &amp;= -\log \pi(q,p) \\ &amp;= -\log \pi(p|q) - \log \pi(q) \\ &amp;= K(p,q) + U(q) \end{align} \]</span> where <span class="math inline">\(K(p,q) = -\log \pi(p|q)\)</span> is the Kinetic energy, and <span class="math inline">\(U(q) = -\log \pi(q)\)</span> is the potential energy.</p><h3 id="transition-kernel">Transition Kernel</h3><p>The evolution of a Hamiltonian system over time is given by the following differential equations: <span class="math display">\[ \begin{align} \frac{d q}{dt} &amp;= \frac{\partial H}{\partial p} = \frac{\partial K}{\partial p} \\ \frac{d p}{dt} &amp;= -\frac{\partial H}{\partial q} = -\frac{\partial K}{\partial q} - \frac{\partial U}{\partial q} \end{align} \]</span> Let <span class="math inline">\(z=(q,p)\)</span>, the Hamiltonian equations can also be rewritten in the following form: <span class="math display">\[ \begin{align} \frac{dz}{\mathrm{d}t} = J \,\nabla H(z) \end{align} \]</span> where <span class="math inline">\(\nabla H\)</span> is the gradient of <span class="math inline">\(H\)</span>, and: <span class="math display">\[ J = \begin{bmatrix} 0 &amp; I \\ -I &amp; 0 \\ \end{bmatrix} \]</span></p><p>The transition kernel <span class="math inline">\(T\)</span> is then given by the following procedure:</p><ol type="1"><li>Lift <span class="math inline">\(q^{(t)}\)</span> to <span class="math inline">\((q^{(t)},p^{(t)})\)</span>, by sampling <span class="math inline">\(p^{(t)} \sim \pi(p|q^{(t)})\)</span>.</li><li>Simulate the Hamiltonian system, by integrating the Hamiltonian differential equations, to obtain candidate state <span class="math inline">\((q^*, p^*)\)</span>.</li><li>For reversibility, negate <span class="math inline">\(p^{\star}\)</span>, such that the candidate state becomes <span class="math inline">\((q^{\star},-p^{\star})\)</span> (see below).</li><li>To correct numerical errors, apply <a href="/Deep_Learning/Monte_Carlo_Methods/Metropolis_Hastings_Algorithm/">Metropolis-Hastings acceptance rate</a> on the candidate state <span class="math inline">\((q^{\star}, -p^{\star})\)</span>, to obtain the final state <span class="math inline">\((q^{(t+1)},p^{(t+1)})\)</span>.</li><li>Discard <span class="math inline">\(p^{(t+1)}\)</span> and use <span class="math inline">\(q^{(t+1)}\)</span> as the final sample of the Markov chain.</li></ol><h3 id="choices-for-kpq-or-equivalently-pipq">Choices for <span class="math inline">\(K(p,q)\)</span> (or equivalently, <span class="math inline">\(\pi(p|q)\)</span>)</h3><p><strong>1. Euclidean-Gaussian Kinetic Energy</strong></p><p>This is perhaps the most commonly used kinetic energy, given by:</p><p><span class="math display">\[ \begin{align} K(p|q) &amp;= \frac{1}{2} p^T M^{-1} p + \log \left| M \right| + \text{const} \\ \pi(p|q) &amp;\propto \exp\left( -\frac{1}{2} p^T M^{-1} p \right) \end{align} \]</span></p><p>Note <span class="math inline">\(\pi(p|q) = \mathcal{N}(p\,|\,0,M)\)</span> is a Gaussian distribution independent of <span class="math inline">\(q\)</span>.</p><p><strong>2. Riemannian-Gaussian Kinetic Energy</strong> <span class="math display">\[ \begin{align} K(p|q) &amp;= \frac{1}{2} \cdot p^T \cdot \Sigma^{-1}(q) \cdot p + \log \left| \Sigma(q) \right| + \text{const} \\ \pi(p|q) &amp;\propto \exp\left( -\frac{1}{2} p^T \cdot \Sigma(q)^{-1}\cdot p \right) \end{align} \]</span></p><p>Note <span class="math inline">\(\pi(p|q) = \mathcal{N}(p|0,\Sigma(q))\)</span> is a Gaussian distribution dependent of <span class="math inline">\(q\)</span>. Such dependence can reflect the local geometry of the target distribution, thus can be better than Euclidean-Gaussian Kinetic Energy.</p><h3 id="numerical-integrator-for-the-hamiltonian-equations">Numerical Integrator for the Hamiltonian Equations</h3><p>Numerical integrators are adopted to simulate a Hamiltonian dynamics system. Given the size of simulation time step (denoted as <span class="math inline">\(\epsilon\)</span>), and the total number of simulation steps to run (denoted as <span class="math inline">\(n\)</span>), a numerical integrator transforms an initial state <span class="math inline">\((q(t),p(t))\)</span> to <span class="math inline">\((q(t+n\epsilon), p(t+n\epsilon))\)</span>.</p><p>For simplicity, in this section, the initial state fed into the numerical integrator is denoted as <span class="math inline">\((q_0, p_0)\)</span> (which is <span class="math inline">\((q(t),p(t))\)</span>), while the transformed state after the <span class="math inline">\(k\)</span>-th simulation step is denoted as <span class="math inline">\((q_k, p_k)\)</span> (which is <span class="math inline">\((q(t+k\epsilon),p(t+k\epsilon))\)</span>).</p><p><strong>1. Euler's Method</strong></p><p>Each step of Euler's method is given by: <span class="math display">\[ \begin{align} p_{k+1} &amp;= p_k + \epsilon \cdot \frac{dp}{dt}(t + k\epsilon) = p_k - \epsilon\cdot\left[ \frac{\partial K}{\partial q}(p_k, q_k) + \frac{\partial U}{\partial q}(q_k) \right] \\ q_{k+1} &amp;= q_k + \epsilon \cdot \frac{dq}{dt}(t+k\epsilon) = q_k + \epsilon\cdot\frac{\partial K}{\partial p}(p_k,q_k) \end{align} \]</span></p><p>However, Euler's method is not <em>sympletic</em>, and is prone to divergence.</p><p><strong>2. LeapFrog Method</strong></p><p>When <span class="math inline">\(K(p,q)\)</span> is independent of <span class="math inline">\(q\)</span>, <em>i.e.</em>, <span class="math inline">\(K(p,q) = K(p)\)</span> and <span class="math inline">\(\pi(p|q) = \pi(p)\)</span>, LeapFrog method can be used, which is sympletic and better than Euler's method. We first state the Hamiltonian equations under this new assumption: <span class="math display">\[ \begin{align} \frac{d q}{dt} &amp;= \frac{\partial H(q,p)}{\partial p} = \frac{\partial K}{\partial p} \\ \frac{d p}{dt} &amp;= -\frac{\partial H}{\partial q} = -\frac{\partial U}{\partial q} \end{align} \]</span> Each step of the LeapFrog method is then given by: <span class="math display">\[ \begin{align} p_{k+0.5} &amp;= p_k + \frac{\epsilon}{2} \cdot \frac{dp}{dt}(t+k\epsilon) = p_k - \frac{\epsilon}{2} \cdot \frac{\partial U}{\partial q}(q_k) \\ q_{k+1} &amp;= q_k + \epsilon \cdot \frac{dq}{dt}(t+(k+0.5)\epsilon) = q_k + \epsilon \cdot \frac{\partial K}{\partial p}(p_{k+0.5}) \\ p_{k+1} &amp;= p_{k+0.5} + \frac{\epsilon}{2} \cdot \frac{dp}{dt}(t+\epsilon) = p_{k+0.5} - \frac{\epsilon}{2} \cdot \frac{\partial U}{\partial q}(q_{k+1}) \end{align} \]</span> Note in a practical implementation, when the desired number of steps <span class="math inline">\(n\)</span> is larger than 1, the intermediate states <span class="math inline">\(p_k\)</span> can be omitted, with only <span class="math inline">\(p_{k+0.5}\)</span> actually computed. The whole LeapFrog method with <span class="math inline">\(n\)</span> simulation steps can be given by:</p><ul><li><span class="math inline">\(p_{0.5} = p_0 - \frac{\epsilon}{2} \cdot \frac{\partial U}{\partial q}(q_0)\)</span></li><li>For each <span class="math inline">\(k = 0 \dots n - 2\)</span><ul><li><span class="math inline">\(q_{k+1} = q_k + \epsilon \cdot \frac{\partial K}{\partial p}(p_{k+0.5})\)</span></li><li><span class="math inline">\(p_{k+1.5} = p_{k+0.5} - \epsilon \cdot \frac{\partial U}{\partial q}(q_{k+1})\)</span></li></ul></li><li><span class="math inline">\(q_n = q_{n-1} + \epsilon \cdot \frac{\partial K}{\partial p}(p_{n-0.5})\)</span></li><li><span class="math inline">\(p_n = p_{n-0.5} - \frac{\epsilon}{2} \cdot \frac{\partial U}{\partial q}(q_n)\)</span></li></ul><h3 id="metropolis-hastings-acceptance-rate">Metropolis-Hastings Acceptance Rate</h3><p>After applying a <em>reversible</em> numerical integrator, such that the candidate <span class="math inline">\((q^{(t)},p^{(t)}) \to (q^{\star},-p^{\star})\)</span> has been proposed, <a href="/Deep_Learning/Monte_Carlo_Methods/Metropolis_Hastings_Algorithm/">Metropolis-Hastings acceptance rate</a> should be calculated, in order to determine whether or not to accept the new state. The rate is given by: <span class="math display">\[ \begin{align} \rho((q^{(t)}, p^{(t)}), (q^{\star}, -p^{\star})) &amp;= \min\left\{ 1, \frac{\pi(q^{\star},-p^{\star})}{\pi(q,p)} \frac{Q(q^{(t)},p^{(t)}|q^{\star},-p^{\star})}{Q(q^{\star},-p^{\star}|q^{(t)},p^{(t)})} \right\} \\ &amp;= \min\left\{ 1, \frac{\pi(q^{\star},-p^{\star})}{\pi(q,p)} \right\} \\ &amp;= \min\left\{ 1, \frac{\exp\left(-H(q^{\star},-p^{\star}) \right)}{\exp\left(-H(q^{(t)},p^{(t)}) \right)} \right\} \\ &amp;= \min\left\{ 1, \exp\left( H(q^{(t)},p^{(t)}) - H(q^{\star},-p^{\star}) \right) \right\} \end{align} \]</span></p><p>The proposal distribution <span class="math inline">\(Q(q^{(t)},p^{(t)}|q^{\star},-p^{\star}) \equiv 1\)</span> and <span class="math inline">\(Q(q^{\star},-p^{\star}|q^{(t)},p^{(t)}) \equiv 1\)</span>, since the integrator is reversible and deterministic.</p><h3 id="further-reading-materials">Further Reading Materials</h3><p>See <span class="citation" data-cites="betancourtConceptualIntroductionHamiltonian2017">Betancourt (<a href="#ref-betancourtConceptualIntroductionHamiltonian2017" role="doc-biblioref">2017</a>)</span>, <span class="citation" data-cites="nealMCMCUsingHamiltonian2011">Neal (<a href="#ref-nealMCMCUsingHamiltonian2011" role="doc-biblioref">2011</a>)</span>, <span class="citation" data-cites="carrollHamiltonianMonteCarlo2019">Carroll (<a href="#ref-carrollHamiltonianMonteCarlo2019" role="doc-biblioref">2019</a>)</span> and <span class="citation" data-cites="youngLeapfrogMethodOther">Young (<a href="#ref-youngLeapfrogMethodOther" role="doc-biblioref">n.d.</a>)</span>.</p><h1 id="bibliography" class="unnumbered">References</h1><div id="refs" class="references" role="doc-bibliography"><div id="ref-betancourtConceptualIntroductionHamiltonian2017"><p>Betancourt, Michael. 2017. “A Conceptual Introduction to Hamiltonian Monte Carlo.” <em>arXiv:1701.02434 [Stat]</em>, January. <a href="http://arxiv.org/abs/1701.02434" target="_blank" rel="noopener">http://arxiv.org/abs/1701.02434</a>.</p></div><div id="ref-carrollHamiltonianMonteCarlo2019"><p>Carroll, Colin. 2019. “Hamiltonian Monte Carlo from Scratch.” <em>Colin Carroll</em>. https://colindcarroll.com/2019/04/11/hamiltonian-monte-carlo-from-scratch/.</p></div><div id="ref-nealMCMCUsingHamiltonian2011"><p>Neal, Radford M. 2011. “MCMC Using Hamiltonian Dynamics.” <em>Handbook of Markov Chain Monte Carlo</em> 2 (11).</p></div><div id="ref-youngLeapfrogMethodOther"><p>Young, Peter. n.d. “The Leapfrog Method and Other ‘Symplectic’ Algorithms for Integrating Newton’s Laws of Motion,” 15.</p></div></div></div><div style="height:10px"></div></div></article><nav id="article-nav"><a href="/Deep_Learning/Monte_Carlo_Methods/Langevin_Dynamics/" id="article-nav-newer" class="article-nav-link-wrap"><strong class="article-nav-caption">Newer</strong><div class="article-nav-title">Langevin Dynamics</div></a><a href="/Deep_Learning/Monte_Carlo_Methods/Gibbs_Sampler/" id="article-nav-older" class="article-nav-link-wrap"><strong class="article-nav-caption">Older</strong><div class="article-nav-title">Gibbs Sampler</div></a></nav></section></div><footer id="footer"><div class="outer"><div id="footer-info" class="inner">Haowen Xu &copy; 2020 <a rel="license" href="http://creativecommons.org/licenses/by-nc-nd/4.0/"><img alt="Creative Commons License" style="border-width:0" src="/images/by-nc-nd-4.0-80x15.png"></a><br>Powered by <a href="http://hexo.io/" target="_blank">Hexo</a> &amp; theme <a href="https://github.com/zthxxx/hexo-theme-Wikitten">Wikitten</a></div></div></footer><script src="/libs/lightgallery/js/lightgallery.min.js"></script><script src="/libs/lightgallery/js/lg-thumbnail.min.js"></script><script src="/libs/lightgallery/js/lg-pager.min.js"></script><script src="/libs/lightgallery/js/lg-autoplay.min.js"></script><script src="/libs/lightgallery/js/lg-fullscreen.min.js"></script><script src="/libs/lightgallery/js/lg-zoom.min.js"></script><script src="/libs/lightgallery/js/lg-hash.min.js"></script><script src="/libs/lightgallery/js/lg-share.min.js"></script><script src="/libs/lightgallery/js/lg-video.min.js"></script><script src="/libs/justified-gallery/jquery.justifiedGallery.min.js"></script><script type="text/x-mathjax-config">MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ["$","$"], ["\\(","\\)"] ],
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
            processEscapes: true,
            TeX: {
                equationNumbers: {
                    autoNumber: 'AMS'
                },
                style: {
                    'font-family': 'serif'
                }
            }
        },
        'HTML-CSS': {
            //preferredFont: 'TeX',
            fonts: ['TeX']
        }
    });
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax();
        for (var i = 0; i < all.length; ++i)
            all[i].SourceElement().parentNode.className += ' has-jax';
    });</script><script async src="//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><script src="/js/main.js"></script></div></body>