<!DOCTYPE html><html lang="en"><head><meta name="generator" content="Hexo 3.9.0"><meta charset="utf-8"><title>Energy Function in Probabilistic Models | My Research Wiki</title><meta name="keywords" content="Energy Function in Probabilistic Models"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=1"><meta name="description" content="This post summarizes the relationship between energy function and the deduced probabilistic model by a specified energy function.Common FormulationThe probabilistic model deduced from an energy functi"><meta property="og:type" content="article"><meta property="og:title" content="Energy Function in Probabilistic Models"><meta property="og:url" content="https://wiki.haowen-xu.com/Deep_Learning/Energy_Based_Models/Energy_Function_in_Probabilistic_Models/index.html"><meta property="og:site_name" content="My Research Wiki"><meta property="og:description" content="This post summarizes the relationship between energy function and the deduced probabilistic model by a specified energy function.Common FormulationThe probabilistic model deduced from an energy functi"><meta property="og:locale" content="en"><meta property="og:updated_time" content="2020-06-01T12:15:59.000Z"><meta name="twitter:card" content="summary"><meta name="twitter:title" content="Energy Function in Probabilistic Models"><meta name="twitter:description" content="This post summarizes the relationship between energy function and the deduced probabilistic model by a specified energy function.Common FormulationThe probabilistic model deduced from an energy functi"><link rel="alternate" href="/atom.xml" title="My Research Wiki" type="application/atom+xml"><link rel="icon" href="/favicon.ico"><link rel="stylesheet" href="/libs/font-awesome/css/font-awesome.min.css"><link rel="stylesheet" href="/libs/open-sans/styles.css"><link rel="stylesheet" href="/libs/source-code-pro/styles.css"><link rel="stylesheet" href="/css/style.css"><script src="/libs/jquery/2.1.3/jquery.min.js"></script><script src="/libs/jquery/plugins/cookie/1.4.1/jquery.cookie.js"></script><link rel="stylesheet" href="/libs/lightgallery/css/lightgallery.min.css"><link rel="stylesheet" href="/libs/justified-gallery/justifiedGallery.min.css"></head></html><body><div id="container"><header id="header"><div id="header-main" class="header-inner"><div class="outer"><a href="/" id="logo"><i class="logo"></i> <span class="site-title">My Research Wiki</span></a><nav id="main-nav"><a class="main-nav-link" href="/">Home</a> <a class="main-nav-link" href="/archives">Archives</a> <a class="main-nav-link" href="/categories">Categories</a></nav><div id="search-form-wrap"><form class="search-form"><input type="text" class="ins-search-input search-form-input" placeholder="Search"> <button type="submit" class="search-form-submit"></button></form><div class="ins-search"><div class="ins-search-mask"></div><div class="ins-search-container"><div class="ins-input-wrapper"><input type="text" class="ins-search-input" placeholder="Type something..."> <span class="ins-close ins-selectable"><i class="fa fa-times-circle"></i></span></div><div class="ins-section-wrapper"><div class="ins-section-container"></div></div></div></div><script>window.INSIGHT_CONFIG={TRANSLATION:{POSTS:"Posts",PAGES:"Pages",CATEGORIES:"Categories",TAGS:"Tags",UNTITLED:"(Untitled)"},ROOT_URL:"/",CONTENT_URL:"/content.json"}</script><script src="/js/insight.js"></script></div></div></div><div id="main-nav-mobile" class="header-sub header-inner"><table class="menu outer"><tr><td><a class="main-nav-link" href="/">Home</a></td><td><a class="main-nav-link" href="/archives">Archives</a></td><td><a class="main-nav-link" href="/categories">Categories</a></td><td><div class="search-form"><input type="text" class="ins-search-input search-form-input" placeholder="Search"></div></td></tr></table></div></header><div class="outer"><aside id="sidebar"><div class="widget-wrap" id="categories"><h3 class="widget-title"><span>categories</span> &nbsp; <a id="allExpand" href="#"><i class="fa fa-angle-double-down fa-2x"></i></a></h3><ul class="unstyled" id="tree"><li class="directory open"><a href="#" data-role="directory"><i class="fa fa-folder-open"></i> &nbsp; Deep Learning</a><ul class="unstyled" id="tree"><li class="directory"><a href="#" data-role="directory"><i class="fa fa-folder"></i> &nbsp; CV</a><ul class="unstyled" id="tree"><li class="file"><a href="/Deep_Learning/CV/Image_Segmentation/">Image Segmentation</a></li></ul></li><li class="directory"><a href="#" data-role="directory"><i class="fa fa-folder"></i> &nbsp; Confronting Partition Function</a><ul class="unstyled" id="tree"><li class="file"><a href="/Deep_Learning/Confronting_Partition_Function/Overview/">Overview</a></li><li class="file"><a href="/Deep_Learning/Confronting_Partition_Function/Contrastive_Divergence/">Contrastive Divergence</a></li><li class="file"><a href="/Deep_Learning/Confronting_Partition_Function/Score_Matching/">Score Matching</a></li><li class="file"><a href="/Deep_Learning/Confronting_Partition_Function/Softmax_Speedup/">Softmax Speedup</a></li></ul></li><li class="directory open"><a href="#" data-role="directory"><i class="fa fa-folder-open"></i> &nbsp; Energy Based Models</a><ul class="unstyled" id="tree"><li class="file"><a href="/Deep_Learning/Energy_Based_Models/Overview/">Overview</a></li><li class="file active"><a href="/Deep_Learning/Energy_Based_Models/Energy_Function_in_Probabilistic_Models/">Energy Function in Probabilistic Models</a></li><li class="file"><a href="/Deep_Learning/Energy_Based_Models/Restricted_Boltzmann_Machine/">Restricted Boltzmann Machine</a></li></ul></li><li class="directory"><a href="#" data-role="directory"><i class="fa fa-folder"></i> &nbsp; Evaluation</a><ul class="unstyled" id="tree"><li class="file"><a href="/Deep_Learning/Evaluation/Evaluation_Metrics/">Evaluation Metrics</a></li><li class="file"><a href="/Deep_Learning/Evaluation/Visualizing_High_Dimensional_Space/">Visualizing High Dimensional Space</a></li></ul></li><li class="directory"><a href="#" data-role="directory"><i class="fa fa-folder"></i> &nbsp; Generative Adversarial Nets</a><ul class="unstyled" id="tree"><li class="file"><a href="/Deep_Learning/Generative_Adversarial_Nets/Overview/">Overview</a></li><li class="file"><a href="/Deep_Learning/Generative_Adversarial_Nets/f-GAN/">f-GAN</a></li><li class="file"><a href="/Deep_Learning/Generative_Adversarial_Nets/Energy_GAN/">Energy GAN</a></li></ul></li><li class="directory"><a href="#" data-role="directory"><i class="fa fa-folder"></i> &nbsp; Graph Neural Networks</a><ul class="unstyled" id="tree"><li class="file"><a href="/Deep_Learning/Graph_Neural_Networks/Node_Embedding/">Node Embedding</a></li><li class="file"><a href="/Deep_Learning/Graph_Neural_Networks/Graph_Convolution_Network/">Graph Convolution Network</a></li><li class="file"><a href="/Deep_Learning/Graph_Neural_Networks/Graph_Auto_Encoder/">Graph Auto-Encoder</a></li></ul></li><li class="directory"><a href="#" data-role="directory"><i class="fa fa-folder"></i> &nbsp; Information Theoretical</a><ul class="unstyled" id="tree"><li class="file"><a href="/Deep_Learning/Information_Theoretical/KL-Divergence/">KL-Divergence</a></li><li class="file"><a href="/Deep_Learning/Information_Theoretical/Mutual_Information/">Mutual Information</a></li></ul></li><li class="directory"><a href="#" data-role="directory"><i class="fa fa-folder"></i> &nbsp; Monte Carlo Methods</a><ul class="unstyled" id="tree"><li class="file"><a href="/Deep_Learning/Monte_Carlo_Methods/Overview/">Overview</a></li><li class="file"><a href="/Deep_Learning/Monte_Carlo_Methods/Monte_Carlo_Integration/">Monte Carlo Integration</a></li><li class="file"><a href="/Deep_Learning/Monte_Carlo_Methods/Accept_Reject_Sampling/">Accept-Reject Sampling</a></li><li class="file"><a href="/Deep_Learning/Monte_Carlo_Methods/Markov_Chain/">Markov Chain</a></li><li class="file"><a href="/Deep_Learning/Monte_Carlo_Methods/Metropolis_Hastings_Algorithm/">Metropolis-Hastings Algorithm</a></li><li class="file"><a href="/Deep_Learning/Monte_Carlo_Methods/Gibbs_Sampler/">Gibbs Sampler</a></li><li class="file"><a href="/Deep_Learning/Monte_Carlo_Methods/Hamiltonian_Dynamics/">Hamiltonian Dynamics</a></li><li class="file"><a href="/Deep_Learning/Monte_Carlo_Methods/Langevin_Dynamics/">Langevin Dynamics</a></li></ul></li><li class="directory"><a href="#" data-role="directory"><i class="fa fa-folder"></i> &nbsp; Optimization</a><ul class="unstyled" id="tree"><li class="file"><a href="/Deep_Learning/Optimization/Gradient_Tricks/">Gradient Tricks</a></li><li class="file"><a href="/Deep_Learning/Optimization/Loss_Surface_and_Generalization/">Loss Surface and Generalization</a></li><li class="file"><a href="/Deep_Learning/Optimization/Stochastic_Gradient_Descent/">Stochastic Gradient descent</a></li></ul></li><li class="directory"><a href="#" data-role="directory"><i class="fa fa-folder"></i> &nbsp; Variational Autoencoder</a><ul class="unstyled" id="tree"><li class="file"><a href="/Deep_Learning/Variational_Autoencoder/Overview/">Overview</a></li><li class="file"><a href="/Deep_Learning/Variational_Autoencoder/Sequential_VAE/">Sequential VAE</a></li><li class="file"><a href="/Deep_Learning/Variational_Autoencoder/Gradient_Estimators_for_Variational_Inference/">Gradient Estimators for Variational Inference</a></li><li class="file"><a href="/Deep_Learning/Variational_Autoencoder/Theoretical_Facts/">Theoretical Facts about VAEs</a></li></ul></li></ul></li><li class="directory"><a href="#" data-role="directory"><i class="fa fa-folder"></i> &nbsp; Mathematics</a><ul class="unstyled" id="tree"><li class="directory"><a href="#" data-role="directory"><i class="fa fa-folder"></i> &nbsp; Analysis</a><ul class="unstyled" id="tree"><li class="file"><a href="/Mathematics/Analysis/Linear_Space_vs_Functional_Space/">Linear space vs functional space</a></li></ul></li><li class="directory"><a href="#" data-role="directory"><i class="fa fa-folder"></i> &nbsp; Calculus</a><ul class="unstyled" id="tree"><li class="file"><a href="/Mathematics/Calculus/Calculus_of_Variations/">Calculus of Variations</a></li></ul></li><li class="directory"><a href="#" data-role="directory"><i class="fa fa-folder"></i> &nbsp; Differential Equations</a><ul class="unstyled" id="tree"><li class="file"><a href="/Mathematics/Differential_Equations/Probability_Distribution_Equations/">Differential Equations on Probability Distributions</a></li></ul></li><li class="directory"><a href="#" data-role="directory"><i class="fa fa-folder"></i> &nbsp; Optimization</a><ul class="unstyled" id="tree"><li class="file"><a href="/Mathematics/Optimization/Convex_Optimization/">Convex Optimization</a></li></ul></li></ul></li><li class="directory"><a href="#" data-role="directory"><i class="fa fa-folder"></i> &nbsp; Research Work</a><ul class="unstyled" id="tree"><li class="file"><a href="/Research_Work/Reading_List/">Reading List</a></li><li class="file"><a href="/Research_Work/Tracking_the_Concepts/">Tracking the Concepts</a></li><li class="file"><a href="/Research_Work/Directions_to_Explore/">Directions to Explore</a></li></ul></li></ul></div><script>$(document).ready(function(){var r="fa-folder-open",i="fa-folder",l="fa-angle-double-down",d="fa-angle-double-up";$(document).on("click",'#categories a[data-role="directory"]',function(a){a.preventDefault();var e=$(this).children(".fa"),s=e.hasClass(r),l=$(this).siblings("ul");e.removeClass(r).removeClass(i),s?(void 0!==l&&l.slideUp({duration:100}),e.addClass(i)):(void 0!==l&&l.slideDown({duration:100}),e.addClass(r))}),$('#categories a[data-role="directory"]').bind("contextmenu",function(a){a.preventDefault();var e=$(this).children(".fa"),s=e.hasClass(r),l=$(this).siblings("ul"),d=$.merge(l.find("li ul"),l),o=$.merge(l.find(".fa"),e);o.removeClass(r).removeClass(i),s?(d.slideUp({duration:100}),o.addClass(i)):(d.slideDown({duration:100}),o.addClass(r))}),$(document).on("click","#allExpand",function(a){a.preventDefault();var e=$(this).children(".fa"),s=e.hasClass(l);e.removeClass(l).removeClass(d),s?($("#sidebar .fa.fa-folder").removeClass("fa-folder").addClass("fa-folder-open"),$("#categories li ul").slideDown({duration:100}),e.addClass(d)):($("#sidebar .fa.fa-folder-open").removeClass("fa-folder-open").addClass("fa-folder"),$("#categories li ul").slideUp({duration:100}),e.addClass(l))})})</script><div id="toTop" class="fa fa-angle-up"></div></aside><section id="main"><article id="post-Deep_Learning/Energy_Based_Models/Energy_Function_in_Probabilistic_Models" class="article article-type-post" itemscope itemprop="blogPost"><div class="article-inner"><header class="article-header"><div class="article-meta"><div class="article-category"><i class="fa fa-folder"></i> <a class="article-category-link" href="/categories/Deep-Learning/">Deep Learning</a><i class="fa fa-angle-right"></i><a class="article-category-link" href="/categories/Deep-Learning/Energy-Based-Models/">Energy Based Models</a></div><div class="article-date"><i class="fa fa-calendar"></i> <a href="/Deep_Learning/Energy_Based_Models/Energy_Function_in_Probabilistic_Models/"><time datetime="2020-02-28T22:43:51.000Z" itemprop="datePublished">2020-02-29</time></a></div><div class="article-meta-button"><a href="https://github.com/haowen-xu/research-notes/raw/master/source/_posts/Deep_Learning/Energy_Based_Models/Energy_Function_in_Probabilistic_Models.md">Source</a></div><div class="article-meta-button"><a href="https://github.com/haowen-xu/research-notes/edit/master/source/_posts/Deep_Learning/Energy_Based_Models/Energy_Function_in_Probabilistic_Models.md">Edit</a></div><div class="article-meta-button"><a href="https://github.com/haowen-xu/research-notes/commits/master/source/_posts/Deep_Learning/Energy_Based_Models/Energy_Function_in_Probabilistic_Models.md">History</a></div></div><h1 class="article-title" itemprop="name">Energy Function in Probabilistic Models</h1></header><div class="article-entry" itemprop="articleBody"><p>This post summarizes the relationship between energy function and the deduced probabilistic model by a specified energy function.</p><h2 id="common-formulation">Common Formulation</h2><p>The probabilistic model deduced from an energy function can have the following formulations.</p><h3 id="gibbs-distribution">Gibbs Distribution</h3><p>Given an energy function <span class="math inline">\(U(\mathbf{x};\theta)\)</span> with parameters <span class="math inline">\(\theta\)</span>, the probability distribution can be deduced as: <span class="math display">\[ \begin{align} p(\mathbf{x};\theta) &amp;= \frac{1}{Z(\theta)}\,\exp\left( -U(\mathbf{x};\theta) \right) \\ Z(\theta) &amp;= \int \exp\left( -U(\mathbf{x};\theta) \right)\,\mathrm{d}\mathbf{x} \end{align} \]</span> The gradient of <span class="math inline">\(\mathbb{E}_{p_D(\mathbf{x})}\left[ -\log p(\mathbf{x};\theta) \right]\)</span> (i.e., the expectation of the negative log-likelihood <span class="math inline">\(-\log p(\mathbf{x})\)</span> over data distribution <span class="math inline">\(p_D(\mathbf{x})\)</span>) is then derived as: <span class="math display">\[ \begin{align} \nabla \mathbb{E}_{p_D(\mathbf{x};\theta)}\left[ -\log p(\mathbf{x};\theta) \right] &amp;= \mathbb{E}_{p_D(\mathbf{x})}\left[ -\nabla \log p(\mathbf{x};\theta) \right] \\ &amp;= \mathbb{E}_{p_D(\mathbf{x})} \left[ \nabla U(\mathbf{x};\theta) + \nabla \log Z(\theta) \right] \\ &amp;= \mathbb{E}_{p_D(\mathbf{x})} \left[ \nabla U(\mathbf{x};\theta) \right] + \nabla \log Z(\theta) \end{align} \]</span></p><p>where <span class="math inline">\(\nabla \log Z(\theta)\)</span> is: <span class="math display">\[ \begin{align} \nabla \log Z(\theta) &amp;= \frac{\nabla Z(\theta)}{Z(\theta)} \\ &amp;= \frac{1}{Z(\theta)} \int \nabla \exp\left( -U(\mathbf{x};\theta) \right)\,\mathrm{d}\mathbf{x} \\ &amp;= \int \frac{\exp\left( -U(\mathbf{x};\theta) \right) / Z(\theta)}{\exp\left( -U(\mathbf{x};\theta) \right)} \nabla \exp\left( -U(\mathbf{x};\theta) \right) \,\mathrm{d}\mathbf{x} \\ &amp;= \int p(\mathbf{x};\theta) \, \nabla \log \exp\left( -U(\mathbf{x};\theta) \right) \,\mathrm{d}\mathbf{x} \\ &amp;= -\int p(\mathbf{x};\theta) \, \nabla U(\mathbf{x};\theta) \,\mathrm{d}\mathbf{x} \\ &amp;= -\mathbb{E}_{p(\mathbf{x};\theta)} \left[ \nabla U(\mathbf{x};\theta) \right] \end{align} \]</span> thus the final gradient can be derived as: <span class="math display">\[ \nabla \mathbb{E}_{p_D(\mathbf{x};\theta)}\left[ -\log p(\mathbf{x};\theta) \right] = \mathbb{E}_{p_D(\mathbf{x})} \left[ \nabla U(\mathbf{x};\theta) \right] - \mathbb{E}_{p(\mathbf{x};\theta)} \left[ \nabla U(\mathbf{x};\theta) \right] \]</span></p><h4 id="positive-and-negative-phase">Positive and Negative Phase</h4><p>The above gradient consists of the positive phase term <span class="math inline">\(\mathbb{E}_{p_D(\mathbf{x})} \left[ \nabla U(\mathbf{x};\theta) \right]\)</span>, and the negative phase term <span class="math inline">\(\mathbb{E}_{p(\mathbf{x};\theta)} \left[ \nabla U(\mathbf{x};\theta) \right]\)</span>. The gradient reaches zero (which indicates a local minima) when these two terms are equal.</p><p><em>If the path of the gradient to <span class="math inline">\(\mathbb{E}_{p(\mathbf{x};\theta)}\)</span> is blocked (this sentence is added by me)</em>, then the positive phase term can be seen as minimizing the energy on "positive samples" from data distribution, and the negative phase can be seen as maximizing the energy on "negative samples" from model distribution. <span class="citation" data-cites="kimDeepDirectedGenerative2016">(Kim and Bengio <a href="#ref-kimDeepDirectedGenerative2016" role="doc-biblioref">2016</a>)</span></p><p>Sampling from <span class="math inline">\(\mathbb{E}_{p(\mathbf{x};\theta)}\)</span> often requires MCMC techniques, for example, the <a href="/Deep_Learning/Confronting_Partition_Function/Contrastive_Divergence/">Contrastive Divergence</a> algorithm.</p><h2 id="conditional-and-independence">Conditional and Independence</h2><h3 id="definition">Definition</h3><p>The distribution <span class="math inline">\(p(\mathbf{x},\mathbf{y},\mathbf{z})\)</span> deduced by energy function <span class="math inline">\(U(\mathbf{x},\mathbf{y},\mathbf{z})\)</span>: <span class="math display">\[ p(\mathbf{x},\mathbf{y},\mathbf{z}) = \frac{\exp\left( -U(\mathbf{x},\mathbf{y},\mathbf{z}) \right)}{\iiint \exp\left( -U(\mathbf{x}^*,\mathbf{y}^*,\mathbf{z}^*) \right) \, \mathrm{d}\mathbf{z}^* \,\mathrm{d}\mathbf{y}^* \,\mathrm{d}\mathbf{x}^*} \]</span> Also, the conditional distribution <span class="math inline">\(p(\mathbf{y},\mathbf{z}|\mathbf{x})\)</span> is defined as: <span class="math display">\[ p(\mathbf{y},\mathbf{z}|\mathbf{x}) = \frac{\exp\left( -U(\mathbf{x},\mathbf{y},\mathbf{z}) \right)}{\iint \exp\left( -U(\mathbf{x},\mathbf{y}^*,\mathbf{z}^*) \right) \, \mathrm{d}\mathbf{z}^* \,\mathrm{d}\mathbf{y}^*} \]</span></p><h3 id="theorem-1">Theorem 1</h3><p>If <span class="math inline">\(U(\mathbf{x},\mathbf{y},\mathbf{z}) = f(\mathbf{x},\mathbf{y}) + g(\mathbf{x},\mathbf{z}) + h(\mathbf{x})\)</span>, then: <span class="math display">\[ \begin{align} p(\mathbf{y}|\mathbf{x}) &amp;= \frac{\exp\left( -f(\mathbf{x},\mathbf{y}) \right)}{\int \exp\left( -f(\mathbf{x},\mathbf{y}^*) \right) \,\mathrm{d}\mathbf{y}^*} \\ p(\mathbf{z}|\mathbf{x}) &amp;= \frac{\exp\left( -g(\mathbf{x},\mathbf{z}) \right)}{\int \exp\left( -g(\mathbf{x},\mathbf{z}^*) \right) \,\mathrm{d}\mathbf{z}^*} \end{align} \]</span> <em>Proof</em>: <span class="math display">\[ \begin{align} p(\mathbf{y}|\mathbf{x}) &amp;= \int p(\mathbf{x},\mathbf{y},\mathbf{z})\,\mathrm{d}\mathbf{z} \\ &amp;= \int \frac{\exp\left( -U(\mathbf{x},\mathbf{y},\mathbf{z}) \right)}{\iint \exp\left( -U(\mathbf{x},\mathbf{y}^*,\mathbf{z}^*) \right) \, \mathrm{d}\mathbf{z}^* \,\mathrm{d}\mathbf{y}^*}\,\mathrm{d}\mathbf{z} \\ &amp;= \frac{\exp\left( -h(\mathbf{x}) \right)\cdot\exp\left( -f(\mathbf{x},\mathbf{y}) \right) \int \exp\left( -g(\mathbf{x},\mathbf{z}) \right)\,\mathrm{d}\mathbf{z}}{\iint \exp\left( -h(\mathbf{x}) \right)\cdot\exp\left( -f(\mathbf{x},\mathbf{y}^*)\right) \cdot\exp\left( -g(\mathbf{x},\mathbf{z}^*) \right)\,\mathrm{d}\mathbf{z}^*\,\mathrm{d}\mathbf{y}^*} \\ &amp;= \frac{\exp\left( -h(\mathbf{x}) \right)\cdot\exp\left( -f(\mathbf{x},\mathbf{y}) \right) \int \exp\left( -g(\mathbf{x},\mathbf{z}) \right)\,\mathrm{d}\mathbf{z}}{\exp\left( -h(\mathbf{x}) \right)\cdot\left( \int \exp\left( -f(\mathbf{x},\mathbf{y}^*)\right)\,\mathrm{d}\mathbf{y}^* \right) \cdot \left( \int \exp\left( -g(\mathbf{x},\mathbf{z}^*) \right)\,\mathrm{d}\mathbf{z}^* \right)} \\ &amp;= \frac{\exp\left( -f(\mathbf{x},\mathbf{y}) \right)}{\int \exp\left( -f(\mathbf{x},\mathbf{y}^*)\right)\,\mathrm{d}\mathbf{y}^*} \end{align} \]</span> <span class="math inline">\(p(\mathbf{z}|\mathbf{x}) = \frac{\exp\left( -g(\mathbf{x},\mathbf{z}) \right)}{\int \exp\left( -g(\mathbf{x},\mathbf{z}^*) \right) \,\mathrm{d}\mathbf{z}^*}\)</span> can be proven in the same way.</p><h4 id="collary-1">Collary 1</h4><p>If <span class="math inline">\(U(\mathbf{x},\mathbf{y},\mathbf{z}) = f(\mathbf{x},\mathbf{y}) + g(\mathbf{x},\mathbf{z}) + h(\mathbf{x})\)</span>, then <span class="math inline">\(\mathbf{y} \perp\!\!\!\perp \mathbf{z} \mid \mathbf{x}\)</span>.</p><p><em>Proof</em>: <span class="math display">\[ \begin{align} p(\mathbf{y},\mathbf{z}|\mathbf{x}) &amp;= \frac{\exp\left( -U(\mathbf{x},\mathbf{y},\mathbf{z}) \right)}{\iint \exp\left( -U(\mathbf{x},\mathbf{y}^*,\mathbf{z}^*) \right) \, \mathrm{d}\mathbf{z}^* \,\mathrm{d}\mathbf{y}^*} \\ &amp;= \frac{\exp\left( -f(\mathbf{x},\mathbf{y}) \right)}{\int \exp\left( -f(\mathbf{x},\mathbf{y}^*) \right) \,\mathrm{d}\mathbf{y}^*} \cdot \frac{\exp\left( -g(\mathbf{x},\mathbf{z}) \right)}{\int \exp\left( -g(\mathbf{x},\mathbf{z}^*) \right) \,\mathrm{d}\mathbf{z}^*} \\ &amp;= p(\mathbf{y}|\mathbf{x}) \cdot p(\mathbf{z}|\mathbf{x}) \end{align} \]</span> which implies <span class="math inline">\(\mathbf{y} \perp\!\!\!\perp \mathbf{z} \mid \mathbf{x}\)</span>.</p><h4 id="collary-2">Collary 2</h4><p>If <span class="math inline">\(U(\mathbf{y},\mathbf{z}) = f(\mathbf{y}) + g(\mathbf{z})\)</span>, then: <span class="math display">\[ \begin{align} p(\mathbf{y}) &amp;= \frac{\exp\left( -f(\mathbf{y}) \right)}{\int \exp\left( -f(\mathbf{y}^*) \right) \,\mathrm{d}\mathbf{y}^*} \\ p(\mathbf{z}) &amp;= \frac{\exp\left( -g(\mathbf{z}) \right)}{\int \exp\left( -g(\mathbf{z}^*) \right) \,\mathrm{d}\mathbf{z}^*} \end{align} \]</span> <em>Proof</em>: similar to Theorem 1.</p><h4 id="collary-3">Collary 3</h4><p>If <span class="math inline">\(U(\mathbf{y},\mathbf{z}) = f(\mathbf{y}) + g(\mathbf{z})\)</span>, then <span class="math inline">\(\mathbf{y} \perp\!\!\!\perp \mathbf{z}\)</span>.</p><p><em>Proof</em>: according to Collary 2, and similar to Collary 1.</p><h1 id="bibliography" class="unnumbered">References</h1><div id="refs" class="references" role="doc-bibliography"><div id="ref-kimDeepDirectedGenerative2016"><p>Kim, Taesup, and Yoshua Bengio. 2016. “Deep Directed Generative Models with Energy-Based Probability Estimation.” <em>arXiv Preprint arXiv:1606.03439</em>.</p></div></div></div><div style="height:10px"></div></div></article><nav id="article-nav"><a href="/Deep_Learning/Confronting_Partition_Function/Softmax_Speedup/" id="article-nav-newer" class="article-nav-link-wrap"><strong class="article-nav-caption">Newer</strong><div class="article-nav-title">Softmax Speedup</div></a><a href="/Deep_Learning/Energy_Based_Models/Restricted_Boltzmann_Machine/" id="article-nav-older" class="article-nav-link-wrap"><strong class="article-nav-caption">Older</strong><div class="article-nav-title">Restricted Boltzmann Machine</div></a></nav></section></div><footer id="footer"><div class="outer"><div id="footer-info" class="inner">Haowen Xu &copy; 2020 <a rel="license" href="http://creativecommons.org/licenses/by-nc-nd/4.0/"><img alt="Creative Commons License" style="border-width:0" src="/images/by-nc-nd-4.0-80x15.png"></a><br>Powered by <a href="http://hexo.io/" target="_blank">Hexo</a> &amp; theme <a href="https://github.com/zthxxx/hexo-theme-Wikitten">Wikitten</a></div></div></footer><script src="/libs/lightgallery/js/lightgallery.min.js"></script><script src="/libs/lightgallery/js/lg-thumbnail.min.js"></script><script src="/libs/lightgallery/js/lg-pager.min.js"></script><script src="/libs/lightgallery/js/lg-autoplay.min.js"></script><script src="/libs/lightgallery/js/lg-fullscreen.min.js"></script><script src="/libs/lightgallery/js/lg-zoom.min.js"></script><script src="/libs/lightgallery/js/lg-hash.min.js"></script><script src="/libs/lightgallery/js/lg-share.min.js"></script><script src="/libs/lightgallery/js/lg-video.min.js"></script><script src="/libs/justified-gallery/jquery.justifiedGallery.min.js"></script><script type="text/x-mathjax-config">MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ["$","$"], ["\\(","\\)"] ],
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
            processEscapes: true,
            TeX: {
                equationNumbers: {
                    autoNumber: 'AMS'
                },
                style: {
                    'font-family': 'serif'
                }
            }
        },
        'HTML-CSS': {
            //preferredFont: 'TeX',
            fonts: ['TeX']
        }
    });
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax();
        for (var i = 0; i < all.length; ++i)
            all[i].SourceElement().parentNode.className += ' has-jax';
    });</script><script async src="//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><script src="/js/main.js"></script></div></body>