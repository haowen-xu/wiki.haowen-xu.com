<!DOCTYPE html><html lang="en"><head><meta name="generator" content="Hexo 3.9.0"><meta charset="utf-8"><title>Stochastic Gradient descent | My Research Wiki</title><meta name="keywords" content="Stochastic Gradient descent"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=1"><meta name="description" content="First-Order MethodsFor simplicity, we first introduce the following common notations:\(J(\theta)\): The objective function, which should be minimized w.r.t. \(\theta\).\(g(\theta)\): The gradient of \"><meta property="og:type" content="article"><meta property="og:title" content="Stochastic Gradient descent"><meta property="og:url" content="https://wiki.haowen-xu.com/Deep_Learning/Optimization/Stochastic_Gradient_Descent/index.html"><meta property="og:site_name" content="My Research Wiki"><meta property="og:description" content="First-Order MethodsFor simplicity, we first introduce the following common notations:\(J(\theta)\): The objective function, which should be minimized w.r.t. \(\theta\).\(g(\theta)\): The gradient of \"><meta property="og:locale" content="en"><meta property="og:updated_time" content="2020-06-01T12:15:59.012Z"><meta name="twitter:card" content="summary"><meta name="twitter:title" content="Stochastic Gradient descent"><meta name="twitter:description" content="First-Order MethodsFor simplicity, we first introduce the following common notations:\(J(\theta)\): The objective function, which should be minimized w.r.t. \(\theta\).\(g(\theta)\): The gradient of \"><link rel="alternate" href="/atom.xml" title="My Research Wiki" type="application/atom+xml"><link rel="icon" href="/favicon.ico"><link rel="stylesheet" href="/libs/font-awesome/css/font-awesome.min.css"><link rel="stylesheet" href="/libs/open-sans/styles.css"><link rel="stylesheet" href="/libs/source-code-pro/styles.css"><link rel="stylesheet" href="/css/style.css"><script src="/libs/jquery/2.1.3/jquery.min.js"></script><script src="/libs/jquery/plugins/cookie/1.4.1/jquery.cookie.js"></script><link rel="stylesheet" href="/libs/lightgallery/css/lightgallery.min.css"><link rel="stylesheet" href="/libs/justified-gallery/justifiedGallery.min.css"></head></html><body><div id="container"><header id="header"><div id="header-main" class="header-inner"><div class="outer"><a href="/" id="logo"><i class="logo"></i> <span class="site-title">My Research Wiki</span></a><nav id="main-nav"><a class="main-nav-link" href="/">Home</a> <a class="main-nav-link" href="/archives">Archives</a> <a class="main-nav-link" href="/categories">Categories</a></nav><div id="search-form-wrap"><form class="search-form"><input type="text" class="ins-search-input search-form-input" placeholder="Search"> <button type="submit" class="search-form-submit"></button></form><div class="ins-search"><div class="ins-search-mask"></div><div class="ins-search-container"><div class="ins-input-wrapper"><input type="text" class="ins-search-input" placeholder="Type something..."> <span class="ins-close ins-selectable"><i class="fa fa-times-circle"></i></span></div><div class="ins-section-wrapper"><div class="ins-section-container"></div></div></div></div><script>window.INSIGHT_CONFIG={TRANSLATION:{POSTS:"Posts",PAGES:"Pages",CATEGORIES:"Categories",TAGS:"Tags",UNTITLED:"(Untitled)"},ROOT_URL:"/",CONTENT_URL:"/content.json"}</script><script src="/js/insight.js"></script></div></div></div><div id="main-nav-mobile" class="header-sub header-inner"><table class="menu outer"><tr><td><a class="main-nav-link" href="/">Home</a></td><td><a class="main-nav-link" href="/archives">Archives</a></td><td><a class="main-nav-link" href="/categories">Categories</a></td><td><div class="search-form"><input type="text" class="ins-search-input search-form-input" placeholder="Search"></div></td></tr></table></div></header><div class="outer"><aside id="sidebar"><div class="widget-wrap" id="categories"><h3 class="widget-title"><span>categories</span> &nbsp; <a id="allExpand" href="#"><i class="fa fa-angle-double-down fa-2x"></i></a></h3><ul class="unstyled" id="tree"><li class="directory open"><a href="#" data-role="directory"><i class="fa fa-folder-open"></i> &nbsp; Deep Learning</a><ul class="unstyled" id="tree"><li class="directory"><a href="#" data-role="directory"><i class="fa fa-folder"></i> &nbsp; CV</a><ul class="unstyled" id="tree"><li class="file"><a href="/Deep_Learning/CV/Image_Segmentation/">Image Segmentation</a></li></ul></li><li class="directory"><a href="#" data-role="directory"><i class="fa fa-folder"></i> &nbsp; Confronting Partition Function</a><ul class="unstyled" id="tree"><li class="file"><a href="/Deep_Learning/Confronting_Partition_Function/Overview/">Overview</a></li><li class="file"><a href="/Deep_Learning/Confronting_Partition_Function/Contrastive_Divergence/">Contrastive Divergence</a></li><li class="file"><a href="/Deep_Learning/Confronting_Partition_Function/Score_Matching/">Score Matching</a></li><li class="file"><a href="/Deep_Learning/Confronting_Partition_Function/Softmax_Speedup/">Softmax Speedup</a></li></ul></li><li class="directory"><a href="#" data-role="directory"><i class="fa fa-folder"></i> &nbsp; Energy Based Models</a><ul class="unstyled" id="tree"><li class="file"><a href="/Deep_Learning/Energy_Based_Models/Overview/">Overview</a></li><li class="file"><a href="/Deep_Learning/Energy_Based_Models/Energy_Function_in_Probabilistic_Models/">Energy Function in Probabilistic Models</a></li><li class="file"><a href="/Deep_Learning/Energy_Based_Models/Restricted_Boltzmann_Machine/">Restricted Boltzmann Machine</a></li></ul></li><li class="directory"><a href="#" data-role="directory"><i class="fa fa-folder"></i> &nbsp; Evaluation</a><ul class="unstyled" id="tree"><li class="file"><a href="/Deep_Learning/Evaluation/Evaluation_Metrics/">Evaluation Metrics</a></li><li class="file"><a href="/Deep_Learning/Evaluation/Visualizing_High_Dimensional_Space/">Visualizing High Dimensional Space</a></li></ul></li><li class="directory"><a href="#" data-role="directory"><i class="fa fa-folder"></i> &nbsp; Generative Adversarial Nets</a><ul class="unstyled" id="tree"><li class="file"><a href="/Deep_Learning/Generative_Adversarial_Nets/Overview/">Overview</a></li><li class="file"><a href="/Deep_Learning/Generative_Adversarial_Nets/f-GAN/">f-GAN</a></li><li class="file"><a href="/Deep_Learning/Generative_Adversarial_Nets/Energy_GAN/">Energy GAN</a></li></ul></li><li class="directory"><a href="#" data-role="directory"><i class="fa fa-folder"></i> &nbsp; Graph Neural Networks</a><ul class="unstyled" id="tree"><li class="file"><a href="/Deep_Learning/Graph_Neural_Networks/Node_Embedding/">Node Embedding</a></li><li class="file"><a href="/Deep_Learning/Graph_Neural_Networks/Graph_Convolution_Network/">Graph Convolution Network</a></li><li class="file"><a href="/Deep_Learning/Graph_Neural_Networks/Graph_Auto_Encoder/">Graph Auto-Encoder</a></li></ul></li><li class="directory"><a href="#" data-role="directory"><i class="fa fa-folder"></i> &nbsp; Information Theoretical</a><ul class="unstyled" id="tree"><li class="file"><a href="/Deep_Learning/Information_Theoretical/KL-Divergence/">KL-Divergence</a></li><li class="file"><a href="/Deep_Learning/Information_Theoretical/Mutual_Information/">Mutual Information</a></li></ul></li><li class="directory"><a href="#" data-role="directory"><i class="fa fa-folder"></i> &nbsp; Monte Carlo Methods</a><ul class="unstyled" id="tree"><li class="file"><a href="/Deep_Learning/Monte_Carlo_Methods/Overview/">Overview</a></li><li class="file"><a href="/Deep_Learning/Monte_Carlo_Methods/Monte_Carlo_Integration/">Monte Carlo Integration</a></li><li class="file"><a href="/Deep_Learning/Monte_Carlo_Methods/Accept_Reject_Sampling/">Accept-Reject Sampling</a></li><li class="file"><a href="/Deep_Learning/Monte_Carlo_Methods/Markov_Chain/">Markov Chain</a></li><li class="file"><a href="/Deep_Learning/Monte_Carlo_Methods/Metropolis_Hastings_Algorithm/">Metropolis-Hastings Algorithm</a></li><li class="file"><a href="/Deep_Learning/Monte_Carlo_Methods/Gibbs_Sampler/">Gibbs Sampler</a></li><li class="file"><a href="/Deep_Learning/Monte_Carlo_Methods/Hamiltonian_Dynamics/">Hamiltonian Dynamics</a></li><li class="file"><a href="/Deep_Learning/Monte_Carlo_Methods/Langevin_Dynamics/">Langevin Dynamics</a></li></ul></li><li class="directory open"><a href="#" data-role="directory"><i class="fa fa-folder-open"></i> &nbsp; Optimization</a><ul class="unstyled" id="tree"><li class="file"><a href="/Deep_Learning/Optimization/Gradient_Tricks/">Gradient Tricks</a></li><li class="file"><a href="/Deep_Learning/Optimization/Loss_Surface_and_Generalization/">Loss Surface and Generalization</a></li><li class="file active"><a href="/Deep_Learning/Optimization/Stochastic_Gradient_Descent/">Stochastic Gradient descent</a></li></ul></li><li class="directory"><a href="#" data-role="directory"><i class="fa fa-folder"></i> &nbsp; Variational Autoencoder</a><ul class="unstyled" id="tree"><li class="file"><a href="/Deep_Learning/Variational_Autoencoder/Overview/">Overview</a></li><li class="file"><a href="/Deep_Learning/Variational_Autoencoder/Sequential_VAE/">Sequential VAE</a></li><li class="file"><a href="/Deep_Learning/Variational_Autoencoder/Gradient_Estimators_for_Variational_Inference/">Gradient Estimators for Variational Inference</a></li><li class="file"><a href="/Deep_Learning/Variational_Autoencoder/Theoretical_Facts/">Theoretical Facts about VAEs</a></li></ul></li></ul></li><li class="directory"><a href="#" data-role="directory"><i class="fa fa-folder"></i> &nbsp; Mathematics</a><ul class="unstyled" id="tree"><li class="directory"><a href="#" data-role="directory"><i class="fa fa-folder"></i> &nbsp; Analysis</a><ul class="unstyled" id="tree"><li class="file"><a href="/Mathematics/Analysis/Linear_Space_vs_Functional_Space/">Linear space vs functional space</a></li></ul></li><li class="directory"><a href="#" data-role="directory"><i class="fa fa-folder"></i> &nbsp; Calculus</a><ul class="unstyled" id="tree"><li class="file"><a href="/Mathematics/Calculus/Calculus_of_Variations/">Calculus of Variations</a></li></ul></li><li class="directory"><a href="#" data-role="directory"><i class="fa fa-folder"></i> &nbsp; Differential Equations</a><ul class="unstyled" id="tree"><li class="file"><a href="/Mathematics/Differential_Equations/Probability_Distribution_Equations/">Differential Equations on Probability Distributions</a></li></ul></li><li class="directory"><a href="#" data-role="directory"><i class="fa fa-folder"></i> &nbsp; Optimization</a><ul class="unstyled" id="tree"><li class="file"><a href="/Mathematics/Optimization/Convex_Optimization/">Convex Optimization</a></li></ul></li></ul></li><li class="directory"><a href="#" data-role="directory"><i class="fa fa-folder"></i> &nbsp; Research Work</a><ul class="unstyled" id="tree"><li class="file"><a href="/Research_Work/Reading_List/">Reading List</a></li><li class="file"><a href="/Research_Work/Tracking_the_Concepts/">Tracking the Concepts</a></li><li class="file"><a href="/Research_Work/Directions_to_Explore/">Directions to Explore</a></li></ul></li></ul></div><script>$(document).ready(function(){var r="fa-folder-open",i="fa-folder",l="fa-angle-double-down",d="fa-angle-double-up";$(document).on("click",'#categories a[data-role="directory"]',function(a){a.preventDefault();var e=$(this).children(".fa"),s=e.hasClass(r),l=$(this).siblings("ul");e.removeClass(r).removeClass(i),s?(void 0!==l&&l.slideUp({duration:100}),e.addClass(i)):(void 0!==l&&l.slideDown({duration:100}),e.addClass(r))}),$('#categories a[data-role="directory"]').bind("contextmenu",function(a){a.preventDefault();var e=$(this).children(".fa"),s=e.hasClass(r),l=$(this).siblings("ul"),d=$.merge(l.find("li ul"),l),o=$.merge(l.find(".fa"),e);o.removeClass(r).removeClass(i),s?(d.slideUp({duration:100}),o.addClass(i)):(d.slideDown({duration:100}),o.addClass(r))}),$(document).on("click","#allExpand",function(a){a.preventDefault();var e=$(this).children(".fa"),s=e.hasClass(l);e.removeClass(l).removeClass(d),s?($("#sidebar .fa.fa-folder").removeClass("fa-folder").addClass("fa-folder-open"),$("#categories li ul").slideDown({duration:100}),e.addClass(d)):($("#sidebar .fa.fa-folder-open").removeClass("fa-folder-open").addClass("fa-folder"),$("#categories li ul").slideUp({duration:100}),e.addClass(l))})})</script><div id="toTop" class="fa fa-angle-up"></div></aside><section id="main"><article id="post-Deep_Learning/Optimization/Stochastic_Gradient_Descent" class="article article-type-post" itemscope itemprop="blogPost"><div class="article-inner"><header class="article-header"><div class="article-meta"><div class="article-category"><i class="fa fa-folder"></i> <a class="article-category-link" href="/categories/Deep-Learning/">Deep Learning</a><i class="fa fa-angle-right"></i><a class="article-category-link" href="/categories/Deep-Learning/Optimization/">Optimization</a></div><div class="article-date"><i class="fa fa-calendar"></i> <a href="/Deep_Learning/Optimization/Stochastic_Gradient_Descent/"><time datetime="2020-05-29T17:53:26.000Z" itemprop="datePublished">2020-05-30</time></a></div><div class="article-meta-button"><a href="https://github.com/haowen-xu/research-notes/raw/master/source/_posts/Deep_Learning/Optimization/Stochastic_Gradient_Descent.md">Source</a></div><div class="article-meta-button"><a href="https://github.com/haowen-xu/research-notes/edit/master/source/_posts/Deep_Learning/Optimization/Stochastic_Gradient_Descent.md">Edit</a></div><div class="article-meta-button"><a href="https://github.com/haowen-xu/research-notes/commits/master/source/_posts/Deep_Learning/Optimization/Stochastic_Gradient_Descent.md">History</a></div></div><h1 class="article-title" itemprop="name">Stochastic Gradient descent</h1></header><div class="article-entry" itemprop="articleBody"><h2 id="first-order-methods">First-Order Methods</h2><p>For simplicity, we first introduce the following common notations:</p><ul><li><span class="math inline">\(J(\theta)\)</span>: The objective function, which should be minimized <em>w.r.t.</em> <span class="math inline">\(\theta\)</span>.</li><li><span class="math inline">\(g(\theta)\)</span>: The gradient of <span class="math inline">\(J(\theta)\)</span>, i.e., <span class="math inline">\(g(\theta) = \nabla J(\theta)\)</span>.</li><li><span class="math inline">\(g_t\)</span>: The abbrevation for <span class="math inline">\(g(\theta_t)\)</span>.</li></ul><p>One key difference between this article and that of <span class="citation" data-cites="OverviewGradientDescent2016">(“An Overview of Gradient Descent Optimization Algorithms” <a href="#ref-OverviewGradientDescent2016" role="doc-biblioref">2016</a>)</span> is that, <span class="math inline">\(\eta\)</span> is applied on the whole delta when updating the parameters <span class="math inline">\(\theta_t\)</span>, including the momentum term. This is because, practically, one may expect <span class="math inline">\(\eta\)</span> to be served as a direct constraint of how much the parameters <span class="math inline">\(\theta_t\)</span> are updated within each training step.</p><h3 id="naive-stochastic-gradient-descent">(Naive) Stochastic Gradient Descent</h3><p><span class="math display">\[ \theta_{t+1} = \theta_t - \eta \, g_t \]</span></p><h3 id="momentum-sgd">Momentum SGD</h3><p><span class="math display">\[ \begin{align} v_t &amp;= \gamma \, v_{t-1} + g_t \\ \theta_{t+1} &amp;= \theta_t - \eta \,v_t \end{align} \]</span></p><p>It converges generally faster than the naive stochastic gradient descent, due to the accumulated <span class="math inline">\(v_t\)</span> can help eliminate the unrelated directions of the gradient, and amplify the most related directions of the gradient. The ratio of amplification is roughly <span class="math inline">\(\frac{1}{1 - \gamma}\)</span>.</p><h3 id="nesterov-momentum-sgd">Nesterov Momentum SGD</h3><p><span class="math display">\[ \begin{align} v_t &amp;= \gamma \,v_{t-1} + g(\theta_t - \eta\, \gamma \,v_{t-1}) \\ \theta_{t+1} &amp;= \theta_t - \eta\, v_t \end{align} \]</span></p><h4 id="alternative-form">Alternative Form</h4><p><span class="citation" data-cites="dozatIncorporatingNesterovMomentum2016">Dozat (<a href="#ref-dozatIncorporatingNesterovMomentum2016" role="doc-biblioref">2016</a>)</span> proposed to combine the two momentum steps into one, resulting in: <span class="math display">\[ \begin{align} v_t &amp;= \gamma \, v_{t-1} + g_t \\ \theta_{t+1} &amp;= \theta_t - \eta \, (\gamma \,v_t + g_t) \end{align} \]</span> which may be more preferable in practice.</p><p><em>Proof</em></p><p>Let <span class="math inline">\(\hat{\theta}_t = \theta_t - \eta\,\gamma\,v_{t-1}\)</span> and <span class="math inline">\(\hat{g}_t = g(\hat{\theta}_t) = g(\theta_t - \eta\, \gamma \,v_{t-1})\)</span>, and substitute into the original form, we can obtain: <span class="math display">\[ \begin{align} v_t &amp;= \gamma\,v_{t-1} + \hat{g}_t \\ \hat{\theta}_{t+1} &amp;= \theta_{t+1} - \eta\,\gamma\,v_t \\ &amp;= \theta_t - \eta\,v_t - \eta\,\gamma\,v_t \\ &amp;= \theta_t - \eta(\gamma\,v_{t-1} + \hat{g}_t) - \eta\,\gamma\,v_t \\ &amp;= (\theta_t - \eta\,\gamma\,v_{t-1}) - \eta\,(\hat{g}_t + \gamma\,v_t) \\ &amp;= \hat{\theta}_t - \eta\,(\gamma\,v_t + \hat{g}_t) \end{align} \]</span> Discarding all <span class="math inline">\(\hat{ }\)</span> marks, we then get to the conclusion.</p><h4 id="convergence-analysis">Convergence Analysis</h4><p>This is a modified version of the above momentum SGD, which converges generally faster. <span class="citation" data-cites="BiMomentumGengKuaiJieKaiNesterovAccelerated">(“比Momentum更快：揭开Nesterov Accelerated Gradient的真面目,” <a href="#ref-BiMomentumGengKuaiJieKaiNesterovAccelerated" role="doc-biblioref">n.d.</a>)</span> suggests that this difference may be caused by the (approximately) second-order property of nesterov momentum SGD, since if we let: <span class="math display">\[ \begin{align} \hat{\theta}_t &amp;= \theta_t - \eta\,\gamma\,v_{t-1} \\ \hat{v}_t &amp;= \gamma^2 \,v_{t-1} + (\gamma + 1) \, g(\hat{\theta}_t) \end{align} \]</span> we can obtain the following iterative equations: <span class="math display">\[ \begin{align} \hat{v}_t &amp;= \gamma\,\hat{v}_{t-1} + g(\hat{\theta}_t) + \gamma\left[ g(\hat{\theta}_t) - g(\hat{\theta}_{t-1}) \right] \\ \hat{\theta}_{t+1} &amp;= \hat{\theta}_t - \eta \, \hat{v}_t \end{align} \]</span> which suggests the nesterov momentum SGD uses the second order gradient (approximated by <span class="math inline">\(g(\hat{\theta}_{t-1}) - g(\hat{\theta}_{t-2})\)</span>) to revise the trajectory produced by the first order gradient <span class="math inline">\(g(\hat{\theta}_{t-1})\)</span>.</p><p><em>Proof</em></p><p>From the original equation of nesterov momentum SGD, we have: <span class="math display">\[ \begin{align} \theta_{t+1} - \eta\,\gamma\,v_t &amp;= \theta_t - \eta\,(\gamma+1)\,v_t \\ &amp;= \theta_t - \eta\,(\gamma+1)\,\big( \gamma\,v_{t-1} + g(\theta_t - \eta\,\gamma\,v_{t-1}) \big) \\ &amp;= \theta_t - \eta\, \gamma\,v_{t-1} - \eta\,\gamma^2\,v_{t-1} - \eta\,(\gamma+1)\,g(\theta_t - \eta\,\gamma\,v_{t-1}) \end{align} \]</span> Substitute <span class="math inline">\(\hat{\theta}_t\)</span> and <span class="math inline">\(\hat{v}_t\)</span> into the above equation, we have: <span class="math display">\[ \hat{\theta}_{t+1} = \hat{\theta}_t - \eta \, \hat{v}_t \]</span> We then next deal with the term <span class="math inline">\(\hat{v}_t\)</span>. Substitute <span class="math inline">\(v_t\)</span>, we have: <span class="math display">\[ \begin{align} \hat{v}_t &amp;= (\gamma+1) \, g(\hat{\theta}_t) + \gamma^2\,v_{t-1} \\ &amp;= (\gamma+1) \, g(\hat{\theta}_t) + \gamma^2 \left( \gamma \, v_{t-2} + g(\hat{\theta}_{t-1})\right) \\ &amp;= (\gamma+1) \, g(\hat{\theta}_t) + \gamma^2 \, g(\hat{\theta}_{t-1}) + \gamma^3\left( \gamma\,v_{t-3} + g(\hat{\theta}_{t-2}) \right) \\ &amp;= (\gamma+1) \, g(\hat{\theta}_t) + \gamma^2 \, g(\hat{\theta}_{t-1}) + \gamma^3 \, g(\hat{\theta}_{t-2}) + \dots \\ \hat{v}_{t-1} &amp;= \qquad \qquad \quad \;\, (\gamma+1) \, g(\hat{\theta}_{t-1}) + \gamma^2 \, g(\hat{\theta}_{t-2}) + \dots \end{align} \]</span></p><p>Subtract <span class="math inline">\(\gamma \, \hat{v}_{t-1}\)</span> from <span class="math inline">\(\hat{v}_t\)</span>, we have: <span class="math display">\[ \hat{v}_t - \gamma\,\hat{v}_{t-1} = (\gamma+1) \, g(\hat{\theta}_t) - \gamma \, g(\hat{\theta}_{t-1}) \]</span> We thus obtain: <span class="math display">\[ \hat{v}_t = \gamma \, \hat{v}_{t-1} + g(\hat{\theta}_t) + \gamma\left[ g(\hat{\theta}_t) - g(\hat{\theta}_{t-1}) \right] \]</span></p><h3 id="adagrad">Adagrad</h3><p><span class="citation" data-cites="duchiAdaptiveSubgradientMethods2011">Duchi, Hazan, and Singer (<a href="#ref-duchiAdaptiveSubgradientMethods2011" role="doc-biblioref">2011</a>)</span> proposed a method, which adapts the learning rate according to the update rate of each parameter: for fast updating parameters, it uses smaller learning rate, and conversely, it uses larger learning rate. This mechanism is well suitable for sparse data <span class="citation" data-cites="OverviewGradientDescent2016">(“An Overview of Gradient Descent Optimization Algorithms” <a href="#ref-OverviewGradientDescent2016" role="doc-biblioref">2016</a>)</span>. <span class="math display">\[ \begin{align} G_t &amp;= \sum_{\tau=1}^t g_{\tau}^2 \\ \theta_{t+1} &amp;= \theta_t - \frac{\eta}{\sqrt{G_t + \epsilon}} \odot g_t \end{align} \]</span> where <span class="math inline">\(\odot\)</span> denotes the element-wise multiplication between two vectors. Here <span class="math inline">\(g_t^2 = g_t \odot g_t\)</span>, is the element-wise square of <span class="math inline">\(g_t\)</span>. <span class="math inline">\(G_t\)</span> is the sum of squares of all gradients of <span class="math inline">\(\theta\)</span> since the beginning of training. The small infinitesimal <span class="math inline">\(\epsilon\)</span> is adopted to avoid dividing by zero.</p><h3 id="adadelta">Adadelta</h3><p>To avoid having an infinitesimal learning rate as that of Adagrad, <span class="citation" data-cites="zeilerADADELTAAdaptiveLearning2012">Zeiler (<a href="#ref-zeilerADADELTAAdaptiveLearning2012" role="doc-biblioref">2012</a>)</span> proposed to use a exponential moving average to estimate the expectation of <span class="math inline">\(g_t^2\)</span> (denoted as <span class="math inline">\(E[g^2]\)</span>), instead of summing up all squares of gradients.</p><p>Also, it maintains the moving average for square of the term <span class="math inline">\(\Delta \theta\)</span> (i.e., the update of parameters at <span class="math inline">\(t\)</span>, denoted as <span class="math inline">\(E[\Delta\theta^2]\)</span>) to match the units of <span class="math inline">\(E[g^2]_t\)</span>. <span class="math display">\[ \begin{align} E[g^2]_t &amp;= \gamma \,E[g^2]_{t-1} + (1-\gamma) \,g_t^2 \\ E[\Delta\theta^2]_t &amp;= \gamma\,E[\Delta\theta^2]_{t-1} + (1-\gamma)\,(\Delta\theta_t)^2 \\ \mathop{RMS}[g]_t &amp;= \sqrt{E[g^2]_t + \epsilon} \\ RMS[\Delta\theta]_t &amp;= \sqrt{E[\Delta\theta^2]_t + \epsilon} \\ \Delta \theta_t &amp;= -\frac{RMS[\Delta\theta]_{t-1}}{RMS[g]_{t-1}} \odot g_t \\ \theta_{t+1} &amp;= \theta_t + \eta \,\Delta \theta_t \end{align} \]</span> where the learning rate <span class="math inline">\(\eta\)</span> is chosen to be 1 in the original paper.</p><h3 id="rmsprop">RMSprop</h3><p>Hinton proposed an unpublished SGD method based on Adagrad, also to avoid having an infinitesimal learning rate. (See <a href="http://www.cs.toronto.edu/~tijmen/csc321/slides/lecture_slides_lec6.pdf" target="_blank" rel="noopener">Lecture 6e of his Coursera Class</a>). <span class="math display">\[ \begin{align} E[g^2]_t &amp;= \gamma \,E[g^2]_{t-1} + (1-\gamma)\,g_t^2 \\ \theta_{t+1} &amp;= \theta_t - \frac{\eta}{\sqrt{E[g^2]_t + \epsilon}} \odot g_t \end{align} \]</span> with the denominator exactly the same as Adadelta. The moving average decay factor <span class="math inline">\(\gamma\)</span> is suggested to be 0.9, while the initial learning rate <span class="math inline">\(\eta\)</span> is suggested to be 0.001.</p><h3 id="adam">Adam</h3><p>In addition to tracking the moving average of squares of gradients, <span class="citation" data-cites="kingmaAdamMethodStochastic2017">Kingma and Ba (<a href="#ref-kingmaAdamMethodStochastic2017" role="doc-biblioref">2017</a>)</span> proposed to also track the moving average of the gradients. <span class="math display">\[ \begin{align} m_t &amp;= \beta_1 m_{t-1} + (1-\beta_1)\,g_t \\ v_t &amp;= \beta_2 v_{t-1} + (1-\beta_2)\,g_t^2 \\ \end{align} \]</span> The authors also proposed to apply a zero-debias term to the moving average estimates: <span class="math display">\[ \begin{align} \hat{m}_t &amp;= \frac{m_t}{1-\beta_1^t} \\ \hat{v}_t &amp;= \frac{v_t}{1-\beta_2^t} \end{align} \]</span> Then update the parameters accordingly: <span class="math display">\[ \theta_{t+1} = \theta_t - \frac{\eta}{\sqrt{\hat{v}_t} + \epsilon} \odot \hat{m}_t \]</span> By default, the hyper-parameters are suggested to be <span class="math inline">\(\beta_1 = 0.9\)</span>, <span class="math inline">\(\beta_2 = 0.999\)</span>, <span class="math inline">\(\epsilon = 10^{-8}\)</span>.</p><h3 id="adamax">Adamax</h3><p>As a variant of Adam, Adamax uses <span class="math inline">\(l_{\infty}\)</span> norm instead of <span class="math inline">\(l_2\)</span> norm for the denominator: <span class="math display">\[ \begin{align} m_t &amp;= \beta_1 m_{t-1} + (1-\beta_1)\,g_t \\ \hat{m}_t &amp;= \frac{m_t}{1-\beta_1^t} \\ u_t &amp;= \left( \beta_2^{\infty} \, u_{t-1}^{\infty} + (1-\beta_2^{\infty}) \,\left| g_t \right|^{\infty} \right)^{1/\infty} \\ &amp;= \max\left( \beta_2\,u_{t-1}, \left| g_t \right| \right) \\ \theta_{t+1} &amp;= \theta_t - \frac{\eta}{u_t} \, \hat{m}_t \end{align} \]</span> By default, the hyper-parameters are suggested to be <span class="math inline">\(\beta_1 = 0.9\)</span>, <span class="math inline">\(\beta_2 = 0.999\)</span>, <span class="math inline">\(\epsilon = 10^{-8}\)</span>.</p><h3 id="nadam">Nadam</h3><p><span class="citation" data-cites="dozatIncorporatingNesterovMomentum2016">Dozat (<a href="#ref-dozatIncorporatingNesterovMomentum2016" role="doc-biblioref">2016</a>)</span> incorporates Nesterov momentum into Adam.</p><p>Comparing the momentum method: <span class="math display">\[ \begin{align} v_t &amp;= \gamma \, v_{t-1} + g_t \\ \theta_{t+1} &amp;= \theta_t - \eta \,v_t \\ &amp;= \theta_t - \eta\,(\gamma\,v_{t-1} + g_t) \end{align} \]</span></p><p>with the “alternative form” of Nesterov Momentum method: <span class="math display">\[ \begin{align} v_t &amp;= \gamma \, v_{t-1} + g_t \\ \theta_{t+1} &amp;= \theta_t - \eta \, (\gamma \,v_t + g_t) \end{align} \]</span></p><p>It is clear that, we can obtain the Nesterov Momentum method by replacing <span class="math inline">\(v_{t-1}\)</span> with <span class="math inline">\(v_t\)</span> in the term <span class="math inline">\(\gamma\,v_{t-1} + g_t\)</span> in the Momentum method.</p><p>We then first seek to write Adam in such a form. Given that: <span class="math display">\[ \begin{align} m_t &amp;= \beta_1 m_{t-1} + (1-\beta_1)\,g_t \\ \hat{m}_t &amp;= \frac{m_t}{1-\beta_1^t} \end{align} \]</span> We have: <span class="math display">\[ \begin{align} \theta_{t+1} &amp;= \theta_t - \frac{\eta}{\sqrt{\hat{v}_t} + \epsilon} \odot \hat{m}_t \\ &amp;= \theta_t - \frac{\eta}{\sqrt{\hat{v}_t} + \epsilon} \odot \frac{m_t}{1-\beta_1^t} \\ &amp;= \theta_t - \frac{\eta}{\sqrt{\hat{v}_t} + \epsilon} \odot \left( \frac{\beta_1}{1-\beta_1^t} \cdot m_{t-1} + \frac{1-\beta_1}{1-\beta_1^t} \cdot g_t \right) \end{align} \]</span></p><p>If we consider <span class="math inline">\(m_{t-1}/(1-\beta_1^t) \approx m_{t-1}/(1-\beta_1^{t-1})\)</span>, which is true when <span class="math inline">\(t \to \infty\)</span>, we can obtain: <span class="math display">\[ \theta_{t+1} = \theta_t - \frac{\eta}{\sqrt{\hat{v}_t}+\epsilon}\odot \left( \beta_1\,\hat{m}_{t-1} + \frac{1-\beta_1}{1-\beta_1^t} \cdot g_t \right) \]</span> By replacing <span class="math inline">\(\hat{m}_{t-1}\)</span> with <span class="math inline">\(\hat{m}_t\)</span> as analogue to the Nesterov Momentum method, we finally obtain: <span class="math display">\[ \theta_{t+1} = \theta_t - \frac{\eta}{\sqrt{\hat{v}_t}+\epsilon}\odot \left( \beta_1\,\hat{m}_t + \frac{1-\beta_1}{1-\beta_1^t} \cdot g_t \right) \]</span></p><p>Note the <span class="math inline">\(\hat{v}_t\)</span> is not changed in Nadam. In summary, we get the following update equations for Nadam: <span class="math display">\[ \begin{align} v_t &amp;= \beta_2 v_{t-1} + (1-\beta_2)\,g_t^2 \\ \hat{v}_t &amp;= \frac{v_t}{1-\beta_2^t} \\ m_t &amp;= \beta_1 m_{t-1} + (1-\beta_1)\,g_t \\ \hat{m}_t &amp;= \frac{m_t}{1-\beta_1^t} \\ \theta_{t+1} &amp;= \theta_t - \frac{\eta}{\sqrt{\hat{v}_t}+\epsilon}\odot \left( \beta_1\,\hat{m}_t + \frac{1-\beta_1}{1-\beta_1^t} \cdot g_t \right) \end{align} \]</span></p><h3 id="amsgrad">AMSGrad</h3><p>The aggressive moving average strategy used by Adam may cause it hard to converge in some problems <span class="citation" data-cites="reddiConvergenceAdam2019">(Reddi, Kale, and Kumar <a href="#ref-reddiConvergenceAdam2019" role="doc-biblioref">2019</a>)</span>. AMSGrad is thus proposed as a modified version of Adam: <span class="math display">\[ \begin{align} m_t &amp;= \beta_1 m_{t-1} + (1-\beta_1)\,g_t \\ v_t &amp;= \beta_2 v_{t-1} + (1-\beta_2)\,g_t^2 \\ \hat{v}_t &amp;= \max(\hat{v}_{t-1}, v_t) \\ \theta_{t+1} &amp;= \theta_t - \frac{\eta}{\sqrt{\hat{v}_t} + \epsilon} \odot m_t \end{align} \]</span> The authors discarded the bias correction term <span class="math inline">\(1 / (1 - \beta_1^t)\)</span> and <span class="math inline">\(1 / (1 - \beta_2^t)\)</span> for simplicity. But in practice, some implementations may still consider this correction term, resulting in: <span class="math display">\[ \begin{align} m_t &amp;= \beta_1 m_{t-1} + (1-\beta_1)\,g_t \\ v_t &amp;= \beta_2 v_{t-1} + (1-\beta_2)\,g_t^2 \\ u_t &amp;= \max(u_{t-1}, v_t) \\ \hat{m}_t &amp;= \frac{m_t}{1 - \beta_1^t} \\ \hat{u}_t &amp;= \frac{u_t}{1 - \beta_2^t} \\ \theta_{t+1} &amp;= \theta_t - \frac{\eta}{\sqrt{\hat{u}_t} + \epsilon} \odot \hat{m}_t \end{align} \]</span></p><h1 id="bibliography" class="unnumbered">References</h1><div id="refs" class="references" role="doc-bibliography"><div id="ref-OverviewGradientDescent2016"><p>“An Overview of Gradient Descent Optimization Algorithms.” 2016. <em>Sebastian Ruder</em>. https://ruder.io/optimizing-gradient-descent/.</p></div><div id="ref-dozatIncorporatingNesterovMomentum2016"><p>Dozat, Timothy. 2016. “Incorporating Nesterov Momentum into Adam,” 4.</p></div><div id="ref-duchiAdaptiveSubgradientMethods2011"><p>Duchi, John, Elad Hazan, and Yoram Singer. 2011. “Adaptive Subgradient Methods for Online Learning and Stochastic Optimization.” <em>Journal of Machine Learning Research</em> 12 (61): 2121–59.</p></div><div id="ref-kingmaAdamMethodStochastic2017"><p>Kingma, Diederik P., and Jimmy Ba. 2017. “Adam: A Method for Stochastic Optimization.” <em>arXiv:1412.6980 [Cs]</em>, January. <a href="http://arxiv.org/abs/1412.6980" target="_blank" rel="noopener">http://arxiv.org/abs/1412.6980</a>.</p></div><div id="ref-reddiConvergenceAdam2019"><p>Reddi, Sashank J., Satyen Kale, and Sanjiv Kumar. 2019. “On the Convergence of Adam and Beyond.” <em>arXiv:1904.09237 [Cs, Math, Stat]</em>, April. <a href="http://arxiv.org/abs/1904.09237" target="_blank" rel="noopener">http://arxiv.org/abs/1904.09237</a>.</p></div><div id="ref-zeilerADADELTAAdaptiveLearning2012"><p>Zeiler, Matthew D. 2012. “ADADELTA: An Adaptive Learning Rate Method.” <em>arXiv:1212.5701 [Cs]</em>, December. <a href="http://arxiv.org/abs/1212.5701" target="_blank" rel="noopener">http://arxiv.org/abs/1212.5701</a>.</p></div><div id="ref-BiMomentumGengKuaiJieKaiNesterovAccelerated"><p>“比Momentum更快：揭开Nesterov Accelerated Gradient的真面目.” n.d. <em>知乎专栏</em>. https://zhuanlan.zhihu.com/p/22810533.</p></div></div></div><div style="height:10px"></div></div></article><nav id="article-nav"><a href="/Deep_Learning/Evaluation/Visualizing_High_Dimensional_Space/" id="article-nav-older" class="article-nav-link-wrap"><strong class="article-nav-caption">Older</strong><div class="article-nav-title">Visualizing High Dimensional Space</div></a></nav></section></div><footer id="footer"><div class="outer"><div id="footer-info" class="inner">Haowen Xu &copy; 2020 <a rel="license" href="http://creativecommons.org/licenses/by-nc-nd/4.0/"><img alt="Creative Commons License" style="border-width:0" src="/images/by-nc-nd-4.0-80x15.png"></a><br>Powered by <a href="http://hexo.io/" target="_blank">Hexo</a> &amp; theme <a href="https://github.com/zthxxx/hexo-theme-Wikitten">Wikitten</a></div></div></footer><script src="/libs/lightgallery/js/lightgallery.min.js"></script><script src="/libs/lightgallery/js/lg-thumbnail.min.js"></script><script src="/libs/lightgallery/js/lg-pager.min.js"></script><script src="/libs/lightgallery/js/lg-autoplay.min.js"></script><script src="/libs/lightgallery/js/lg-fullscreen.min.js"></script><script src="/libs/lightgallery/js/lg-zoom.min.js"></script><script src="/libs/lightgallery/js/lg-hash.min.js"></script><script src="/libs/lightgallery/js/lg-share.min.js"></script><script src="/libs/lightgallery/js/lg-video.min.js"></script><script src="/libs/justified-gallery/jquery.justifiedGallery.min.js"></script><script type="text/x-mathjax-config">MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ["$","$"], ["\\(","\\)"] ],
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
            processEscapes: true,
            TeX: {
                equationNumbers: {
                    autoNumber: 'AMS'
                },
                style: {
                    'font-family': 'serif'
                }
            }
        },
        'HTML-CSS': {
            //preferredFont: 'TeX',
            fonts: ['TeX']
        }
    });
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax();
        for (var i = 0; i < all.length; ++i)
            all[i].SourceElement().parentNode.className += ' has-jax';
    });</script><script async src="//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><script src="/js/main.js"></script></div></body>