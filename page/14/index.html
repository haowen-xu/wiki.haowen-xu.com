<!DOCTYPE html><html lang="en"><head><meta name="generator" content="Hexo 3.9.0"><meta charset="utf-8"><title>My Research Wiki</title><meta name="keywords" content="My Research Wiki"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=1"><meta property="og:type" content="website"><meta property="og:title" content="My Research Wiki"><meta property="og:url" content="https://wiki.haowen-xu.com/page/14/index.html"><meta property="og:site_name" content="My Research Wiki"><meta property="og:locale" content="en"><meta name="twitter:card" content="summary"><meta name="twitter:title" content="My Research Wiki"><link rel="alternate" href="/atom.xml" title="My Research Wiki" type="application/atom+xml"><link rel="icon" href="/favicon.ico"><link rel="stylesheet" href="/libs/font-awesome/css/font-awesome.min.css"><link rel="stylesheet" href="/libs/open-sans/styles.css"><link rel="stylesheet" href="/libs/source-code-pro/styles.css"><link rel="stylesheet" href="/css/style.css"><script src="/libs/jquery/2.1.3/jquery.min.js"></script><script src="/libs/jquery/plugins/cookie/1.4.1/jquery.cookie.js"></script><link rel="stylesheet" href="/libs/lightgallery/css/lightgallery.min.css"><link rel="stylesheet" href="/libs/justified-gallery/justifiedGallery.min.css"></head></html><body><div id="container"><header id="header"><div id="header-main" class="header-inner"><div class="outer"><a href="/" id="logo"><i class="logo"></i> <span class="site-title">My Research Wiki</span></a><nav id="main-nav"><a class="main-nav-link" href="/">Home</a> <a class="main-nav-link" href="/archives">Archives</a> <a class="main-nav-link" href="/categories">Categories</a></nav><div id="search-form-wrap"><form class="search-form"><input type="text" class="ins-search-input search-form-input" placeholder="Search"> <button type="submit" class="search-form-submit"></button></form><div class="ins-search"><div class="ins-search-mask"></div><div class="ins-search-container"><div class="ins-input-wrapper"><input type="text" class="ins-search-input" placeholder="Type something..."> <span class="ins-close ins-selectable"><i class="fa fa-times-circle"></i></span></div><div class="ins-section-wrapper"><div class="ins-section-container"></div></div></div></div><script>window.INSIGHT_CONFIG={TRANSLATION:{POSTS:"Posts",PAGES:"Pages",CATEGORIES:"Categories",TAGS:"Tags",UNTITLED:"(Untitled)"},ROOT_URL:"/",CONTENT_URL:"/content.json"}</script><script src="/js/insight.js"></script></div></div></div><div id="main-nav-mobile" class="header-sub header-inner"><table class="menu outer"><tr><td><a class="main-nav-link" href="/">Home</a></td><td><a class="main-nav-link" href="/archives">Archives</a></td><td><a class="main-nav-link" href="/categories">Categories</a></td><td><div class="search-form"><input type="text" class="ins-search-input search-form-input" placeholder="Search"></div></td></tr></table></div></header><div class="outer"><aside id="sidebar"><div class="widget-wrap" id="categories"><h3 class="widget-title"><span>categories</span> &nbsp; <a id="allExpand" href="#"><i class="fa fa-angle-double-down fa-2x"></i></a></h3><ul class="unstyled" id="tree"><li class="directory"><a href="#" data-role="directory"><i class="fa fa-folder"></i> &nbsp; Deep Learning</a><ul class="unstyled" id="tree"><li class="directory"><a href="#" data-role="directory"><i class="fa fa-folder"></i> &nbsp; CV</a><ul class="unstyled" id="tree"><li class="file"><a href="/Deep_Learning/CV/Image_Segmentation/">Image Segmentation</a></li></ul></li><li class="directory"><a href="#" data-role="directory"><i class="fa fa-folder"></i> &nbsp; Confronting Partition Function</a><ul class="unstyled" id="tree"><li class="file"><a href="/Deep_Learning/Confronting_Partition_Function/Overview/">Overview</a></li><li class="file"><a href="/Deep_Learning/Confronting_Partition_Function/Contrastive_Divergence/">Contrastive Divergence</a></li><li class="file"><a href="/Deep_Learning/Confronting_Partition_Function/Score_Matching/">Score Matching</a></li><li class="file"><a href="/Deep_Learning/Confronting_Partition_Function/Softmax_Speedup/">Softmax Speedup</a></li></ul></li><li class="directory"><a href="#" data-role="directory"><i class="fa fa-folder"></i> &nbsp; Energy Based Models</a><ul class="unstyled" id="tree"><li class="file"><a href="/Deep_Learning/Energy_Based_Models/Overview/">Overview</a></li><li class="file"><a href="/Deep_Learning/Energy_Based_Models/Energy_Function_in_Probabilistic_Models/">Energy Function in Probabilistic Models</a></li><li class="file"><a href="/Deep_Learning/Energy_Based_Models/Restricted_Boltzmann_Machine/">Restricted Boltzmann Machine</a></li></ul></li><li class="directory"><a href="#" data-role="directory"><i class="fa fa-folder"></i> &nbsp; Evaluation</a><ul class="unstyled" id="tree"><li class="file"><a href="/Deep_Learning/Evaluation/Evaluation_Metrics/">Evaluation Metrics</a></li><li class="file"><a href="/Deep_Learning/Evaluation/Visualizing_High_Dimensional_Space/">Visualizing High Dimensional Space</a></li></ul></li><li class="directory"><a href="#" data-role="directory"><i class="fa fa-folder"></i> &nbsp; Generative Adversarial Nets</a><ul class="unstyled" id="tree"><li class="file"><a href="/Deep_Learning/Generative_Adversarial_Nets/Overview/">Overview</a></li><li class="file"><a href="/Deep_Learning/Generative_Adversarial_Nets/f-GAN/">f-GAN</a></li><li class="file"><a href="/Deep_Learning/Generative_Adversarial_Nets/Energy_GAN/">Energy GAN</a></li></ul></li><li class="directory"><a href="#" data-role="directory"><i class="fa fa-folder"></i> &nbsp; Graph Neural Networks</a><ul class="unstyled" id="tree"><li class="file"><a href="/Deep_Learning/Graph_Neural_Networks/Node_Embedding/">Node Embedding</a></li><li class="file"><a href="/Deep_Learning/Graph_Neural_Networks/Graph_Convolution_Network/">Graph Convolution Network</a></li><li class="file"><a href="/Deep_Learning/Graph_Neural_Networks/Graph_Auto_Encoder/">Graph Auto-Encoder</a></li></ul></li><li class="directory"><a href="#" data-role="directory"><i class="fa fa-folder"></i> &nbsp; Information Theoretical</a><ul class="unstyled" id="tree"><li class="file"><a href="/Deep_Learning/Information_Theoretical/KL-Divergence/">KL-Divergence</a></li><li class="file"><a href="/Deep_Learning/Information_Theoretical/Mutual_Information/">Mutual Information</a></li></ul></li><li class="directory"><a href="#" data-role="directory"><i class="fa fa-folder"></i> &nbsp; Monte Carlo Methods</a><ul class="unstyled" id="tree"><li class="file"><a href="/Deep_Learning/Monte_Carlo_Methods/Overview/">Overview</a></li><li class="file"><a href="/Deep_Learning/Monte_Carlo_Methods/Monte_Carlo_Integration/">Monte Carlo Integration</a></li><li class="file"><a href="/Deep_Learning/Monte_Carlo_Methods/Accept_Reject_Sampling/">Accept-Reject Sampling</a></li><li class="file"><a href="/Deep_Learning/Monte_Carlo_Methods/Markov_Chain/">Markov Chain</a></li><li class="file"><a href="/Deep_Learning/Monte_Carlo_Methods/Metropolis_Hastings_Algorithm/">Metropolis-Hastings Algorithm</a></li><li class="file"><a href="/Deep_Learning/Monte_Carlo_Methods/Gibbs_Sampler/">Gibbs Sampler</a></li><li class="file"><a href="/Deep_Learning/Monte_Carlo_Methods/Hamiltonian_Dynamics/">Hamiltonian Dynamics</a></li><li class="file"><a href="/Deep_Learning/Monte_Carlo_Methods/Langevin_Dynamics/">Langevin Dynamics</a></li></ul></li><li class="directory"><a href="#" data-role="directory"><i class="fa fa-folder"></i> &nbsp; Optimization</a><ul class="unstyled" id="tree"><li class="file"><a href="/Deep_Learning/Optimization/Gradient_Tricks/">Gradient Tricks</a></li><li class="file"><a href="/Deep_Learning/Optimization/Loss_Surface_and_Generalization/">Loss Surface and Generalization</a></li><li class="file"><a href="/Deep_Learning/Optimization/Stochastic_Gradient_Descent/">Stochastic Gradient descent</a></li></ul></li><li class="directory"><a href="#" data-role="directory"><i class="fa fa-folder"></i> &nbsp; Variational Autoencoder</a><ul class="unstyled" id="tree"><li class="file"><a href="/Deep_Learning/Variational_Autoencoder/Overview/">Overview</a></li><li class="file"><a href="/Deep_Learning/Variational_Autoencoder/Sequential_VAE/">Sequential VAE</a></li><li class="file"><a href="/Deep_Learning/Variational_Autoencoder/Gradient_Estimators_for_Variational_Inference/">Gradient Estimators for Variational Inference</a></li><li class="file"><a href="/Deep_Learning/Variational_Autoencoder/Theoretical_Facts/">Theoretical Facts about VAEs</a></li></ul></li></ul></li><li class="directory"><a href="#" data-role="directory"><i class="fa fa-folder"></i> &nbsp; Mathematics</a><ul class="unstyled" id="tree"><li class="directory"><a href="#" data-role="directory"><i class="fa fa-folder"></i> &nbsp; Analysis</a><ul class="unstyled" id="tree"><li class="file"><a href="/Mathematics/Analysis/Linear_Space_vs_Functional_Space/">Linear space vs functional space</a></li></ul></li><li class="directory"><a href="#" data-role="directory"><i class="fa fa-folder"></i> &nbsp; Calculus</a><ul class="unstyled" id="tree"><li class="file"><a href="/Mathematics/Calculus/Calculus_of_Variations/">Calculus of Variations</a></li></ul></li><li class="directory"><a href="#" data-role="directory"><i class="fa fa-folder"></i> &nbsp; Differential Equations</a><ul class="unstyled" id="tree"><li class="file"><a href="/Mathematics/Differential_Equations/Probability_Distribution_Equations/">Differential Equations on Probability Distributions</a></li></ul></li><li class="directory"><a href="#" data-role="directory"><i class="fa fa-folder"></i> &nbsp; Optimization</a><ul class="unstyled" id="tree"><li class="file"><a href="/Mathematics/Optimization/Convex_Optimization/">Convex Optimization</a></li></ul></li></ul></li><li class="directory"><a href="#" data-role="directory"><i class="fa fa-folder"></i> &nbsp; Research Work</a><ul class="unstyled" id="tree"><li class="file"><a href="/Research_Work/Reading_List/">Reading List</a></li><li class="file"><a href="/Research_Work/Tracking_the_Concepts/">Tracking the Concepts</a></li><li class="file"><a href="/Research_Work/Directions_to_Explore/">Directions to Explore</a></li></ul></li></ul></div><script>$(document).ready(function(){var r="fa-folder-open",i="fa-folder",l="fa-angle-double-down",d="fa-angle-double-up";$(document).on("click",'#categories a[data-role="directory"]',function(a){a.preventDefault();var e=$(this).children(".fa"),s=e.hasClass(r),l=$(this).siblings("ul");e.removeClass(r).removeClass(i),s?(void 0!==l&&l.slideUp({duration:100}),e.addClass(i)):(void 0!==l&&l.slideDown({duration:100}),e.addClass(r))}),$('#categories a[data-role="directory"]').bind("contextmenu",function(a){a.preventDefault();var e=$(this).children(".fa"),s=e.hasClass(r),l=$(this).siblings("ul"),d=$.merge(l.find("li ul"),l),o=$.merge(l.find(".fa"),e);o.removeClass(r).removeClass(i),s?(d.slideUp({duration:100}),o.addClass(i)):(d.slideDown({duration:100}),o.addClass(r))}),$(document).on("click","#allExpand",function(a){a.preventDefault();var e=$(this).children(".fa"),s=e.hasClass(l);e.removeClass(l).removeClass(d),s?($("#sidebar .fa.fa-folder").removeClass("fa-folder").addClass("fa-folder-open"),$("#categories li ul").slideDown({duration:100}),e.addClass(d)):($("#sidebar .fa.fa-folder-open").removeClass("fa-folder-open").addClass("fa-folder"),$("#categories li ul").slideUp({duration:100}),e.addClass(l))})})</script><div id="toTop" class="fa fa-angle-up"></div></aside><section id="main"><article id="post-Deep_Learning/Variational_Autoencoder/Gradient_Estimators_for_Variational_Inference" class="article article-type-post" itemscope itemprop="blogPost"><div class="article-inner"><header class="article-header"><div class="article-meta"><div class="article-category"><i class="fa fa-folder"></i> <a class="article-category-link" href="/categories/Deep-Learning/">Deep Learning</a><i class="fa fa-angle-right"></i><a class="article-category-link" href="/categories/Deep-Learning/Variational-Autoencoder/">Variational Autoencoder</a></div><div class="article-date"><i class="fa fa-calendar"></i> <a href="/Deep_Learning/Variational_Autoencoder/Gradient_Estimators_for_Variational_Inference/"><time datetime="2018-08-21T08:41:00.000Z" itemprop="datePublished">2018-08-21</time></a></div><div class="article-meta-button"><a href="https://github.com/haowen-xu/research-notes/raw/master/source/_posts/Deep_Learning/Variational_Autoencoder/Gradient_Estimators_for_Variational_Inference.md">Source</a></div><div class="article-meta-button"><a href="https://github.com/haowen-xu/research-notes/edit/master/source/_posts/Deep_Learning/Variational_Autoencoder/Gradient_Estimators_for_Variational_Inference.md">Edit</a></div><div class="article-meta-button"><a href="https://github.com/haowen-xu/research-notes/commits/master/source/_posts/Deep_Learning/Variational_Autoencoder/Gradient_Estimators_for_Variational_Inference.md">History</a></div></div><h1 itemprop="name"><a class="article-title" href="/Deep_Learning/Variational_Autoencoder/Gradient_Estimators_for_Variational_Inference/">Gradient Estimators for Variational Inference</a></h1></header><div class="article-entry" itemprop="articleBody"><p>In complex <em>Bayesian networks</em>, especially for <em>deep Bayesian networks</em>, it is often computational intractable to compute some “posterior distributions” (typically along the opposite directions of links, for example, <span class="math inline">\(p_{\theta}(\mathbf{z}|\mathbf{x})\)</span> in the main network of the right figure). These posteriors are often required in both training and testing. In such cases, <em>variational inference</em> techniques are often adopted, to approximate the intractable posterior by another network (e.g., <span class="math inline">\(q_{\phi}(\mathbf{z}|\mathbf{x})\)</span> to approximate <span class="math inline">\(p_{\theta}(\mathbf{z}|\mathbf{x})\)</span> in the right figure). Such “other networks” are often called the “variational networks” or “inference networks”.</p><p>Note that also we only present a very basic form of Bayesian networks in this page (<em>i.e.</em>, having just one visible variable <span class="math inline">\(\mathbf{x}\)</span> and one latent variable <span class="math inline">\(\mathbf{z}\)</span>), the formula of this page can be extended to multiple visible and latent variables easily, by treating all visible variables as <span class="math inline">\(\mathbf{x}\)</span> and all latent variables as <span class="math inline">\(\mathbf{z}\)</span>.</p><h2 id="variational-lower-bounds">Variational Lower Bounds</h2><p>When training a Bayesian network using variational inference, the state-of-the-arts technique is to construct a lower bound <span class="math inline">\(\mathcal{L}(\mathbf{x};\theta,\phi)\)</span> for <span class="math inline">\(\log p_{\theta}(\mathbf{x})\)</span>. When maximizing <span class="math inline">\(\mathbb{E}_{\mathbf{x}\sim p_{data}(\mathbf{x})}\left[\mathcal{L}(\mathbf{x};\theta,\phi)\right]\)</span> , it simultaneously do the following two things: (1) maximize the joint log-likelihood <span class="math inline">\(\mathbb{E}_{\mathbf{x} \sim p_{data}(\mathbf{x}),\mathbf{z}\sim p_{\theta}(\mathbf{z})}\left[\log p_{\theta}(\mathbf{x},\mathbf{z})\right]\)</span>, and (2) let <span class="math inline">\(q_{\phi}(\mathbf{z}|\mathbf{x})\)</span> to approximate <span class="math inline">\(p_{\theta}(\mathbf{z}|\mathbf{x})\)</span>.</p><h3 id="evidence-lower-bound-elbo">Evidence Lower Bound (ELBO)</h3><p>The “Evidence Lower Bound” <span class="math inline">\(\mathcal{L}(\mathbf{x};\theta,\phi)\)</span> is deduced by:</p><p><span class="math display">\[ \begin{aligned} \log p_{\theta}(\mathbf{x}) &amp;\geq \log p_{\theta}(\mathbf{x}) - \operatorname{D}_{KL}\big[ q_{\phi}(\mathbf{z}|\mathbf{x})\|p_{\theta}(\mathbf{z}|\mathbf{x}) \big] \\ &amp;= \mathbb{E}_{\mathbf{z} \sim q_{\phi}(\mathbf{z}|\mathbf{x})}\big[ \log p_{\theta}(\mathbf{x}) + \log p_{\theta}(\mathbf{z}|\mathbf{x}) - \log q_{\phi}(\mathbf{z}|\mathbf{x}) \big] \\ &amp;= \mathbb{E}_{\mathbf{z} \sim q_{\phi}(\mathbf{z}|\mathbf{x})}\big[ \log p_{\theta}(\mathbf{x},\mathbf{z}) - \log q_{\phi}(\mathbf{z}|\mathbf{x}) \big] \\ &amp;= \mathcal{L}(\mathbf{x};\theta,\phi) \end{aligned} \]</span></p><h3 id="monte-carlo-objective">Monte Carlo Objective</h3><p>The “Monto Carlo Objective” is an <a href="/Deep_Learning/Monte_Carlo_Methods/Monte_Carlo_Integration/#sec:importance_sampling">importance sampling</a> based variational lower-bound, given by:</p><p><span class="math display">\[ \mathcal{L}_{K}(\mathbf{x};\theta,\phi) = \mathbb{E}_{\mathbf{z}^{(1:K)} \sim q_{\phi}(\mathbf{z}|\mathbf{x})}\Bigg[ \log \frac{1}{K} \sum_{k=1}^K { \frac{p_{\theta}(\mathbf{x},\mathbf{z}^{(k)})} {q_{\phi}(\mathbf{z}^{(k)}|\mathbf{x})} } \Bigg] \]</span></p><p>where <span class="math inline">\(\mathbf{z}^{(1:K)}\)</span> are <span class="math inline">\(K\)</span> independent samples of <span class="math inline">\(\mathbf{z}\)</span> from <span class="math inline">\(q_{\phi}(\mathbf{z}|\mathbf{x})\)</span>. It is proven by <span class="citation" data-cites="burdaImportanceWeightedAutoencoders2015">Burda, Grosse, and Salakhutdinov (<a href="#ref-burdaImportanceWeightedAutoencoders2015" role="doc-biblioref">2015</a>)</span> that:</p><p><span class="math display">\[ \log p_{\theta}(\mathbf{x}) \geq \mathcal{L}_K(\theta,\phi) \geq \mathcal{L}_M(\theta,\phi)$ for $K \geq M$, and $\lim_{K \to \infty} \mathcal{L}_K (\theta,\phi) = \log p_{\theta}(\mathbf{x}) \]</span></p><h2 id="gradient-estimators">Gradient Estimators</h2><p>To optimize a variational lower bound, especially for deep Bayesian networks, <a href="/Deep_Learning/Optimization/Stochastic_Gradient_Descent/">stochastic gradient descent</a> is often adopted. However, it is not straightforward to compute the gradient of an expectation. The gradient estimators thus serve to compute the gradients for the variational lower bounds.</p><p>For simplicity, we shall omit the subscripts in this section, thus the gradient operator <span class="math inline">\(\nabla\)</span> should be applied on both <span class="math inline">\(\theta\)</span> and <span class="math inline">\(\phi\)</span>, and <span class="math inline">\(f(\mathbf{x},\mathbf{z})\)</span> should have both two sets of parameters.</p><h3 id="sgvb">SGVB</h3><p><span class="citation" data-cites="kingmaAutoEncodingVariationalBayes2014">Kingma and Welling (<a href="#ref-kingmaAutoEncodingVariationalBayes2014" role="doc-biblioref">2014</a>)</span> proposes that, if <span class="math inline">\(\mathbf{z}\)</span> can be <em>reparameterized</em> by <span class="math inline">\(\mathbf{z} = \mathbf{z}(\epsilon)\)</span>, where <span class="math inline">\(\mathbf{\epsilon}\)</span> is another random variable independent of <span class="math inline">\(\theta\)</span> and <span class="math inline">\(\phi\)</span>, and <span class="math inline">\(\mathbf{z}(\mathbf{\epsilon})\)</span> is a continuous, differentiable mapping, then the gradient estimator for <span class="math inline">\(\mathcal{L}(\mathbf{x};\theta,\phi)=\mathbb{E}_{q(\mathbf{z}|\mathbf{x})}\big[f(\mathbf{x},\mathbf{z})\big]\)</span> is given by:</p><p><span class="math display">\[ \nabla \, \mathbb{E}_{q(\mathbf{z}|\mathbf{x})}\big[f(\mathbf{x},\mathbf{z})\big] = \nabla \, \mathbb{E}_{q(\mathbf{\epsilon})}\big[f(\mathbf{x},\mathbf{z}(\mathbf{\epsilon}))\big] = \mathbb{E}_{q(\mathbf{\epsilon})}\big[\nabla f(\mathbf{x},\mathbf{z}(\mathbf{\epsilon}))\big] \]</span></p><h3 id="iwae">IWAE</h3><p><span class="citation" data-cites="burdaImportanceWeightedAutoencoders2015">Burda, Grosse, and Salakhutdinov (<a href="#ref-burdaImportanceWeightedAutoencoders2015" role="doc-biblioref">2015</a>)</span> extends SGVB to the Monte Carlo objective. Let <span class="math inline">\(w_k = f\big(\mathbf{x},\mathbf{z}(\mathbf{\epsilon}^{(k)})\big)\)</span>, and <span class="math inline">\(\widetilde{w}_k = w_k / \sum_{i=1}^K w_i\)</span>, the gradient estimator for <span class="math inline">\(\mathcal{L}_K(\mathbf{x};\theta,\phi)=\mathbb{E}_{q(\mathbf{z}^{(1:K)}|\mathbf{x})}\Big[\log \frac{1}{K} \sum_{k=1}^K f\big(\mathbf{x},\mathbf{z}^{(k)}\big)\Big]\)</span> is deduced by:</p><p><span class="math display">\[ \begin{aligned} &amp;\nabla\,\mathbb{E}_{q(\mathbf{z}^{(1:K)}|\mathbf{x})}\Big[\log \frac{1}{K} \sum_{k=1}^K f\big(\mathbf{x},\mathbf{z}^{(k)}\big)\Big] = \nabla \, \mathbb{E}_{q(\mathbf{\epsilon}^{(1:K)})}\Bigg[\log \frac{1}{K} \sum_{k=1}^K w_k\Bigg] = \mathbb{E}_{q(\mathbf{\epsilon}^{(1:K)})}\Bigg[\nabla \log \frac{1}{K} \sum_{k=1}^K w_k\Bigg] = \\ &amp; \quad \mathbb{E}_{q(\mathbf{\epsilon}^{(1:K)})}\Bigg[\frac{\nabla \frac{1}{K} \sum_{k=1}^K w_k}{\frac{1}{K} \sum_{i=1}^K w_i}\Bigg] = \mathbb{E}_{q(\mathbf{\epsilon}^{(1:K)})}\Bigg[\frac{\sum_{k=1}^K w_k \nabla \log w_k}{\sum_{i=1}^K w_i}\Bigg] = \mathbb{E}_{q(\mathbf{\epsilon}^{(1:K)})}\Bigg[\sum_{k=1}^K \widetilde{w}_k \nabla \log w_k\Bigg] \end{aligned} \]</span></p><h3 id="nvil">NVIL</h3><p><span class="citation" data-cites="mnihNeuralVariationalInference2014">Mnih and Gregor (<a href="#ref-mnihNeuralVariationalInference2014" role="doc-biblioref">2014</a>)</span> proposes a variant of <span class="dangling-link">REINFORCE</span>, choosing the gradient estimator for <span class="math inline">\(\mathcal{L}(\mathbf{x};\theta,\phi)=\mathbb{E}_{q(\mathbf{z}|\mathbf{x})}\big[f(\mathbf{x},\mathbf{z})\big]\)</span> as:</p><p><span class="math display">\[ \begin{aligned} \nabla \, \mathbb{E}_{q(\mathbf{z}|\mathbf{x})} \big[f(\mathbf{x},\mathbf{z})\big] &amp;= \mathbb{E}_{q(\mathbf{z}|\mathbf{x})}\Big[ \nabla f(\mathbf{x},\mathbf{z}) + f(\mathbf{x},\mathbf{z})\,\nabla\log q(\mathbf{z}|\mathbf{x})\Big] \\ &amp;= \mathbb{E}_{q(\mathbf{z}|\mathbf{x})}\Big[ \nabla f(\mathbf{x},\mathbf{z}) + \big(f(\mathbf{x},\mathbf{z}) - C_{\psi}(\mathbf{x})-c\big)\,\nabla\log q(\mathbf{z}|\mathbf{x})\Big] \end{aligned} \]</span></p><p><span class="math inline">\(C_{\psi}(\mathbf{x})\)</span> is a learnable network with parameter <span class="math inline">\(\psi\)</span>, and <span class="math inline">\(c\)</span> is a learnable constant. They should be learnt by minimizing <span class="math inline">\(\mathbb{E}_{ q(\mathbf{z}|\mathbf{x}) }\Big[\big(f(\mathbf{x},\mathbf{z}) - C_{\psi}(\mathbf{x})-c\big)^2 \Big]\)</span>, leading to the gradient estimator for <span class="math inline">\(\psi\)</span>:</p><p><span class="math display">\[ \nabla_{\psi} \, \mathbb{E}_{q(\mathbf{z}|\mathbf{x})}\Big[\big(f(\mathbf{x},\mathbf{z})-C_{\psi}(\mathbf{x})-c\big)^2\Big] = \mathbb{E}_{q(\mathbf{z}|\mathbf{x})}\Big[-2\, \big(f(\mathbf{x},\mathbf{z})-C_{\psi}(\mathbf{x})-c\big) \, \nabla_{\psi} \, C_{\psi}(\mathbf{x})\Big] \]</span></p><p>The NVIL algorithm glues these two objectives together with a proper coefficient, and performs SGD on them together.</p><h3 id="vimco">VIMCO</h3><p><span class="citation" data-cites="mnihVariationalInferenceMonte2016">Mnih and Rezende (<a href="#ref-mnihVariationalInferenceMonte2016" role="doc-biblioref">2016</a>)</span> suggests to use the unrelated samples of the Monte Carlo objective, instead of the dedicated learnable <span class="math inline">\(C_{\psi}(\mathbf{x})\)</span> and <span class="math inline">\(c\)</span>, to centralize the learning signals. The VIMCO gradient estimator for <span class="math inline">\(\mathcal{L}_K(\mathbf{x};\theta,\phi)=\mathbb{E}_{q(\mathbf{z}^{(1:K)}|\mathbf{x})}\Big[\log \frac{1}{K} \sum_{k=1}^K f\big(\mathbf{x},\mathbf{z}^{(k)}\big)\Big]\)</span> is deduced by:</p><p><span class="math display">\[ \begin{aligned} &amp;\nabla\,\mathbb{E}_{q(\mathbf{z}^{(1:K)}|\mathbf{x})}\Big[\log \frac{1}{K} \sum_{k=1}^K f\big(\mathbf{x},\mathbf{z}^{(k)}\big)\Big] \\ &amp;\quad = \mathbb{E}_{q(\mathbf{z}^{(1:K)}|\mathbf{x})}\bigg[{\sum_{k=1}^K \hat{L}(\mathbf{z}^{(k)}|\mathbf{z}^{(-k)}) \, \nabla \log q(\mathbf{z}^{(k)}|\mathbf{x})}\bigg] + \mathbb{E}_{q(\mathbf{z}^{(1:K)}|\mathbf{x})}\bigg[{\sum_{k=1}^K \widetilde{w}_k\,\nabla\log f(\mathbf{x},\mathbf{z}^{(k)})}\bigg] \end{aligned} \]</span></p><p>where <span class="math inline">\(w_k = f\big(\mathbf{x},\mathbf{z}^{(k)}\big)\)</span>, <span class="math inline">\(\widetilde{w}_k = w_k / \sum_{i=1}^K w_i\)</span>, and:</p><p><span class="math display">\[ \begin{aligned} \hat{L}(\mathbf{z}^{(k)}|\mathbf{z}^{(-k)}) &amp;= \hat{L}(\mathbf{z}^{(1:K)}) - \log \frac{1}{K} \bigg(\hat{f}(\mathbf{x},\mathbf{z}^{(-k)})+\sum_{i \neq k} f(\mathbf{x},\mathbf{z}^{(i)})\bigg) \\ \hat{L}(\mathbf{z}^{(1:K)}) &amp;= \log \frac{1}{K} \sum_{k=1}^K f(\mathbf{x},\mathbf{z}^{(k)}) \\ \hat{f}(\mathbf{x},\mathbf{z}^{(-k)}) &amp;= \exp\big(\frac{1}{K-1} \sum_{i \neq k} \log f(\mathbf{x},\mathbf{z}^{(i)})\big) \end{aligned} \]</span></p><h1 id="bibliography" class="unnumbered">References</h1><div id="refs" class="references" role="doc-bibliography"><div id="ref-burdaImportanceWeightedAutoencoders2015"><p>Burda, Yuri, Roger Grosse, and Ruslan Salakhutdinov. 2015. “Importance Weighted Autoencoders.” <em>arXiv Preprint arXiv:1509.00519</em>.</p></div><div id="ref-kingmaAutoEncodingVariationalBayes2014"><p>Kingma, Diederik P, and Max Welling. 2014. “Auto-Encoding Variational Bayes.” In <em>Proceedings of the International Conference on Learning Representations</em>.</p></div><div id="ref-mnihNeuralVariationalInference2014"><p>Mnih, Andriy, and Karol Gregor. 2014. “Neural Variational Inference and Learning in Belief Networks.” <em>arXiv Preprint arXiv:1402.0030</em>.</p></div><div id="ref-mnihVariationalInferenceMonte2016"><p>Mnih, Andriy, and Danilo Rezende. 2016. “Variational Inference for Monte Carlo Objectives.” In <em>PMLR</em>, 2188–96.</p></div></div></div><div style="height:10px"></div></div></article><nav id="page-nav"><a class="extend prev" rel="prev" href="/page/13/">&laquo; Prev</a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/12/">12</a><a class="page-number" href="/page/13/">13</a><span class="page-number current">14</span></nav></section></div><footer id="footer"><div class="outer"><div id="footer-info" class="inner">Haowen Xu &copy; 2020 <a rel="license" href="http://creativecommons.org/licenses/by-nc-nd/4.0/"><img alt="Creative Commons License" style="border-width:0" src="/images/by-nc-nd-4.0-80x15.png"></a><br>Powered by <a href="http://hexo.io/" target="_blank">Hexo</a> &amp; theme <a href="https://github.com/zthxxx/hexo-theme-Wikitten">Wikitten</a></div></div></footer><script src="/libs/lightgallery/js/lightgallery.min.js"></script><script src="/libs/lightgallery/js/lg-thumbnail.min.js"></script><script src="/libs/lightgallery/js/lg-pager.min.js"></script><script src="/libs/lightgallery/js/lg-autoplay.min.js"></script><script src="/libs/lightgallery/js/lg-fullscreen.min.js"></script><script src="/libs/lightgallery/js/lg-zoom.min.js"></script><script src="/libs/lightgallery/js/lg-hash.min.js"></script><script src="/libs/lightgallery/js/lg-share.min.js"></script><script src="/libs/lightgallery/js/lg-video.min.js"></script><script src="/libs/justified-gallery/jquery.justifiedGallery.min.js"></script><script type="text/x-mathjax-config">MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ["$","$"], ["\\(","\\)"] ],
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
            processEscapes: true,
            TeX: {
                equationNumbers: {
                    autoNumber: 'AMS'
                },
                style: {
                    'font-family': 'serif'
                }
            }
        },
        'HTML-CSS': {
            //preferredFont: 'TeX',
            fonts: ['TeX']
        }
    });
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax();
        for (var i = 0; i < all.length; ++i)
            all[i].SourceElement().parentNode.className += ' has-jax';
    });</script><script async src="//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><script src="/js/main.js"></script></div></body>