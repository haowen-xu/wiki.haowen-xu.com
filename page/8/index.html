<!DOCTYPE html><html lang="en"><head><meta name="generator" content="Hexo 3.9.0"><meta charset="utf-8"><title>My Research Wiki</title><meta name="keywords" content="My Research Wiki"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=1"><meta property="og:type" content="website"><meta property="og:title" content="My Research Wiki"><meta property="og:url" content="https://wiki.haowen-xu.com/page/8/index.html"><meta property="og:site_name" content="My Research Wiki"><meta property="og:locale" content="en"><meta name="twitter:card" content="summary"><meta name="twitter:title" content="My Research Wiki"><link rel="alternate" href="/atom.xml" title="My Research Wiki" type="application/atom+xml"><link rel="icon" href="/favicon.ico"><link rel="stylesheet" href="/libs/font-awesome/css/font-awesome.min.css"><link rel="stylesheet" href="/libs/open-sans/styles.css"><link rel="stylesheet" href="/libs/source-code-pro/styles.css"><link rel="stylesheet" href="/css/style.css"><script src="/libs/jquery/2.1.3/jquery.min.js"></script><script src="/libs/jquery/plugins/cookie/1.4.1/jquery.cookie.js"></script><link rel="stylesheet" href="/libs/lightgallery/css/lightgallery.min.css"><link rel="stylesheet" href="/libs/justified-gallery/justifiedGallery.min.css"></head></html><body><div id="container"><header id="header"><div id="header-main" class="header-inner"><div class="outer"><a href="/" id="logo"><i class="logo"></i> <span class="site-title">My Research Wiki</span></a><nav id="main-nav"><a class="main-nav-link" href="/">Home</a> <a class="main-nav-link" href="/archives">Archives</a> <a class="main-nav-link" href="/categories">Categories</a></nav><div id="search-form-wrap"><form class="search-form"><input type="text" class="ins-search-input search-form-input" placeholder="Search"> <button type="submit" class="search-form-submit"></button></form><div class="ins-search"><div class="ins-search-mask"></div><div class="ins-search-container"><div class="ins-input-wrapper"><input type="text" class="ins-search-input" placeholder="Type something..."> <span class="ins-close ins-selectable"><i class="fa fa-times-circle"></i></span></div><div class="ins-section-wrapper"><div class="ins-section-container"></div></div></div></div><script>window.INSIGHT_CONFIG={TRANSLATION:{POSTS:"Posts",PAGES:"Pages",CATEGORIES:"Categories",TAGS:"Tags",UNTITLED:"(Untitled)"},ROOT_URL:"/",CONTENT_URL:"/content.json"}</script><script src="/js/insight.js"></script></div></div></div><div id="main-nav-mobile" class="header-sub header-inner"><table class="menu outer"><tr><td><a class="main-nav-link" href="/">Home</a></td><td><a class="main-nav-link" href="/archives">Archives</a></td><td><a class="main-nav-link" href="/categories">Categories</a></td><td><div class="search-form"><input type="text" class="ins-search-input search-form-input" placeholder="Search"></div></td></tr></table></div></header><div class="outer"><aside id="sidebar"><div class="widget-wrap" id="categories"><h3 class="widget-title"><span>categories</span> &nbsp; <a id="allExpand" href="#"><i class="fa fa-angle-double-down fa-2x"></i></a></h3><ul class="unstyled" id="tree"><li class="directory"><a href="#" data-role="directory"><i class="fa fa-folder"></i> &nbsp; Deep Learning</a><ul class="unstyled" id="tree"><li class="directory"><a href="#" data-role="directory"><i class="fa fa-folder"></i> &nbsp; CV</a><ul class="unstyled" id="tree"><li class="file"><a href="/Deep_Learning/CV/Image_Segmentation/">Image Segmentation</a></li></ul></li><li class="directory"><a href="#" data-role="directory"><i class="fa fa-folder"></i> &nbsp; Confronting Partition Function</a><ul class="unstyled" id="tree"><li class="file"><a href="/Deep_Learning/Confronting_Partition_Function/Overview/">Overview</a></li><li class="file"><a href="/Deep_Learning/Confronting_Partition_Function/Contrastive_Divergence/">Contrastive Divergence</a></li><li class="file"><a href="/Deep_Learning/Confronting_Partition_Function/Score_Matching/">Score Matching</a></li><li class="file"><a href="/Deep_Learning/Confronting_Partition_Function/Softmax_Speedup/">Softmax Speedup</a></li></ul></li><li class="directory"><a href="#" data-role="directory"><i class="fa fa-folder"></i> &nbsp; Energy Based Models</a><ul class="unstyled" id="tree"><li class="file"><a href="/Deep_Learning/Energy_Based_Models/Overview/">Overview</a></li><li class="file"><a href="/Deep_Learning/Energy_Based_Models/Energy_Function_in_Probabilistic_Models/">Energy Function in Probabilistic Models</a></li><li class="file"><a href="/Deep_Learning/Energy_Based_Models/Restricted_Boltzmann_Machine/">Restricted Boltzmann Machine</a></li></ul></li><li class="directory"><a href="#" data-role="directory"><i class="fa fa-folder"></i> &nbsp; Evaluation</a><ul class="unstyled" id="tree"><li class="file"><a href="/Deep_Learning/Evaluation/Evaluation_Metrics/">Evaluation Metrics</a></li><li class="file"><a href="/Deep_Learning/Evaluation/Visualizing_High_Dimensional_Space/">Visualizing High Dimensional Space</a></li></ul></li><li class="directory"><a href="#" data-role="directory"><i class="fa fa-folder"></i> &nbsp; Generative Adversarial Nets</a><ul class="unstyled" id="tree"><li class="file"><a href="/Deep_Learning/Generative_Adversarial_Nets/Overview/">Overview</a></li><li class="file"><a href="/Deep_Learning/Generative_Adversarial_Nets/f-GAN/">f-GAN</a></li><li class="file"><a href="/Deep_Learning/Generative_Adversarial_Nets/Energy_GAN/">Energy GAN</a></li></ul></li><li class="directory"><a href="#" data-role="directory"><i class="fa fa-folder"></i> &nbsp; Graph Neural Networks</a><ul class="unstyled" id="tree"><li class="file"><a href="/Deep_Learning/Graph_Neural_Networks/Node_Embedding/">Node Embedding</a></li><li class="file"><a href="/Deep_Learning/Graph_Neural_Networks/Graph_Convolution_Network/">Graph Convolution Network</a></li><li class="file"><a href="/Deep_Learning/Graph_Neural_Networks/Graph_Auto_Encoder/">Graph Auto-Encoder</a></li></ul></li><li class="directory"><a href="#" data-role="directory"><i class="fa fa-folder"></i> &nbsp; Information Theoretical</a><ul class="unstyled" id="tree"><li class="file"><a href="/Deep_Learning/Information_Theoretical/KL-Divergence/">KL-Divergence</a></li><li class="file"><a href="/Deep_Learning/Information_Theoretical/Mutual_Information/">Mutual Information</a></li></ul></li><li class="directory"><a href="#" data-role="directory"><i class="fa fa-folder"></i> &nbsp; Monte Carlo Methods</a><ul class="unstyled" id="tree"><li class="file"><a href="/Deep_Learning/Monte_Carlo_Methods/Overview/">Overview</a></li><li class="file"><a href="/Deep_Learning/Monte_Carlo_Methods/Monte_Carlo_Integration/">Monte Carlo Integration</a></li><li class="file"><a href="/Deep_Learning/Monte_Carlo_Methods/Accept_Reject_Sampling/">Accept-Reject Sampling</a></li><li class="file"><a href="/Deep_Learning/Monte_Carlo_Methods/Markov_Chain/">Markov Chain</a></li><li class="file"><a href="/Deep_Learning/Monte_Carlo_Methods/Metropolis_Hastings_Algorithm/">Metropolis-Hastings Algorithm</a></li><li class="file"><a href="/Deep_Learning/Monte_Carlo_Methods/Gibbs_Sampler/">Gibbs Sampler</a></li><li class="file"><a href="/Deep_Learning/Monte_Carlo_Methods/Hamiltonian_Dynamics/">Hamiltonian Dynamics</a></li><li class="file"><a href="/Deep_Learning/Monte_Carlo_Methods/Langevin_Dynamics/">Langevin Dynamics</a></li></ul></li><li class="directory"><a href="#" data-role="directory"><i class="fa fa-folder"></i> &nbsp; Optimization</a><ul class="unstyled" id="tree"><li class="file"><a href="/Deep_Learning/Optimization/Gradient_Tricks/">Gradient Tricks</a></li><li class="file"><a href="/Deep_Learning/Optimization/Loss_Surface_and_Generalization/">Loss Surface and Generalization</a></li><li class="file"><a href="/Deep_Learning/Optimization/Stochastic_Gradient_Descent/">Stochastic Gradient descent</a></li></ul></li><li class="directory"><a href="#" data-role="directory"><i class="fa fa-folder"></i> &nbsp; Variational Autoencoder</a><ul class="unstyled" id="tree"><li class="file"><a href="/Deep_Learning/Variational_Autoencoder/Overview/">Overview</a></li><li class="file"><a href="/Deep_Learning/Variational_Autoencoder/Sequential_VAE/">Sequential VAE</a></li><li class="file"><a href="/Deep_Learning/Variational_Autoencoder/Gradient_Estimators_for_Variational_Inference/">Gradient Estimators for Variational Inference</a></li><li class="file"><a href="/Deep_Learning/Variational_Autoencoder/Theoretical_Facts/">Theoretical Facts about VAEs</a></li></ul></li></ul></li><li class="directory"><a href="#" data-role="directory"><i class="fa fa-folder"></i> &nbsp; Mathematics</a><ul class="unstyled" id="tree"><li class="directory"><a href="#" data-role="directory"><i class="fa fa-folder"></i> &nbsp; Analysis</a><ul class="unstyled" id="tree"><li class="file"><a href="/Mathematics/Analysis/Linear_Space_vs_Functional_Space/">Linear space vs functional space</a></li></ul></li><li class="directory"><a href="#" data-role="directory"><i class="fa fa-folder"></i> &nbsp; Calculus</a><ul class="unstyled" id="tree"><li class="file"><a href="/Mathematics/Calculus/Calculus_of_Variations/">Calculus of Variations</a></li></ul></li><li class="directory"><a href="#" data-role="directory"><i class="fa fa-folder"></i> &nbsp; Differential Equations</a><ul class="unstyled" id="tree"><li class="file"><a href="/Mathematics/Differential_Equations/Probability_Distribution_Equations/">Differential Equations on Probability Distributions</a></li></ul></li><li class="directory"><a href="#" data-role="directory"><i class="fa fa-folder"></i> &nbsp; Optimization</a><ul class="unstyled" id="tree"><li class="file"><a href="/Mathematics/Optimization/Convex_Optimization/">Convex Optimization</a></li></ul></li></ul></li><li class="directory"><a href="#" data-role="directory"><i class="fa fa-folder"></i> &nbsp; Research Work</a><ul class="unstyled" id="tree"><li class="file"><a href="/Research_Work/Reading_List/">Reading List</a></li><li class="file"><a href="/Research_Work/Tracking_the_Concepts/">Tracking the Concepts</a></li><li class="file"><a href="/Research_Work/Directions_to_Explore/">Directions to Explore</a></li></ul></li></ul></div><script>$(document).ready(function(){var r="fa-folder-open",i="fa-folder",l="fa-angle-double-down",d="fa-angle-double-up";$(document).on("click",'#categories a[data-role="directory"]',function(a){a.preventDefault();var e=$(this).children(".fa"),s=e.hasClass(r),l=$(this).siblings("ul");e.removeClass(r).removeClass(i),s?(void 0!==l&&l.slideUp({duration:100}),e.addClass(i)):(void 0!==l&&l.slideDown({duration:100}),e.addClass(r))}),$('#categories a[data-role="directory"]').bind("contextmenu",function(a){a.preventDefault();var e=$(this).children(".fa"),s=e.hasClass(r),l=$(this).siblings("ul"),d=$.merge(l.find("li ul"),l),o=$.merge(l.find(".fa"),e);o.removeClass(r).removeClass(i),s?(d.slideUp({duration:100}),o.addClass(i)):(d.slideDown({duration:100}),o.addClass(r))}),$(document).on("click","#allExpand",function(a){a.preventDefault();var e=$(this).children(".fa"),s=e.hasClass(l);e.removeClass(l).removeClass(d),s?($("#sidebar .fa.fa-folder").removeClass("fa-folder").addClass("fa-folder-open"),$("#categories li ul").slideDown({duration:100}),e.addClass(d)):($("#sidebar .fa.fa-folder-open").removeClass("fa-folder-open").addClass("fa-folder"),$("#categories li ul").slideUp({duration:100}),e.addClass(l))})})</script><div id="toTop" class="fa fa-angle-up"></div></aside><section id="main"><article id="post-Deep_Learning/Variational_Autoencoder/Sequential_VAE" class="article article-type-post" itemscope itemprop="blogPost"><div class="article-inner"><header class="article-header"><div class="article-meta"><div class="article-category"><i class="fa fa-folder"></i> <a class="article-category-link" href="/categories/Deep-Learning/">Deep Learning</a><i class="fa fa-angle-right"></i><a class="article-category-link" href="/categories/Deep-Learning/Variational-Autoencoder/">Variational Autoencoder</a></div><div class="article-date"><i class="fa fa-calendar"></i> <a href="/Deep_Learning/Variational_Autoencoder/Sequential_VAE/"><time datetime="2019-11-04T06:52:00.000Z" itemprop="datePublished">2019-11-04</time></a></div><div class="article-meta-button"><a href="https://github.com/haowen-xu/research-notes/raw/master/source/_posts/Deep_Learning/Variational_Autoencoder/Sequential_VAE.md">Source</a></div><div class="article-meta-button"><a href="https://github.com/haowen-xu/research-notes/edit/master/source/_posts/Deep_Learning/Variational_Autoencoder/Sequential_VAE.md">Edit</a></div><div class="article-meta-button"><a href="https://github.com/haowen-xu/research-notes/commits/master/source/_posts/Deep_Learning/Variational_Autoencoder/Sequential_VAE.md">History</a></div></div><h1 itemprop="name"><a class="article-title" href="/Deep_Learning/Variational_Autoencoder/Sequential_VAE/">Sequential VAE</a></h1></header><div class="article-entry" itemprop="articleBody"><p>Sequential VAEs model observed sequence <span class="math inline">\(\mathbf{x}_1, \mathbf{x}_2, \dots, \mathbf{x}_T\)</span> using latent sequence <span class="math inline">\(\mathbf{z}_1, \mathbf{z}_2, \dots, \mathbf{z}_T\)</span>.</p><p>In this article, we use <span class="math inline">\(\mathbf{x}_{1:T}\)</span> and <span class="math inline">\(\mathbf{z}_{1:T}\)</span> to denote <span class="math inline">\(\mathbf{x}_1, \mathbf{x}_2, \dots, \mathbf{x}_T\)</span> and <span class="math inline">\(\mathbf{z}_1, \mathbf{z}_2, \dots, \mathbf{z}_T\)</span>, respectively. Also, we use <span class="math inline">\(\mathbf{x}_{\neg t}\)</span> to denote <span class="math inline">\(\mathbf{x}_1,\dots,\mathbf{x}_{t-1},\mathbf{x}_{t+1},\dots,\mathbf{x}_T\)</span>, and <span class="math inline">\(\mathbf{z}_{\neg t}\)</span> likewise.</p><h2 id="the-future-dependency-problem">The Future Dependency Problem</h2><p>In this section, we shall discuss the future dependency problem of <span class="math inline">\(\mathbf{z}_t\)</span> on <span class="math inline">\(\mathbf{x}_{t:T}\)</span> in the variational distribution <span class="math inline">\(q_{\phi}(\mathbf{z}_{1:T}|\mathbf{x}_{1:T})\)</span>, via a simple hidden state markov chain model.</p><p>Suppose <span class="math inline">\(\mathbf{z}_{1:T}\)</span> is a Markov chain, and serves as a sequence of hidden states that determines the <span class="math inline">\(\mathbf{x}_{1:T}\)</span> sequence. Formally, the probabilistic formulation of such a model can be written as: <span class="math display">\[ \begin{align} p_{\lambda}(\mathbf{z}_{1:T}) &amp;= \prod_{t=1}^T p_{\lambda}(\mathbf{z}_t|\mathbf{z}_{t-1}) \\ p_{\theta}(\mathbf{x}_{1:T}|\mathbf{z}_{1:T}) &amp;= \prod_{t=1}^T p_{\theta}(\mathbf{x}_t|\mathbf{z}_t) \end{align} \]</span> This formulation can also be visualized as the following Bayesian network diagram:</p><figure><img src="/Deep_Learning/Variational_Autoencoder/Sequential_VAE/hmm_model.png" id="fig:hidden-state-markov-chain-model" data-max-height="120px" alt="" style="max-height:120px"><figcaption>Figure 1: Hidden State Markov Chain Model</figcaption></figure><p>Surprisingly, the posterior distribution, <em>i.e.</em>, <span class="math inline">\(p_{\theta}(\mathbf{z}_{1:T}|\mathbf{x}_{1:T})\)</span>, exhibits <em>future dependency</em>, as is noticed by <span class="citation" data-cites="fraccaroSequentialNeuralModels2016">Fraccaro et al. (<a href="#ref-fraccaroSequentialNeuralModels2016" role="doc-biblioref">2016</a>)</span>. Using <span class="dangling-link">d-separation</span>, one can easily figure out that: <span class="math display">\[ p_{\theta}(\mathbf{z}_{1:T}|\mathbf{x}_{1:T}) = \prod_{t=1}^T p_{\theta}(\mathbf{z}_t|\mathbf{z}_{t-1}, \mathbf{x}_{t:T}) \]</span> Such independence relationship is also illustrated in the following diagram. Clearly, the observation of <span class="math inline">\(\mathbf{z}_{t-1}\)</span> blocks the dependency of <span class="math inline">\(\mathbf{z}_t\)</span> on <span class="math inline">\(\mathbf{x}_{1:(t-1)}\)</span> and <span class="math inline">\(\mathbf{z}_{1:(t-1)}\)</span>, however, does not block its dependence on the future <span class="math inline">\(\mathbf{x}_{(t+1):T}\)</span>.</p><figure><img src="/Deep_Learning/Variational_Autoencoder/Sequential_VAE/hmm_d_separation.png" id="fig:hmm-d-separation" data-max-height="120px" alt="" style="max-height:120px"><figcaption>Figure 2: <em>d-separation</em> illustration for <span class="math inline">\(\mathbf{z}_t\)</span></figcaption></figure><p>The future dependency seems counter-intuitive at the first glance. However, this dependency can be naturally explained in the information theoretic perspective. Since the sequence <span class="math inline">\(\mathbf{x}_{t:T}\)</span> is generated with the influence of <span class="math inline">\(\mathbf{z}_t\)</span>, <em>i.e.</em>, the information of <span class="math inline">\(\mathbf{z}_t\)</span> flows into <span class="math inline">\(\mathbf{x}_{t:T}\)</span>, then it should be not suprising that knowing the information of <span class="math inline">\(\mathbf{x}_{t:T}\)</span> is helpful to infer <span class="math inline">\(\mathbf{z}_t\)</span>.</p><h2 id="vrnn">VRNN</h2><p><span class="citation" data-cites="chungRecurrentLatentVariable2015">Chung et al. (<a href="#ref-chungRecurrentLatentVariable2015" role="doc-biblioref">2015</a>)</span> proposed to embed a variational autoencoder into each step of an LSTM or GRU recurrent network, formalized as: <span class="math display">\[ \begin{align} p_{\lambda}(\mathbf{z}_t|\mathbf{h}_{t-1}) &amp;= \mathcal{N}(\mathbf{z}_t|\boldsymbol{\mu}_{\lambda,t}, \boldsymbol{\sigma}_{\lambda,t}^2) \\ p_{\theta}(\mathbf{x}_t|\mathbf{z}_t,\mathbf{h}_{t-1}) &amp;= \mathcal{N}(\mathbf{x}_t| \boldsymbol{\mu}_{\theta,t}, \boldsymbol{\sigma}_{\theta,t}^2) \\ q_{\phi}(\mathbf{z}_t|\mathbf{x}_t,\mathbf{h}_{t-1}) &amp;= \mathcal{N}(\mathbf{z}_t| \boldsymbol{\mu}_{\phi,t}, \boldsymbol{\sigma}_{\phi,t}^2) \\ \mathbf{h}_t &amp;= f_{\text{rnn}}(f_{\mathbf{x}}(\mathbf{x}_t),f_{\mathbf{z}}(\mathbf{z}_t),\mathbf{h}_{t-1}) \\ [\boldsymbol{\mu}_{\lambda,t}, \boldsymbol{\sigma}_{\lambda,t}] &amp;= f_{\text{prior}}(\mathbf{h}_{t-1}) \\ [\boldsymbol{\mu}_{\theta,t}, \boldsymbol{\sigma}_{\theta,t}] &amp;= f_{\text{dec}}(f_{\mathbf{z}}(\mathbf{z}_t), \mathbf{h}_{t-1}) \\ [\boldsymbol{\mu}_{\phi,t}, \boldsymbol{\sigma}_{\phi,t}] &amp;= f_{\text{enc}}(f_{\mathbf{x}}(\mathbf{x}_t), \mathbf{h}_{t-1}) \end{align} \]</span> where <span class="math inline">\(f_{\mathbf{z}}\)</span> and <span class="math inline">\(f_{\mathbf{x}}\)</span> are feature networks shared among the prior, the encoder and the decoder, which are “crucial for learning complex sequences” according to <span class="citation" data-cites="chungRecurrentLatentVariable2015">Chung et al. (<a href="#ref-chungRecurrentLatentVariable2015" role="doc-biblioref">2015</a>)</span>. <span class="math inline">\(f_{\text{rnn}}\)</span> is the transition kernel of the recurrent network, and <span class="math inline">\(\mathbf{h}_{1:T}\)</span> are the deterministic hidden states of the recurrent network. <span class="math inline">\(f_{\text{prior}}\)</span>, <span class="math inline">\(f_{\text{enc}}\)</span> and <span class="math inline">\(f_{\text{dec}}\)</span> are the neural networks in the prior, the encoder and the decoder, respectively.</p><p>The overall architecture of VRNN can be illustrated as the following figure, given by <span class="citation" data-cites="chungRecurrentLatentVariable2015">Chung et al. (<a href="#ref-chungRecurrentLatentVariable2015" role="doc-biblioref">2015</a>)</span>:</p><figure><img src="/Deep_Learning/Variational_Autoencoder/Sequential_VAE/vrnn_original_arch.png" id="fig:vrnn-original-arch" data-max-height="240px" alt="" style="max-height:240px"><figcaption>Figure 3: Overall architecture of VRNN</figcaption></figure><p>The following figure may provide a more clear illustration of the dependency among <span class="math inline">\(\mathbf{h}_{1:T}\)</span>, <span class="math inline">\(\mathbf{x}_{1:T}\)</span> and <span class="math inline">\(\mathbf{z}_{1:T}\)</span> in the generative part:</p><figure><img src="/Deep_Learning/Variational_Autoencoder/Sequential_VAE/vrnn.png" id="fig:vrnn" data-max-height="192px" alt="" style="max-height:192px"><figcaption>Figure 4: Dependency graph of VRNN in the generative part</figcaption></figure><p>The authors did not provide a theoretical analysis of the dependency relationship in their variational posterior <span class="math inline">\(q_{\phi}(\mathbf{z}_{1:T}|\mathbf{x}_{1:T})\)</span>, but according to <span class="dangling-link">d-separation</span>, we can easily figure out the correct dependency for the true posterior should be: <span class="math display">\[ p_{\theta}(\mathbf{z}_t|\mathbf{z}_{1:(t-1)},\mathbf{x}_{1:T},\mathbf{h}_{1:T}) = p_{\theta}(\mathbf{z}_t|\mathbf{h}_{t-1},\mathbf{x}_t,\mathbf{h}_t) \]</span> The dependency of <span class="math inline">\(\mathbf{z}_t\)</span> on future state <span class="math inline">\(\mathbf{h}_t\)</span> brings trouble for posterior inference. <span class="citation" data-cites="chungRecurrentLatentVariable2015">Chung et al. (<a href="#ref-chungRecurrentLatentVariable2015" role="doc-biblioref">2015</a>)</span> simply neglected this dependency. On the other hand, <span class="citation" data-cites="fraccaroSequentialNeuralModels2016">Fraccaro et al. (<a href="#ref-fraccaroSequentialNeuralModels2016" role="doc-biblioref">2016</a>)</span> considered such dependency and proposed SRNN, which brought us to a theoretically more reasonable factorization.</p><h3 id="srnn">SRNN</h3><p><span class="citation" data-cites="fraccaroSequentialNeuralModels2016">Fraccaro et al. (<a href="#ref-fraccaroSequentialNeuralModels2016" role="doc-biblioref">2016</a>)</span> proposed to factorize <span class="math inline">\(\mathbf{z}_{1:T}\)</span> as a state-space machine, depending on deterministic hidden state <span class="math inline">\(\mathbf{h}_{1:T}\)</span> of a recurrent network, and potentially the input <span class="math inline">\(\mathbf{u}_{1:T}\)</span> of each time step. The observation <span class="math inline">\(\mathbf{x}_t\)</span> of each time step is then assumed to depend only on <span class="math inline">\(\mathbf{d}_t\)</span> and <span class="math inline">\(\mathbf{z}_t\)</span>. The overall architecture of SRNN is illustrated in the following figure <span class="citation" data-cites="fraccaroSequentialNeuralModels2016">(Fraccaro et al. <a href="#ref-fraccaroSequentialNeuralModels2016" role="doc-biblioref">2016</a>)</span>:</p><figure><img src="/Deep_Learning/Variational_Autoencoder/Sequential_VAE/srnn_original_arch.png" id="fig:srnn-original-arch" data-max-height="320px" alt="" style="max-height:320px"><figcaption>Figure 5: Overall architecture of SRNN</figcaption></figure><h4 id="generative-part">Generative Part</h4><p>The initial state is chosen to be <span class="math inline">\(\mathbf{z}_0 = \mathbf{0}\)</span> and <span class="math inline">\(\mathbf{d}_0 = \mathbf{0}\)</span>. According to <span class="dangling-link">d-separation</span>, the generative part is formulated as: <span class="math display">\[ \begin{align} p_{\lambda}(\mathbf{z}_{1:T},\mathbf{d}_{1:T}|\mathbf{u}_{1:T},\mathbf{z}_0,\mathbf{d}_0) &amp;= \prod_{t=1}^T p_{\lambda}(\mathbf{z}_t|\mathbf{z}_{t-1},\mathbf{d}_t) \, p_{\lambda}(\mathbf{d}_t|\mathbf{d}_{t-1},\mathbf{u}_t) \\ p_{\theta}(\mathbf{x}_{1:T}|\mathbf{z}_{1:T},\mathbf{d}_{1:T},\mathbf{u}_{1:T},\mathbf{z}_0,\mathbf{d}_0) &amp;= \prod_{t=1}^T p_{\theta}(\mathbf{x}_t|\mathbf{z}_t,\mathbf{d}_t) \end{align} \]</span></p><p><span class="math inline">\(p_{\lambda}(\mathbf{d}_t|\mathbf{d}_{t-1},\mathbf{u}_t)\)</span> is a dirac distribution, derived by <span class="math inline">\(\text{RNN}^{(p)}\)</span>, a recurrent network: <span class="math display">\[ \begin{align} p_{\lambda}(\mathbf{d}_t|\mathbf{d}_{d-1},\mathbf{u}_t) &amp;= \delta(\mathbf{d}_t-\widetilde{\mathbf{d}}_t) \\ \widetilde{\mathbf{d}}_t &amp;= \text{RNN}^{(p)}(\mathbf{d}_{t-1}, \mathbf{u}_t) \end{align} \]</span> <span class="math inline">\(p_{\lambda}(\mathbf{z}_t|\mathbf{z}_{t-1},\mathbf{d}_t)\)</span> is a <span class="dangling-link">state-space machine</span>, given by: <span class="math display">\[ \begin{align} p_{\lambda}(\mathbf{z}_t|\mathbf{z}_{t-1},\mathbf{d}_t) &amp;= \mathcal{N}(\mathbf{z}_t| \boldsymbol{\mu}_{\lambda}(\mathbf{z}_{t-1},\mathbf{d}_t), \boldsymbol{\sigma}^2_{\lambda}(\mathbf{z}_{t-1},\mathbf{d}_t)) \\ \boldsymbol{\mu}_{\lambda}(\mathbf{z}_{t-1},\mathbf{d}_t) &amp;= \text{NN}^{(p)}_1(\mathbf{z}_{t-1},\mathbf{d}_t) \\ \log \boldsymbol{\sigma}_{\lambda}(\mathbf{z}_{t-1},\mathbf{d}_t) &amp;= \text{NN}^{(p)}_2(\mathbf{z}_{t-1},\mathbf{d}_t) \end{align} \]</span></p><p><span class="math inline">\(p_{\theta}(\mathbf{x}_t|\mathbf{z}_t, \mathbf{d}_t)\)</span> is derived by: <span class="math display">\[ p_{\theta}(\mathbf{x}_t|\mathbf{z}_t,\mathbf{d}_t) = \mathcal{N}(\mathbf{x}_t| \boldsymbol{\mu}_{\theta}(\mathbf{z}_t,\mathbf{d}_t), \boldsymbol{\sigma}^2_{\theta}(\mathbf{z}_t,\mathbf{d}_t)) \]</span></p><p>where <span class="math inline">\(\boldsymbol{\mu}_{\theta}(\mathbf{z}_t,\mathbf{d}_t)\)</span> and <span class="math inline">\(\boldsymbol{\sigma}_{\theta}(\mathbf{z}_t,\mathbf{d}_t)\)</span> use similar parameterization as in <span class="math inline">\(p_{\lambda}(\mathbf{z}_t|\mathbf{z}_{t-1},\mathbf{d}_t)\)</span>.</p><h4 id="variational-part">Variational Part</h4><p>The variational approximated posterior can be factorized as: <span class="math display">\[ \begin{align} q_{\phi}(\mathbf{z}_{1:T},\mathbf{d}_{1:T}|\mathbf{x}_{1:T},\mathbf{u}_{1:T},\mathbf{d}_0,\mathbf{u}_0) &amp;= q_{\phi}(\mathbf{z}_{1:T}|\mathbf{d}_{1:T},\mathbf{x}_{1:T},\mathbf{u}_{1:T},\mathbf{d}_0,\mathbf{u}_0)\, q_{\phi}(\mathbf{d}_{1:T}|\mathbf{x}_{1:T},\mathbf{u}_{1:T},\mathbf{d}_0,\mathbf{u}_0) \end{align} \]</span></p><p>Since in the generative part, <span class="math inline">\(p_{\lambda}(\mathbf{d}_t|\mathbf{d}_{t-1},\mathbf{u}_t)\)</span> is a dirac distribution, <span class="citation" data-cites="fraccaroSequentialNeuralModels2016">Fraccaro et al. (<a href="#ref-fraccaroSequentialNeuralModels2016" role="doc-biblioref">2016</a>)</span> decided to assume the second term in the above equation to be: <span class="math display">\[ q_{\phi}(\mathbf{d}_{1:T}|\mathbf{x}_{1:T},\mathbf{u}_{1:T},\mathbf{d}_0,\mathbf{u}_0) \equiv p_{\lambda}(\mathbf{d}_{1:T}|\mathbf{u}_{1:T},\mathbf{d}_0,\mathbf{u}_0) = \prod_{t=1}^T p_{\lambda}(\mathbf{d}_t|\mathbf{d}_{t-1},\mathbf{u}_t) \]</span> That is, the same recurrent network <span class="math inline">\(\text{RNN}^{(p)}\)</span> is used to produce the deterministic states <span class="math inline">\(\mathbf{d}_{1:T}\)</span> in both the generative part and variational part.</p><p>The first term is factorized according to <span class="dangling-link">d-separation</span>, as: <span class="math display">\[ q_{\phi}(\mathbf{z}_{1:T}|\mathbf{d}_{1:T},\mathbf{x}_{1:T},\mathbf{u}_{1:T},\mathbf{d}_0,\mathbf{u}_0) = \prod_{t=1}^T q_{\phi}(\mathbf{z}_t|\mathbf{z}_{t-1},\mathbf{d}_{t:T},\mathbf{x}_{t:T}) \]</span> where <span class="math inline">\(q_{\phi}(\mathbf{z}_t|\mathbf{z}_{t-1},\mathbf{d}_{t:T},\mathbf{x}_{t:T})\)</span> is derived by a reverse recurrent network <span class="math inline">\(\text{RNN}^{(q)}\)</span>, whose hidden state was denoted as <span class="math inline">\(\mathbf{a}_t\)</span>, as illustrated in Fig.&nbsp;<a href="#fig:srnn-original-arch">5</a>. The formalization of <span class="math inline">\(q_{\phi}(\mathbf{z}_t|\mathbf{z}_{t-1},\mathbf{d}_{t:T},\mathbf{x}_{t:T})\)</span> is: <span class="math display">\[ \begin{align} q_{\phi}(\mathbf{z}_t|\mathbf{z}_{t-1},\mathbf{d}_{t:T},\mathbf{x}_{t:T}) &amp;= q_{\phi}(\mathbf{z}_t|\mathbf{z}_{t-1},\mathbf{a}_t) \\ q_{\phi}(\mathbf{z}_t|\mathbf{z}_{t-1},\mathbf{a}_t) &amp;= \mathcal{N}(\mathbf{z}_t| \boldsymbol{\mu}_{\phi}(\mathbf{z}_{t-1},\mathbf{a}_t), \boldsymbol{\sigma}_{\phi}^2(\mathbf{z}_{t-1},\mathbf{a}_t)) \\ \boldsymbol{\mu}_{\phi}(\mathbf{z}_{t-1},\mathbf{a}_t) &amp;= \boldsymbol{\mu}_{\lambda}(\mathbf{z}_{t-1},\mathbf{d}_t) + \text{NN}^{(q)}_1(\mathbf{z}_{t-1},\mathbf{a}_t) \\ \log \boldsymbol{\sigma}_{\phi}(\mathbf{z}_{t-1},\mathbf{a}_t) &amp;= \text{NN}^{(q)}_2(\mathbf{z}_{t-1},\mathbf{a}_t) \\ \mathbf{a}_t &amp;= \text{RNN}^{(q)}(\mathbf{a}_{t+1},[\mathbf{d}_t,\mathbf{x}_t]) \end{align} \]</span> Notice <span class="math inline">\(\text{NN}^{(q)}_1(\mathbf{z}_{t-1},\mathbf{a}_t)\)</span> is adopted to learn the residual <span class="math inline">\(\boldsymbol{\mu}_{\phi}(\mathbf{z}_{t-1},\mathbf{a}_t) - \boldsymbol{\mu}_{\lambda}(\mathbf{z}_{t-1},\mathbf{d}_t)\)</span>, instead of <span class="math inline">\(\boldsymbol{\mu}_{\phi}(\mathbf{z}_{t-1},\mathbf{a}_t)\)</span> directly. <span class="citation" data-cites="fraccaroSequentialNeuralModels2016">Fraccaro et al. (<a href="#ref-fraccaroSequentialNeuralModels2016" role="doc-biblioref">2016</a>)</span> found that this residual parameterization can lead to better performance.</p><h1 id="bibliography" class="unnumbered">References</h1><div id="refs" class="references" role="doc-bibliography"><div id="ref-chungRecurrentLatentVariable2015"><p>Chung, Junyoung, Kyle Kastner, Laurent Dinh, Kratarth Goel, Aaron C. Courville, and Yoshua Bengio. 2015. “A Recurrent Latent Variable Model for Sequential Data.” In <em>Advances in Neural Information Processing Systems</em>, 2980–8.</p></div><div id="ref-fraccaroSequentialNeuralModels2016"><p>Fraccaro, Marco, Søren Kaae Sønderby, Ulrich Paquet, and Ole Winther. 2016. “Sequential Neural Models with Stochastic Layers.” In <em>Advances in Neural Information Processing Systems</em>, 2199–2207.</p></div></div></div><div style="height:10px"></div></div></article><article id="post-Deep_Learning/Variational_Autoencoder/Overview" class="article article-type-post" itemscope itemprop="blogPost"><div class="article-inner"><header class="article-header"><div class="article-meta"><div class="article-category"><i class="fa fa-folder"></i> <a class="article-category-link" href="/categories/Deep-Learning/">Deep Learning</a><i class="fa fa-angle-right"></i><a class="article-category-link" href="/categories/Deep-Learning/Variational-Autoencoder/">Variational Autoencoder</a></div><div class="article-date"><i class="fa fa-calendar"></i> <a href="/Deep_Learning/Variational_Autoencoder/Overview/"><time datetime="2019-11-03T11:01:00.000Z" itemprop="datePublished">2019-11-03</time></a></div><div class="article-meta-button"><a href="https://github.com/haowen-xu/research-notes/raw/master/source/_posts/Deep_Learning/Variational_Autoencoder/Overview.md">Source</a></div><div class="article-meta-button"><a href="https://github.com/haowen-xu/research-notes/edit/master/source/_posts/Deep_Learning/Variational_Autoencoder/Overview.md">Edit</a></div><div class="article-meta-button"><a href="https://github.com/haowen-xu/research-notes/commits/master/source/_posts/Deep_Learning/Variational_Autoencoder/Overview.md">History</a></div></div><h1 itemprop="name"><a class="article-title" href="/Deep_Learning/Variational_Autoencoder/Overview/">Overview</a></h1></header><div class="article-entry" itemprop="articleBody"><h2 id="variational-autoencoder-basis">Variational Autoencoder Basis</h2><h3 id="the-probabilistic-model-formulation">The Probabilistic Model Formulation</h3><p>Variational autoencoder, first proposed by <span class="citation" data-cites="kingmaAutoEncodingVariationalBayes2014">Kingma and Welling (<a href="#ref-kingmaAutoEncodingVariationalBayes2014" role="doc-biblioref">2014</a>)</span> and <span class="citation" data-cites="rezendeStochasticBackpropagationApproximate2014">Rezende, Mohamed, and Wierstra (<a href="#ref-rezendeStochasticBackpropagationApproximate2014" role="doc-biblioref">2014</a>)</span>, was originally a deep Bayesian network composed of latent variable <span class="math inline">\(\mathbf{z}\)</span> and observed variable <span class="math inline">\(\mathbf{x}\)</span>, formulated as: <span class="math display">\[ p(\mathbf{x};\theta,\lambda) = \int_{\mathcal{Z}} p_{\theta}(\mathbf{x}|\mathbf{z})\,p_{\lambda}(\mathbf{z})\,d\mathbf{z} \]</span> where <span class="math inline">\(p_{\lambda}(\mathbf{z})\)</span> is the prior for <span class="math inline">\(\mathbf{z}\)</span>, either fixed, or derived by a neural network with parameter <span class="math inline">\(\lambda\)</span>; and <span class="math inline">\(p_{\theta}(\mathbf{x}|\mathbf{z})\)</span> is derived by a neural network with parameter <span class="math inline">\(\theta\)</span>. <span class="math inline">\(p_{\lambda}(\mathbf{z})\)</span> is denoted as <span class="math inline">\(p_{\theta}(\mathbf{z})\)</span> in some literature, including in its original papers.</p><h3 id="variational-approximation-of-the-posterior">Variational Approximation of the Posterior</h3><p>The most significant design of variational autoencoder, which makes it much different from other generative models, is the use of <a href="/Deep_Learning/Variational_Autoencoder/Gradient_Estimators_for_Variational_Inference/">variational inference</a> to approximate the intractable <span class="math inline">\(p_{\theta}(\mathbf{z}|\mathbf{x}) = \frac{p_{\theta}(\mathbf{x}|\mathbf{z})\,p_{\lambda}(\mathbf{z})}{\int_{\mathcal{Z}} p_{\theta}(\mathbf{x}|\mathbf{w})\,p_{\lambda}(\mathbf{w})\,d\mathbf{w}}\)</span>, using a separatedly learned <span class="math inline">\(q_{\phi}(\mathbf{z}|\mathbf{x})\)</span>, derived by a neural network with parameter <span class="math inline">\(\phi\)</span>. The evidence lower-bound (ELBO) can be used to joinly train these components, formulated as: <span class="math display">\[ \begin{aligned} \log p(\mathbf{x};\theta,\lambda) &amp;\geq \log p_{\theta}(\mathbf{x}) - \operatorname{D}_{KL}\big[ q_{\phi}(\mathbf{z}|\mathbf{x})\|p_{\theta}(\mathbf{z}|\mathbf{x}) \big] \\ &amp;= \mathbb{E}_{\mathbf{z} \sim q_{\phi}(\mathbf{z}|\mathbf{x})}\big[ \log p_{\theta}(\mathbf{x}) + \log p_{\theta}(\mathbf{z}|\mathbf{x}) - \log q_{\phi}(\mathbf{z}|\mathbf{x}) \big] \\ &amp;= \mathbb{E}_{\mathbf{z} \sim q_{\phi}(\mathbf{z}|\mathbf{x})}\big[ \log p_{\theta}(\mathbf{x}|\mathbf{z}) + \log p_{\lambda}(\mathbf{z}) - \log q_{\phi}(\mathbf{z}|\mathbf{x}) \big] \\ &amp;= \mathbb{E}_{\mathbf{z} \sim q_{\phi}(\mathbf{z}|\mathbf{x})}\big[\log p_{\theta}(\mathbf{x}|\mathbf{z})\big] - D_{\mathrm{KL}}\left( q_{\phi}(\mathbf{z}|\mathbf{x}) \| p_{\lambda}(\mathbf{z}) \right) \\ &amp;= \mathcal{L}(\mathbf{x};\theta,\lambda,\phi) \end{aligned} \]</span></p><p><span class="citation" data-cites="kingmaAutoEncodingVariationalBayes2014">Kingma and Welling (<a href="#ref-kingmaAutoEncodingVariationalBayes2014" role="doc-biblioref">2014</a>)</span> proposed to optimize ELBO using SGVB gradient estimator, which requires <span class="math inline">\(q_{\phi}(\mathbf{z}|\mathbf{x})\)</span> to be re-parameterized. Only some of the continuous distributions can be re-parameterized. For non-reparameterizable continuous distributions and discrete distributions, other gradient estimators may be adopted, which are reviewed in <a href="/Deep_Learning/Variational_Autoencoder/Gradient_Estimators_for_Variational_Inference/">variational inference</a>.</p><h3 id="the-auto-encoding-structure">The Auto-Encoding Structure</h3><p>The pair of <span class="math inline">\(q_{\phi}(\mathbf{z}|\mathbf{x})\)</span> and <span class="math inline">\(p_{\theta}(\mathbf{x}|\mathbf{z})\)</span> resembles an <em>autoencoder</em>, where <span class="math inline">\(q_{\phi}(\mathbf{z}|\mathbf{x})\)</span> is the encoder, and <span class="math inline">\(p_{\theta}(\mathbf{x}|\mathbf{z})\)</span> is the decoder. In this perspective, <span class="math inline">\(D_{\mathrm{KL}}\left( q_{\phi}(\mathbf{z}|\mathbf{x}) \| p_{\lambda}(\mathbf{z}) \right)\)</span> becomes a regularization term to encourage a meaningful latent coding, which was further discussed in <span class="math inline">\(\beta\)</span>-VAE <span class="citation" data-cites="higginsBetavaeLearningBasic2017 burgessUnderstandingDisentanglingBeta2018 mathieuDisentanglingDisentanglementVariational2018">(Higgins et al. <a href="#ref-higginsBetavaeLearningBasic2017" role="doc-biblioref">2017</a>; Burgess et al. <a href="#ref-burgessUnderstandingDisentanglingBeta2018" role="doc-biblioref">2018</a>; Mathieu et al. <a href="#ref-mathieuDisentanglingDisentanglementVariational2018" role="doc-biblioref">2018</a>)</span> and others.</p><p>The auto-encoding structure is even more well-known and widely used than the probabilistic formulation of a <em>variational autoencoder</em>. Because of this, the term <em>variational autoencoder</em> now has been generalized to refer to a family of generative models, which learn stochastic encoders and infer latent variables by variational inference, rather than just the original model.</p><h2 id="advanced-model-architectures">Advanced Model Architectures</h2><p>Some more advanced model architectures, which is composed of more than just one latent variable <span class="math inline">\(\mathbf{z}\)</span> and one observed variable <span class="math inline">\(\mathbf{x}\)</span>, are reviewed in this section.</p><ul><li><a href="/Deep_Learning/Variational_Autoencoder/Sequential_VAE/">Sequential VAE</a></li></ul><h2 id="training-variational-autoencoder">Training Variational Autoencoder</h2><ul><li>Stochastic gradient descent<ul><li><a href="/Deep_Learning/Variational_Autoencoder/Gradient_Estimators_for_Variational_Inference/">Gradient Estimators for Variational Inference</a></li></ul></li></ul><h1 id="bibliography" class="unnumbered">References</h1><div id="refs" class="references" role="doc-bibliography"><div id="ref-burgessUnderstandingDisentanglingBeta2018"><p>Burgess, Christopher P., Irina Higgins, Arka Pal, Loic Matthey, Nick Watters, Guillaume Desjardins, and Alexander Lerchner. 2018. “Understanding Disentangling in $\beta$-VAE.” <em>arXiv:1804.03599 [Cs, Stat]</em>, April. <a href="http://arxiv.org/abs/1804.03599" target="_blank" rel="noopener">http://arxiv.org/abs/1804.03599</a>.</p></div><div id="ref-higginsBetavaeLearningBasic2017"><p>Higgins, Irina, Loic Matthey, Arka Pal, Christopher Burgess, Xavier Glorot, Matthew Botvinick, Shakir Mohamed, and Alexander Lerchner. 2017. “Beta-Vae: Learning Basic Visual Concepts with a Constrained Variational Framework.” In <em>International Conference on Learning Representations</em>. Vol. 3.</p></div><div id="ref-kingmaAutoEncodingVariationalBayes2014"><p>Kingma, Diederik P, and Max Welling. 2014. “Auto-Encoding Variational Bayes.” In <em>Proceedings of the International Conference on Learning Representations</em>.</p></div><div id="ref-mathieuDisentanglingDisentanglementVariational2018"><p>Mathieu, Emile, Tom Rainforth, N. Siddharth, and Yee Whye Teh. 2018. “Disentangling Disentanglement in Variational Autoencoders.” <em>arXiv:1812.02833 [Cs, Stat]</em>, December. <a href="http://arxiv.org/abs/1812.02833" target="_blank" rel="noopener">http://arxiv.org/abs/1812.02833</a>.</p></div><div id="ref-rezendeStochasticBackpropagationApproximate2014"><p>Rezende, Danilo Jimenez, Shakir Mohamed, and Daan Wierstra. 2014. “Stochastic Backpropagation and Approximate Inference in Deep Generative Models.” In <em>Proceedings of the 31st International Conference on International Conference on Machine Learning - Volume 32</em>, II–1278–II–1286. ICML’14. Beijing, China: JMLR.org.</p></div></div></div><div style="height:10px"></div></div></article><article id="post-Deep_Learning/Monte_Carlo_Methods/Langevin_Dynamics" class="article article-type-post" itemscope itemprop="blogPost"><div class="article-inner"><header class="article-header"><div class="article-meta"><div class="article-category"><i class="fa fa-folder"></i> <a class="article-category-link" href="/categories/Deep-Learning/">Deep Learning</a><i class="fa fa-angle-right"></i><a class="article-category-link" href="/categories/Deep-Learning/Monte-Carlo-Methods/">Monte Carlo Methods</a></div><div class="article-date"><i class="fa fa-calendar"></i> <a href="/Deep_Learning/Monte_Carlo_Methods/Langevin_Dynamics/"><time datetime="2019-10-21T07:08:00.000Z" itemprop="datePublished">2019-10-21</time></a></div><div class="article-meta-button"><a href="https://github.com/haowen-xu/research-notes/raw/master/source/_posts/Deep_Learning/Monte_Carlo_Methods/Langevin_Dynamics.md">Source</a></div><div class="article-meta-button"><a href="https://github.com/haowen-xu/research-notes/edit/master/source/_posts/Deep_Learning/Monte_Carlo_Methods/Langevin_Dynamics.md">Edit</a></div><div class="article-meta-button"><a href="https://github.com/haowen-xu/research-notes/commits/master/source/_posts/Deep_Learning/Monte_Carlo_Methods/Langevin_Dynamics.md">History</a></div></div><h1 itemprop="name"><a class="article-title" href="/Deep_Learning/Monte_Carlo_Methods/Langevin_Dynamics/">Langevin Dynamics</a></h1></header><div class="article-entry" itemprop="articleBody"><h2 id="problem-statement">Problem Statement</h2><p>To sample from <span class="math inline">\(p(\mathbf{x})\)</span>, where <span class="math inline">\(p(\mathbf{x})\)</span> is not easy to sample from, but the gradient <span class="math inline">\(\nabla_\mathbf{x} \log p(\mathbf{x})\)</span> is tractable.</p><h2 id="langevin-dynamics">Langevin Dynamics</h2><p>The transition kernel <span class="math inline">\(T\)</span> of Langevin dynamics is given by the following equation: <span class="math display">\[ \begin{align} &amp;\mathbf{x}^{(t+1)} = \mathbf{x}^{(t)} + \frac{\epsilon^2}{2}\cdot \nabla_{\mathbf{x}} \log p(\mathbf{x}^{(t)}) + \epsilon\cdot \mathbf{z}^{(t)} \\ &amp;\text{where}\;\,\mathbf{z}^{(t)} \sim \mathcal{N}(\mathbf{0},\mathbf{I}) \end{align} \]</span> and then <a href="/Deep_Learning/Monte_Carlo_Methods/Metropolis_Hastings_Algorithm/">Metropolis-Hastings algorithm</a> is adopted to determine whether or not the new sample <span class="math inline">\(\mathbf{x}^{(t+1)}\)</span> should be accepted. The acceptance rate is given by: <span class="math display">\[ \begin{align} \rho(\mathbf{x}^{(t)}, \mathbf{x}^{(t+1)}) &amp;= \min\bigg\{ 1, \exp\bigg( -\log p(\mathbf{x}^{(t)}) + \log p(\mathbf{x}^{(t+1)}) \\ &amp;\qquad\qquad\qquad\qquad+\frac{1}{2} \left\| \mathbf{z}^{(t)} \right\|^2_2 -\frac{1}{2} \left\| \mathbf{z}^{(t+1)} \right\|^2_2 \bigg) \bigg\} \\ \mathbf{z}^{(t+1)} &amp;= -\mathbf{z}^{(t)} - \frac{\epsilon}{2}\cdot \left[ \nabla_{\mathbf{x}} \log p(\mathbf{x}^{(t)}) + \nabla_{\mathbf{x}} \log p(\mathbf{x}^{(t+1)}) \right] \end{align} \]</span></p><h3 id="langevin-dynamics-as-metropolis-hastings-algorithm">Langevin Dynamics as Metropolis-Hastings Algorithm</h3><p>One may also substitute out <span class="math inline">\(\mathbf{z}^{(t)}\)</span> and <span class="math inline">\(\mathbf{z}^{(t+1)}\)</span> using <span class="math inline">\(\mathbf{x}^{(t)}\)</span> and <span class="math inline">\(\mathbf{x}^{(t+1)}\)</span>, such that the whole Langevin dynamics can be viewed as a strict Metropolis-Hastings transition kernel, as follows: <span class="math display">\[ \begin{align} \mathbf{z}^{(t)} &amp;= \frac{1}{\epsilon}\left[ \mathbf{x}^{(t+1)} - \mathbf{x}^{(t)} - \frac{\epsilon^2}{2} \nabla_{\mathbf{x}} \log p(\mathbf{x}^{(t)}) \right] \\ \mathbf{z}^{(t+1)} &amp;= \frac{1}{\epsilon}\left[ \mathbf{x}^{(t)} - \mathbf{x}^{(t+1)} - \frac{\epsilon^2}{2} \nabla_{\mathbf{x}} \log p(\mathbf{x}^{(t+1)}) \right] \end{align} \]</span> Also, we can write <span class="math inline">\(\rho(\mathbf{x}^{(t)}, \mathbf{x}^{(t+1)})\)</span> as: <span class="math display">\[ \rho(\mathbf{x}^{(t)}, \mathbf{x}^{(t+1)}) = \min\left\{ 1, \frac{\exp\left( \log p(\mathbf{x}^{(t+1)}) \right)}{\exp\left( \log p(\mathbf{x}^{(t)}) \right)} \cdot \frac{\exp\left( -\frac{1}{2}\left\| \mathbf{z}^{(t+1)} \right\|^2_2 \right)}{\exp\left( -\frac{1}{2}\left\| \mathbf{z}^{(t)} \right\|^2_2 \right)} \right\} \]</span> where: <span class="math display">\[ \begin{align} \exp\left( -\frac{1}{2}\left\| \mathbf{z}^{(t+1)} \right\|^2_2 \right) &amp;= \exp\left( -\frac{1}{2\epsilon^2} \left\| \mathbf{x}^{(t)} - \left( \mathbf{x}^{(t+1)} + \frac{\epsilon^2}{2} \nabla_{\mathbf{x}} \log p(\mathbf{x}^{(t+1)}) \right) \right\|^2_2 \right) \\ \exp\left( -\frac{1}{2}\left\| \mathbf{z}^{(t)} \right\|^2_2 \right) &amp;= \exp\left( -\frac{1}{2\epsilon^2} \left\| \mathbf{x}^{(t+1)} - \left( \mathbf{x}^{(t)} + \frac{\epsilon^2}{2} \nabla_{\mathbf{x}} \log p(\mathbf{x}^{(t)}) \right) \right\|^2_2 \right) \end{align} \]</span> The ratio <span class="math inline">\(\exp\left( -\frac{1}{2}\left\| \mathbf{z}^{(t+1)} \right\|^2_2 \right) / \exp\left( -\frac{1}{2}\left\| \mathbf{z}^{(t)} \right\|^2_2 \right)\)</span> can be viewed as <span class="math inline">\(q(\mathbf{x}^{(t)}|\mathbf{x}^{(t+1)}) / q(\mathbf{x}^{(t+1)}|\mathbf{x}^{(t)})\)</span>, where: <span class="math display">\[ \begin{align} q(\mathbf{x}^{(t)}|\mathbf{x}^{(t+1)}) &amp;= \mathcal{N}\left(\mathbf{x}^{(t)}\,\bigg|\,\mathbf{x}^{(t+1)} + \frac{\epsilon^2}{2} \nabla_{\mathbf{x}} \log p(\mathbf{x}^{(t+1)}), \epsilon^2\right) \\ q(\mathbf{x}^{(t+1)}|\mathbf{x}^{(t)}) &amp;= \mathcal{N}\left(\mathbf{x}^{(t+1)}\,\bigg|\,\mathbf{x}^{(t)} + \frac{\epsilon^2}{2} \nabla_{\mathbf{x}} \log p(\mathbf{x}^{(t)}), \epsilon^2\right) \end{align} \]</span> which are two Normal distributions with mean in the form of <span class="math inline">\(\mathbf{x}+\frac{\epsilon^2}{2}\nabla_{\mathbf{x}} \log p(\mathbf{x})\)</span> and variance being <span class="math inline">\(\epsilon^2\)</span>. Also, since <span class="math inline">\(p(\mathbf{x}) = \exp\left( \log p(\mathbf{x}) \right)\)</span>, we finally obtain: <span class="math display">\[ \rho(\mathbf{x}^{(t)}, \mathbf{x}^{(t+1)}) = \min\left\{ 1, \frac{p(\mathbf{x}^{(t+1)})}{p(\mathbf{x}^{(t)})} \cdot \frac{q(\mathbf{x}^{(t)}|\mathbf{x}^{(t+1)})}{q(\mathbf{x}^{(t+1)}|\mathbf{x}^{(t)})} \right\} \]</span> which is exactly the acceptance rate of <a href="/Deep_Learning/Monte_Carlo_Methods/Metropolis_Hastings_Algorithm/">Metropolis-Hastings algorithm</a>, with target distribution <span class="math inline">\(p(\mathbf{x})\)</span> and proposal distribution <span class="math inline">\(q(\mathbf{x}^{\star}|\mathbf{x})\)</span>.</p><h3 id="relationship-with-hamiltonian-monte-carlo">Relationship with Hamiltonian Monte Carlo</h3><p>Langevin dyanmics is actually a <a href="/Deep_Learning/Monte_Carlo_Methods/Hamiltonian_Dynamics/">Hamiltonian dynamics</a> system, with the potential and kinetic energy chosen as: <span class="math display">\[ \begin{align} U(q) &amp;= -\log \pi(q) \\ K(p|q) &amp;= K(p) = -\log \mathcal{N}(p|0,I) = \frac{1}{2} p^\top p + \text{const} = \frac{1}{2}\left\| p \right\|^2_2 + \text{const} \end{align} \]</span> and the integrator for the Hamiltonian equations chosen as one-step LeapFrog method.</p><p>The Hamiltonian equations, under this assumption, are given by: <span class="math display">\[ \begin{align} \frac{dq}{dt} &amp;= \frac{\partial K}{\partial p} = p \\ \frac{dp}{dt} &amp;= -\frac{\partial U}{\partial q} = \nabla \log \pi(q) \end{align} \]</span></p><p>Using one-step LeapFrog integrator, we obtain: <span class="math display">\[ \begin{align} p_{0.5} &amp;= p_0 - \frac{\epsilon}{2}\cdot \frac{\partial U}{\partial q}(q_0) \\ q_1 &amp;= q_0 + \epsilon \cdot \frac{\partial K}{\partial p}(p_{0.5}) = q_0 - \frac{\epsilon^2}{2} \cdot \frac{\partial U}{\partial q}(q_0) + \epsilon \cdot p_0 \\ p_1 &amp;= p_{0.5} - \frac{\epsilon}{2} \cdot \frac{\partial U}{\partial q}(q_1) = p_0 - \frac{\epsilon}{2} \cdot \frac{\partial U}{\partial q}(q_0) - \frac{\epsilon}{2} \cdot \frac{\partial U}{\partial q}(q_1) \end{align} \]</span> Negate <span class="math inline">\(p_1\)</span>, we obtain the candidate state <span class="math inline">\((q_1,-p_1)\)</span>. The <a href="/Deep_Learning/Monte_Carlo_Methods/Metropolis_Hastings_Algorithm/">Metropolis-Hastings acceptance rate</a> is then given by:</p><p><span class="math display">\[ \begin{align} \rho((q_0,p_0),(q_1,-p_1)) &amp;= \min\left\{ 1, \frac{\pi(q_1,-p_1)}{\pi(q_0,p_0)} \right\} \\ &amp;= \min\left\{ 1, \frac{\exp\left( -H(q_1,-p_1) \right)}{\exp\left( -H(q_0,p_0) \right)} \right\} \\ &amp;= \min\left\{ 1, \exp\left( U(q_0) - U(q_1) + K(p_0) - K(-p_1) \right) \right\} \\ &amp;= \min\left\{ 1, \exp\left( -\log \pi(q_0) + \log \pi(q_1) + \frac{1}{2} \left\| p_0 \right\|^2_2 - \frac{1}{2} \left\| -p_1 \right\|^2_2 \right) \right\} \end{align} \]</span> Substitute <span class="math inline">\(q_0 = \mathbf{x}^{(t)}\)</span>, <span class="math inline">\(q_1 = \mathbf{x}^{(t+1)}\)</span> and <span class="math inline">\(p_0=\mathbf{z}^{(t)}\)</span>, <span class="math inline">\(-p_1=\mathbf{z}^{(t+1)}\)</span>, we obtain the transition kernel and the acceptance rate for Langevin dynamics in the previous section.</p><h3 id="further-reading-materials">Further Reading Materials</h3><p>See <span class="citation" data-cites="nealMCMCUsingHamiltonian2011">Neal (<a href="#ref-nealMCMCUsingHamiltonian2011" role="doc-biblioref">2011</a>)</span>.</p><h1 id="bibliography" class="unnumbered">References</h1><div id="refs" class="references" role="doc-bibliography"><div id="ref-nealMCMCUsingHamiltonian2011"><p>Neal, Radford M. 2011. “MCMC Using Hamiltonian Dynamics.” <em>Handbook of Markov Chain Monte Carlo</em> 2 (11).</p></div></div></div><div style="height:10px"></div></div></article><nav id="page-nav"><a class="extend prev" rel="prev" href="/page/7/">&laquo; Prev</a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/6/">6</a><a class="page-number" href="/page/7/">7</a><span class="page-number current">8</span><a class="page-number" href="/page/9/">9</a><a class="page-number" href="/page/10/">10</a><span class="space">&hellip;</span><a class="page-number" href="/page/14/">14</a><a class="extend next" rel="next" href="/page/9/">Next &raquo;</a></nav></section></div><footer id="footer"><div class="outer"><div id="footer-info" class="inner">Haowen Xu &copy; 2020 <a rel="license" href="http://creativecommons.org/licenses/by-nc-nd/4.0/"><img alt="Creative Commons License" style="border-width:0" src="/images/by-nc-nd-4.0-80x15.png"></a><br>Powered by <a href="http://hexo.io/" target="_blank">Hexo</a> &amp; theme <a href="https://github.com/zthxxx/hexo-theme-Wikitten">Wikitten</a></div></div></footer><script src="/libs/lightgallery/js/lightgallery.min.js"></script><script src="/libs/lightgallery/js/lg-thumbnail.min.js"></script><script src="/libs/lightgallery/js/lg-pager.min.js"></script><script src="/libs/lightgallery/js/lg-autoplay.min.js"></script><script src="/libs/lightgallery/js/lg-fullscreen.min.js"></script><script src="/libs/lightgallery/js/lg-zoom.min.js"></script><script src="/libs/lightgallery/js/lg-hash.min.js"></script><script src="/libs/lightgallery/js/lg-share.min.js"></script><script src="/libs/lightgallery/js/lg-video.min.js"></script><script src="/libs/justified-gallery/jquery.justifiedGallery.min.js"></script><script type="text/x-mathjax-config">MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ["$","$"], ["\\(","\\)"] ],
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
            processEscapes: true,
            TeX: {
                equationNumbers: {
                    autoNumber: 'AMS'
                },
                style: {
                    'font-family': 'serif'
                }
            }
        },
        'HTML-CSS': {
            //preferredFont: 'TeX',
            fonts: ['TeX']
        }
    });
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax();
        for (var i = 0; i < all.length; ++i)
            all[i].SourceElement().parentNode.className += ' has-jax';
    });</script><script async src="//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><script src="/js/main.js"></script></div></body>