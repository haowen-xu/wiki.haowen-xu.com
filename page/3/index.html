<!DOCTYPE html><html lang="en"><head><meta name="generator" content="Hexo 3.9.0"><meta charset="utf-8"><title>My Research Wiki</title><meta name="keywords" content="My Research Wiki"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=1"><meta property="og:type" content="website"><meta property="og:title" content="My Research Wiki"><meta property="og:url" content="https://wiki.haowen-xu.com/page/3/index.html"><meta property="og:site_name" content="My Research Wiki"><meta property="og:locale" content="en"><meta name="twitter:card" content="summary"><meta name="twitter:title" content="My Research Wiki"><link rel="alternate" href="/atom.xml" title="My Research Wiki" type="application/atom+xml"><link rel="icon" href="/favicon.ico"><link rel="stylesheet" href="/libs/font-awesome/css/font-awesome.min.css"><link rel="stylesheet" href="/libs/open-sans/styles.css"><link rel="stylesheet" href="/libs/source-code-pro/styles.css"><link rel="stylesheet" href="/css/style.css"><script src="/libs/jquery/2.1.3/jquery.min.js"></script><script src="/libs/jquery/plugins/cookie/1.4.1/jquery.cookie.js"></script><link rel="stylesheet" href="/libs/lightgallery/css/lightgallery.min.css"><link rel="stylesheet" href="/libs/justified-gallery/justifiedGallery.min.css"></head></html><body><div id="container"><header id="header"><div id="header-main" class="header-inner"><div class="outer"><a href="/" id="logo"><i class="logo"></i> <span class="site-title">My Research Wiki</span></a><nav id="main-nav"><a class="main-nav-link" href="/">Home</a> <a class="main-nav-link" href="/archives">Archives</a> <a class="main-nav-link" href="/categories">Categories</a></nav><div id="search-form-wrap"><form class="search-form"><input type="text" class="ins-search-input search-form-input" placeholder="Search"> <button type="submit" class="search-form-submit"></button></form><div class="ins-search"><div class="ins-search-mask"></div><div class="ins-search-container"><div class="ins-input-wrapper"><input type="text" class="ins-search-input" placeholder="Type something..."> <span class="ins-close ins-selectable"><i class="fa fa-times-circle"></i></span></div><div class="ins-section-wrapper"><div class="ins-section-container"></div></div></div></div><script>window.INSIGHT_CONFIG={TRANSLATION:{POSTS:"Posts",PAGES:"Pages",CATEGORIES:"Categories",TAGS:"Tags",UNTITLED:"(Untitled)"},ROOT_URL:"/",CONTENT_URL:"/content.json"}</script><script src="/js/insight.js"></script></div></div></div><div id="main-nav-mobile" class="header-sub header-inner"><table class="menu outer"><tr><td><a class="main-nav-link" href="/">Home</a></td><td><a class="main-nav-link" href="/archives">Archives</a></td><td><a class="main-nav-link" href="/categories">Categories</a></td><td><div class="search-form"><input type="text" class="ins-search-input search-form-input" placeholder="Search"></div></td></tr></table></div></header><div class="outer"><aside id="sidebar"><div class="widget-wrap" id="categories"><h3 class="widget-title"><span>categories</span> &nbsp; <a id="allExpand" href="#"><i class="fa fa-angle-double-down fa-2x"></i></a></h3><ul class="unstyled" id="tree"><li class="directory"><a href="#" data-role="directory"><i class="fa fa-folder"></i> &nbsp; Deep Learning</a><ul class="unstyled" id="tree"><li class="directory"><a href="#" data-role="directory"><i class="fa fa-folder"></i> &nbsp; CV</a><ul class="unstyled" id="tree"><li class="file"><a href="/Deep_Learning/CV/Image_Segmentation/">Image Segmentation</a></li></ul></li><li class="directory"><a href="#" data-role="directory"><i class="fa fa-folder"></i> &nbsp; Confronting Partition Function</a><ul class="unstyled" id="tree"><li class="file"><a href="/Deep_Learning/Confronting_Partition_Function/Overview/">Overview</a></li><li class="file"><a href="/Deep_Learning/Confronting_Partition_Function/Contrastive_Divergence/">Contrastive Divergence</a></li><li class="file"><a href="/Deep_Learning/Confronting_Partition_Function/Score_Matching/">Score Matching</a></li><li class="file"><a href="/Deep_Learning/Confronting_Partition_Function/Softmax_Speedup/">Softmax Speedup</a></li></ul></li><li class="directory"><a href="#" data-role="directory"><i class="fa fa-folder"></i> &nbsp; Energy Based Models</a><ul class="unstyled" id="tree"><li class="file"><a href="/Deep_Learning/Energy_Based_Models/Overview/">Overview</a></li><li class="file"><a href="/Deep_Learning/Energy_Based_Models/Energy_Function_in_Probabilistic_Models/">Energy Function in Probabilistic Models</a></li><li class="file"><a href="/Deep_Learning/Energy_Based_Models/Restricted_Boltzmann_Machine/">Restricted Boltzmann Machine</a></li></ul></li><li class="directory"><a href="#" data-role="directory"><i class="fa fa-folder"></i> &nbsp; Evaluation</a><ul class="unstyled" id="tree"><li class="file"><a href="/Deep_Learning/Evaluation/Evaluation_Metrics/">Evaluation Metrics</a></li><li class="file"><a href="/Deep_Learning/Evaluation/Visualizing_High_Dimensional_Space/">Visualizing High Dimensional Space</a></li></ul></li><li class="directory"><a href="#" data-role="directory"><i class="fa fa-folder"></i> &nbsp; Generative Adversarial Nets</a><ul class="unstyled" id="tree"><li class="file"><a href="/Deep_Learning/Generative_Adversarial_Nets/Overview/">Overview</a></li><li class="file"><a href="/Deep_Learning/Generative_Adversarial_Nets/f-GAN/">f-GAN</a></li><li class="file"><a href="/Deep_Learning/Generative_Adversarial_Nets/Energy_GAN/">Energy GAN</a></li></ul></li><li class="directory"><a href="#" data-role="directory"><i class="fa fa-folder"></i> &nbsp; Graph Neural Networks</a><ul class="unstyled" id="tree"><li class="file"><a href="/Deep_Learning/Graph_Neural_Networks/Node_Embedding/">Node Embedding</a></li><li class="file"><a href="/Deep_Learning/Graph_Neural_Networks/Graph_Convolution_Network/">Graph Convolution Network</a></li><li class="file"><a href="/Deep_Learning/Graph_Neural_Networks/Graph_Auto_Encoder/">Graph Auto-Encoder</a></li></ul></li><li class="directory"><a href="#" data-role="directory"><i class="fa fa-folder"></i> &nbsp; Information Theoretical</a><ul class="unstyled" id="tree"><li class="file"><a href="/Deep_Learning/Information_Theoretical/KL-Divergence/">KL-Divergence</a></li><li class="file"><a href="/Deep_Learning/Information_Theoretical/Mutual_Information/">Mutual Information</a></li></ul></li><li class="directory"><a href="#" data-role="directory"><i class="fa fa-folder"></i> &nbsp; Monte Carlo Methods</a><ul class="unstyled" id="tree"><li class="file"><a href="/Deep_Learning/Monte_Carlo_Methods/Overview/">Overview</a></li><li class="file"><a href="/Deep_Learning/Monte_Carlo_Methods/Monte_Carlo_Integration/">Monte Carlo Integration</a></li><li class="file"><a href="/Deep_Learning/Monte_Carlo_Methods/Accept_Reject_Sampling/">Accept-Reject Sampling</a></li><li class="file"><a href="/Deep_Learning/Monte_Carlo_Methods/Markov_Chain/">Markov Chain</a></li><li class="file"><a href="/Deep_Learning/Monte_Carlo_Methods/Metropolis_Hastings_Algorithm/">Metropolis-Hastings Algorithm</a></li><li class="file"><a href="/Deep_Learning/Monte_Carlo_Methods/Gibbs_Sampler/">Gibbs Sampler</a></li><li class="file"><a href="/Deep_Learning/Monte_Carlo_Methods/Hamiltonian_Dynamics/">Hamiltonian Dynamics</a></li><li class="file"><a href="/Deep_Learning/Monte_Carlo_Methods/Langevin_Dynamics/">Langevin Dynamics</a></li></ul></li><li class="directory"><a href="#" data-role="directory"><i class="fa fa-folder"></i> &nbsp; Optimization</a><ul class="unstyled" id="tree"><li class="file"><a href="/Deep_Learning/Optimization/Gradient_Tricks/">Gradient Tricks</a></li><li class="file"><a href="/Deep_Learning/Optimization/Loss_Surface_and_Generalization/">Loss Surface and Generalization</a></li><li class="file"><a href="/Deep_Learning/Optimization/Stochastic_Gradient_Descent/">Stochastic Gradient descent</a></li></ul></li><li class="directory"><a href="#" data-role="directory"><i class="fa fa-folder"></i> &nbsp; Variational Autoencoder</a><ul class="unstyled" id="tree"><li class="file"><a href="/Deep_Learning/Variational_Autoencoder/Overview/">Overview</a></li><li class="file"><a href="/Deep_Learning/Variational_Autoencoder/Sequential_VAE/">Sequential VAE</a></li><li class="file"><a href="/Deep_Learning/Variational_Autoencoder/Gradient_Estimators_for_Variational_Inference/">Gradient Estimators for Variational Inference</a></li><li class="file"><a href="/Deep_Learning/Variational_Autoencoder/Theoretical_Facts/">Theoretical Facts about VAEs</a></li></ul></li></ul></li><li class="directory"><a href="#" data-role="directory"><i class="fa fa-folder"></i> &nbsp; Mathematics</a><ul class="unstyled" id="tree"><li class="directory"><a href="#" data-role="directory"><i class="fa fa-folder"></i> &nbsp; Analysis</a><ul class="unstyled" id="tree"><li class="file"><a href="/Mathematics/Analysis/Linear_Space_vs_Functional_Space/">Linear space vs functional space</a></li></ul></li><li class="directory"><a href="#" data-role="directory"><i class="fa fa-folder"></i> &nbsp; Calculus</a><ul class="unstyled" id="tree"><li class="file"><a href="/Mathematics/Calculus/Calculus_of_Variations/">Calculus of Variations</a></li></ul></li><li class="directory"><a href="#" data-role="directory"><i class="fa fa-folder"></i> &nbsp; Differential Equations</a><ul class="unstyled" id="tree"><li class="file"><a href="/Mathematics/Differential_Equations/Probability_Distribution_Equations/">Differential Equations on Probability Distributions</a></li></ul></li><li class="directory"><a href="#" data-role="directory"><i class="fa fa-folder"></i> &nbsp; Optimization</a><ul class="unstyled" id="tree"><li class="file"><a href="/Mathematics/Optimization/Convex_Optimization/">Convex Optimization</a></li></ul></li></ul></li><li class="directory"><a href="#" data-role="directory"><i class="fa fa-folder"></i> &nbsp; Research Work</a><ul class="unstyled" id="tree"><li class="file"><a href="/Research_Work/Reading_List/">Reading List</a></li><li class="file"><a href="/Research_Work/Tracking_the_Concepts/">Tracking the Concepts</a></li><li class="file"><a href="/Research_Work/Directions_to_Explore/">Directions to Explore</a></li></ul></li></ul></div><script>$(document).ready(function(){var r="fa-folder-open",i="fa-folder",l="fa-angle-double-down",d="fa-angle-double-up";$(document).on("click",'#categories a[data-role="directory"]',function(a){a.preventDefault();var e=$(this).children(".fa"),s=e.hasClass(r),l=$(this).siblings("ul");e.removeClass(r).removeClass(i),s?(void 0!==l&&l.slideUp({duration:100}),e.addClass(i)):(void 0!==l&&l.slideDown({duration:100}),e.addClass(r))}),$('#categories a[data-role="directory"]').bind("contextmenu",function(a){a.preventDefault();var e=$(this).children(".fa"),s=e.hasClass(r),l=$(this).siblings("ul"),d=$.merge(l.find("li ul"),l),o=$.merge(l.find(".fa"),e);o.removeClass(r).removeClass(i),s?(d.slideUp({duration:100}),o.addClass(i)):(d.slideDown({duration:100}),o.addClass(r))}),$(document).on("click","#allExpand",function(a){a.preventDefault();var e=$(this).children(".fa"),s=e.hasClass(l);e.removeClass(l).removeClass(d),s?($("#sidebar .fa.fa-folder").removeClass("fa-folder").addClass("fa-folder-open"),$("#categories li ul").slideDown({duration:100}),e.addClass(d)):($("#sidebar .fa.fa-folder-open").removeClass("fa-folder-open").addClass("fa-folder"),$("#categories li ul").slideUp({duration:100}),e.addClass(l))})})</script><div id="toTop" class="fa fa-angle-up"></div></aside><section id="main"><article id="post-Deep_Learning/Optimization/Gradient_Tricks" class="article article-type-post" itemscope itemprop="blogPost"><div class="article-inner"><header class="article-header"><div class="article-meta"><div class="article-category"><i class="fa fa-folder"></i> <a class="article-category-link" href="/categories/Deep-Learning/">Deep Learning</a><i class="fa fa-angle-right"></i><a class="article-category-link" href="/categories/Deep-Learning/Optimization/">Optimization</a></div><div class="article-date"><i class="fa fa-calendar"></i> <a href="/Deep_Learning/Optimization/Gradient_Tricks/"><time datetime="2020-03-18T17:28:16.000Z" itemprop="datePublished">2020-03-19</time></a></div><div class="article-meta-button"><a href="https://github.com/haowen-xu/research-notes/raw/master/source/_posts/Deep_Learning/Optimization/Gradient_Tricks.md">Source</a></div><div class="article-meta-button"><a href="https://github.com/haowen-xu/research-notes/edit/master/source/_posts/Deep_Learning/Optimization/Gradient_Tricks.md">Edit</a></div><div class="article-meta-button"><a href="https://github.com/haowen-xu/research-notes/commits/master/source/_posts/Deep_Learning/Optimization/Gradient_Tricks.md">History</a></div></div><h1 itemprop="name"><a class="article-title" href="/Deep_Learning/Optimization/Gradient_Tricks/">Gradient Tricks</a></h1></header><div class="article-entry" itemprop="articleBody"><h2 id="clipping">Clipping</h2><h3 id="adaptive-clipping">Adaptive Clipping</h3><p>To avoid the optimizer putting too much attention on just one of the loss components (or adversarial losses), <em>adaptive clipping</em> can be adopted <span class="citation" data-cites="belghaziMineMutualInformation2018">(Belghazi et al. <a href="#ref-belghaziMineMutualInformation2018" role="doc-biblioref">2018</a>)</span>, to match the gradient scales of different losses.</p><p>For example, <span class="citation" data-cites="belghaziMineMutualInformation2018">Belghazi et al. (<a href="#ref-belghaziMineMutualInformation2018" role="doc-biblioref">2018</a>)</span> adapts <span class="math inline">\(g_m\)</span> to match the scale of <span class="math inline">\(g_u\)</span>, where <span class="math inline">\(g_u\)</span> is the main loss gradient, and <span class="math inline">\(g_m\)</span> is the gradient of the mutual information regularizer: <span class="math display">\[ \tilde{g}_m = \min\left( \|g_u\|, \|g_m\| \right) \frac{g_m}{\|g_m\|} \]</span></p><h1 id="bibliography" class="unnumbered">References</h1><div id="refs" class="references" role="doc-bibliography"><div id="ref-belghaziMineMutualInformation2018"><p>Belghazi, Mohamed Ishmael, Aristide Baratin, Sai Rajeswar, Sherjil Ozair, Yoshua Bengio, Aaron Courville, and R. Devon Hjelm. 2018. “Mine: Mutual Information Neural Estimation.” <em>arXiv Preprint arXiv:1801.04062</em>.</p></div></div></div><div style="height:10px"></div></div></article><article id="post-Deep_Learning/Generative_Adversarial_Nets/f-GAN" class="article article-type-post" itemscope itemprop="blogPost"><div class="article-inner"><header class="article-header"><div class="article-meta"><div class="article-category"><i class="fa fa-folder"></i> <a class="article-category-link" href="/categories/Deep-Learning/">Deep Learning</a><i class="fa fa-angle-right"></i><a class="article-category-link" href="/categories/Deep-Learning/Generative-Adversarial-Nets/">Generative Adversarial Nets</a></div><div class="article-date"><i class="fa fa-calendar"></i> <a href="/Deep_Learning/Generative_Adversarial_Nets/f-GAN/"><time datetime="2020-03-16T22:58:04.000Z" itemprop="datePublished">2020-03-17</time></a></div><div class="article-meta-button"><a href="https://github.com/haowen-xu/research-notes/raw/master/source/_posts/Deep_Learning/Generative_Adversarial_Nets/f-GAN.md">Source</a></div><div class="article-meta-button"><a href="https://github.com/haowen-xu/research-notes/edit/master/source/_posts/Deep_Learning/Generative_Adversarial_Nets/f-GAN.md">Edit</a></div><div class="article-meta-button"><a href="https://github.com/haowen-xu/research-notes/commits/master/source/_posts/Deep_Learning/Generative_Adversarial_Nets/f-GAN.md">History</a></div></div><h1 itemprop="name"><a class="article-title" href="/Deep_Learning/Generative_Adversarial_Nets/f-GAN/">f-GAN</a></h1></header><div class="article-entry" itemprop="articleBody"><p>Proposed by <span class="citation" data-cites="nowozinFGANTrainingGenerative2016">Nowozin, Cseke, and Tomioka (<a href="#ref-nowozinFGANTrainingGenerative2016" role="doc-biblioref">2016</a>)</span>, f-GAN generalizes the KL-divergence of the original GAN framework <span class="citation" data-cites="goodfellowGenerativeAdversarialNets2014">(Goodfellow et al. <a href="#ref-goodfellowGenerativeAdversarialNets2014" role="doc-biblioref">2014</a>)</span> to the f-divergence.</p><h2 id="theoretical-framework">Theoretical Framework</h2><h3 id="f-divergence">f-Divergence</h3><p><span class="math display">\[ D_{f}(P \| Q) = \int q(\mathbf{x}) \,f\left( \frac{p(\mathbf{x})}{q(\mathbf{x})} \right)\,\mathrm{d}\mathbf{x} \]</span></p><p>where <span class="math inline">\(f: \mathbb{R}^+ \to \mathbb{R}\)</span> is a convex, lower-semicontinuous function satisfying <span class="math inline">\(f(\mathbf{1})=0\)</span>.</p><h3 id="fenchel-conjugate">Fenchel conjugate</h3><p>The Fenchel conjugate of <span class="math inline">\(f(u)\)</span> is: <span class="math display">\[ f^*(t) = \sup_{u \in \text{dom}_f}\left\{ ut - f(u) \right\} \]</span> Since <span class="math inline">\(f\)</span> is a convex and lower-semicontinuous function, <span class="math inline">\(f^{**} = f\)</span>, therefore: <span class="math display">\[ f(u) = \sup_{t \in \text{dom}_{f^*}} \left\{ tu - f^*(t) \right\} \]</span> And further we have: <span class="math display">\[ D_{f}(P \| Q) = \int q(\mathbf{x}) \, \sup_{t \in \text{dom}_{f^*}} \left\{ t\,\frac{p(\mathbf{x})}{q(\mathbf{x})} - f^*(t) \right\} \,\mathrm{d}\mathbf{x} \]</span></p><h3 id="variational-estimation-of-f-divergence">Variational Estimation of f-Divergence</h3><p>Using a function <span class="math inline">\(T: \mathcal{X} \to \mathbb{R}\)</span> of family <span class="math inline">\(\mathcal{T}\)</span>, we can can obtain the following lower-bound <span class="citation" data-cites="nowozinFGANTrainingGenerative2016">(Nowozin, Cseke, and Tomioka <a href="#ref-nowozinFGANTrainingGenerative2016" role="doc-biblioref">2016</a>)</span>: <span class="math display">\[ \begin{align} D_{f}(P \| Q) &amp;= \int q(\mathbf{x}) \, \sup_{t \in \text{dom}_{f^*}} \left\{ t\,\frac{p(\mathbf{x})}{q(\mathbf{x})} - f^*(t) \right\} \,\mathrm{d}\mathbf{x} \\ &amp;\geq \sup_{T \in \mathcal{T}} \left\{ \int q(\mathbf{x}) \left( T(\mathbf{x})\,\frac{p(\mathbf{x})}{q(\mathbf{x})} - f^*(T(\mathbf{x})) \right) \,\mathrm{d}\mathbf{x} \right\} \\ &amp;= \sup_{T \in \mathcal{T}} \left\{ \int p(\mathbf{x})\,T(\mathbf{x}) \,\mathrm{d}\mathbf{x} - \int q(\mathbf{x}) \,f^*(T(\mathbf{x})) \,\mathrm{d}\mathbf{x} \right\} \\ &amp;= \sup_{T \in \mathcal{T}} \left\{ \mathbb{E}_{p(\mathbf{x})}\left[ T(\mathbf{x}) \right] - \mathbb{E}_{q(\mathbf{x})} \left[ f^*(T(\mathbf{x})) \right] \right\} \end{align} \]</span> It is a lower-bound, because the family <span class="math inline">\(\mathcal{T}\)</span> might not cover all of the possible functions. In fact, the bound is tight for <span class="math display">\[ T^*(\mathbf{x}) = f'\left(\frac{p(\mathbf{x})}{q(\mathbf{x})}\right) \]</span> where <span class="math inline">\(f'\)</span> is the first derivative of <span class="math inline">\(f\)</span>.</p><h3 id="variational-divergence-minimization">Variational Divergence Minimization</h3><p>Using the variational lower-bound of the f-divergence <span class="math inline">\(D_{f}(P \| Q)\)</span>, we can obtain the objective <span class="math inline">\(\mathcal{F}(\theta,\omega)\)</span>, for the generator <span class="math inline">\(q_{\theta}(\mathbf{x})\)</span>, which should be <strong>minimized</strong> w.r.t. <span class="math inline">\(\theta\)</span>, and <strong>maximized</strong> w.r.t. <span class="math inline">\(\omega\)</span>:</p><p><span class="math display">\[ \mathcal{F}(\theta,\omega) = \mathbb{E}_{p_d(\mathbf{x})}\left[ T_{\omega}(\mathbf{x}) \right] - \mathbb{E}_{q_{\theta}(\mathbf{x})}\left[ f^*(T_{\omega}(\mathbf{x})) \right] \]</span></p><p><strong>Note: <span class="math inline">\(\mathcal{F}(\theta,\omega)\)</span> is just a lower-bound of <span class="math inline">\(D_{f}(P \| Q)\)</span>. Minimizing a lower-bound may not lead to optimal result (commented by me).</strong></p><p>To ensure <span class="math inline">\(T_{\omega}\)</span> match the domain of <span class="math inline">\(f^*\)</span>, it can be further reparameterized as: <span class="math display">\[ T_{\omega}(\mathbf{x}) = g_f(V_{\omega}(\mathbf{x})) \]</span> where <span class="math inline">\(V_{\omega}: \mathcal{X} \to \mathbb{R}\)</span>, and <span class="math inline">\(g_f: \mathbb{R} \to \text{dom}_{f^*}\)</span> being the activation function chosen according to <span class="math inline">\(f\)</span>. Then the above objective can be rewritten as: <span class="math display">\[ \mathcal{F}(\theta,\omega) = \mathbb{E}_{p_d(\mathbf{x})}\left[ g_f(V_{\omega}(\mathbf{x})) \right] + \mathbb{E}_{q_{\theta}(\mathbf{x})}\left[ -f^*(g_f(V_{\omega}(\mathbf{x}))) \right] \]</span></p><h3 id="single-step-gradient-method">Single-Step Gradient Method</h3><p>Instead of alternate between optimizing <span class="math inline">\(\omega\)</span> and <span class="math inline">\(\theta\)</span> in different steps, <span class="citation" data-cites="nowozinFGANTrainingGenerative2016">Nowozin, Cseke, and Tomioka (<a href="#ref-nowozinFGANTrainingGenerative2016" role="doc-biblioref">2016</a>)</span> proposed to optimize these two set of parameters in a single step by: <span class="math display">\[ \begin{align} \omega^{t+1} &amp;= \omega^{t} + \eta \,\nabla_{\omega} \mathcal{F}(\theta^t,\omega^t) \\ &amp;= \omega^{t} + \eta \,\nabla_{\omega} \left( \mathbb{E}_{p_d(\mathbf{x})}\left[ g_f(V_{\omega}(\mathbf{x})) \right] + \mathbb{E}_{q_{\theta}(\mathbf{x})}\left[ -f^*(g_f(V_{\omega}(\mathbf{x}))) \right] \right) \\ \theta^{t+1} &amp;= \theta^{t} - \eta \,\nabla_{\theta} \mathcal{F}(\theta^t,\omega^t) \\ &amp;= \theta^{t} - \eta \,\nabla_{\theta} \left( \mathbb{E}_{q_{\theta}(\mathbf{x})}\left[ -f^*(g_f(V_{\omega}(\mathbf{x}))) \right] \right) \end{align} \]</span></p><p>And similar to <span class="citation" data-cites="goodfellowGenerativeAdversarialNets2014">Goodfellow et al. (<a href="#ref-goodfellowGenerativeAdversarialNets2014" role="doc-biblioref">2014</a>)</span>, <span class="citation" data-cites="nowozinFGANTrainingGenerative2016">Nowozin, Cseke, and Tomioka (<a href="#ref-nowozinFGANTrainingGenerative2016" role="doc-biblioref">2016</a>)</span> also proposed an alternative method to update the paramter <span class="math inline">\(\theta\)</span>, so as to speed up training: <span class="math display">\[ \theta^{t+1} = \theta^{t} + \eta \,\nabla_{\theta} \mathbb{E}_{q_{\theta}(\mathbf{x})}\left[ g_f(V_{\omega}(\mathbf{x})) \right] \]</span> Also note that, in many architectures, the gradient estimator <span class="math inline">\(\nabla_{\theta} \mathbb{E}_{q_{\theta}(\mathbf{x})}\)</span> can be computed with the re-paramterization trick, i.e., reparameterize <span class="math inline">\(\mathbf{x}\)</span> by a differentiable function <span class="math inline">\(\mathbf{x} = \mathbf{x}_{\theta}(\mathbf{\epsilon})\)</span>, where <span class="math inline">\(\mathbf{\epsilon}\)</span> is a random noise independent of <span class="math inline">\(\theta\)</span>.</p><h2 id="formulations-for-various-f-divergence">Formulations for Various f-Divergence</h2><p>More details can be found in <span class="citation" data-cites="nowozinFGANTrainingGenerative2016">Nowozin, Cseke, and Tomioka (<a href="#ref-nowozinFGANTrainingGenerative2016" role="doc-biblioref">2016</a>)</span>, including the formulations for Pearson <span class="math inline">\(\chi^2\)</span>, and the Squared Hellinger.</p><h3 id="kullback-leibler">Kullback-Leibler</h3><p><span class="math display">\[ \begin{align} D_{f}(P \| Q) &amp;= D_{\mathrm{KL}}(P\|Q) \\ &amp;= \int p(\mathbf{x}) \log \frac{p(\mathbf{x})}{q(\mathbf{x})}\,\mathrm{d}\mathbf{x} \\ f(u) &amp;= u \log u \\ f^*(t) &amp;= \exp(t - 1) \\ g_f(v) &amp;= v \end{align} \]</span></p><h3 id="reverse-kl">Reverse KL</h3><p><span class="math display">\[ \begin{align} D_{f}(P \| Q) &amp;= D_{\mathrm{KL}}(Q\|P) \\ &amp;= \int q(\mathbf{x}) \log \frac{q(\mathbf{x})}{p(\mathbf{x})}\,\mathrm{d}\mathbf{x} \\ f(u) &amp;= -\log u \\ f^*(t) &amp;= -1 - \log(-t) \\ g_f(v) &amp;= -\exp(-v) \end{align} \]</span></p><h3 id="jensen-shannon">Jensen-Shannon</h3><p><span class="math display">\[ \begin{align} D_{f}(P \| Q) &amp;= \text{JSD}(P\|Q) = \frac{1}{2}\Big( D_{\mathrm{KL}}(P\|M) +D_{\mathrm{KL}}(Q\|M) \Big) \\ &amp;= \frac{1}{2}\int \left( p(\mathbf{x}) \log \frac{2p(\mathbf{x})}{p(\mathbf{x}) + q(\mathbf{x})} + q(\mathbf{x}) \log \frac{2 q(\mathbf{x})}{p(\mathbf{x}) + q(\mathbf{x})} \right)\,\mathrm{d}\mathbf{x} \\ f(u) &amp;= u\log u - (u+1)\log \frac{u+1}{2} \\ f^*(t) &amp;= -\log(2-\exp(t)) \\ g_f(v) &amp;= \log 2 - \log (1+\exp(-v)) \end{align} \]</span></p><p>where <span class="math inline">\(M = \frac{P+Q}{2}\)</span>.</p><h3 id="original-gan-goodfellowgenerativeadversarialnets2014">Original GAN <span class="citation" data-cites="goodfellowGenerativeAdversarialNets2014">(Goodfellow et al. <a href="#ref-goodfellowGenerativeAdversarialNets2014" role="doc-biblioref">2014</a>)</span></h3><p><span class="math display">\[ \begin{align} D_{f}(P \| Q) &amp;= \int \left( p(\mathbf{x}) \log \frac{2p(\mathbf{x})}{p(\mathbf{x}) + q(\mathbf{x})} + q(\mathbf{x}) \log \frac{2 q(\mathbf{x})}{p(\mathbf{x}) + q(\mathbf{x})} \right)\mathrm{d}\mathbf{x} - \log 4 \\ f(u) &amp;= u \log u - (u+1) \log (u+1) \\ f^*(t) &amp;= -\log(1-\exp(t)) \\ g_f(v) &amp;= -\log(1+\exp(-v)) \end{align} \]</span></p><h1 id="bibliography" class="unnumbered">References</h1><div id="refs" class="references" role="doc-bibliography"><div id="ref-goodfellowGenerativeAdversarialNets2014"><p>Goodfellow, Ian, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair, Aaron Courville, and Yoshua Bengio. 2014. “Generative Adversarial Nets.” In <em>Advances in Neural Information Processing Systems</em>, 2672–80.</p></div><div id="ref-nowozinFGANTrainingGenerative2016"><p>Nowozin, Sebastian, Botond Cseke, and Ryota Tomioka. 2016. “F-GAN: Training Generative Neural Samplers Using Variational Divergence Minimization.” In <em>Advances in Neural Information Processing Systems 29</em>, edited by D. D. Lee, M. Sugiyama, U. V. Luxburg, I. Guyon, and R. Garnett, 271–79. Curran Associates, Inc.</p></div></div></div><div style="height:10px"></div></div></article><article id="post-Deep_Learning/Information_Theoretical/Mutual_Information" class="article article-type-post" itemscope itemprop="blogPost"><div class="article-inner"><header class="article-header"><div class="article-meta"><div class="article-category"><i class="fa fa-folder"></i> <a class="article-category-link" href="/categories/Deep-Learning/">Deep Learning</a><i class="fa fa-angle-right"></i><a class="article-category-link" href="/categories/Deep-Learning/Information-Theoretical/">Information Theoretical</a></div><div class="article-date"><i class="fa fa-calendar"></i> <a href="/Deep_Learning/Information_Theoretical/Mutual_Information/"><time datetime="2020-03-16T20:02:24.000Z" itemprop="datePublished">2020-03-17</time></a></div><div class="article-meta-button"><a href="https://github.com/haowen-xu/research-notes/raw/master/source/_posts/Deep_Learning/Information_Theoretical/Mutual_Information.md">Source</a></div><div class="article-meta-button"><a href="https://github.com/haowen-xu/research-notes/edit/master/source/_posts/Deep_Learning/Information_Theoretical/Mutual_Information.md">Edit</a></div><div class="article-meta-button"><a href="https://github.com/haowen-xu/research-notes/commits/master/source/_posts/Deep_Learning/Information_Theoretical/Mutual_Information.md">History</a></div></div><h1 itemprop="name"><a class="article-title" href="/Deep_Learning/Information_Theoretical/Mutual_Information/">Mutual Information</a></h1></header><div class="article-entry" itemprop="articleBody"><h2 id="definition">Definition</h2><p><span class="math display">\[ \begin{align} I(X;Y) &amp;= D_{\mathrm{KL}}\left( p(x,y) \,\|\, p(x)\,p(y) \right) \\ &amp;= \int p(x,y)\, \log \frac{p(x,y)}{p(x)\,p(y)}\,dx \end{align} \]</span></p><h3 id="invariant-under-reparameterization">Invariant Under Reparameterization</h3><p>If <span class="math inline">\(f\)</span> and <span class="math inline">\(g\)</span> are homeormophism, then <span class="math display">\[ I(X;Y) = I(f(X);f(Y)) \]</span> that is, mutual information is invariant under reparameterization <span class="citation" data-cites="brakelLearningIndependentFeatures2017">(Brakel and Bengio <a href="#ref-brakelLearningIndependentFeatures2017" role="doc-biblioref">2017</a>)</span>.</p><h2 id="estimators">Estimators</h2><h3 id="infonce">InfoNCE</h3><p>(to be completed)</p><h3 id="mine">MINE</h3><p><span class="citation" data-cites="belghaziMineMutualInformation2018">Belghazi et al. (<a href="#ref-belghaziMineMutualInformation2018" role="doc-biblioref">2018</a>)</span> proposed a mutual information estimator based on the Donsker-Varadhan dual representation <span class="citation" data-cites="donskerAsymptoticEvaluationCertain1983">(Donsker and Varadhan <a href="#ref-donskerAsymptoticEvaluationCertain1983" role="doc-biblioref">1983</a>)</span>. <span class="math display">\[ \begin{align} I(X;Z) &amp;\geq \sup_{T_{\theta}} \left\{ \mathbb{E}_{p(x,z)}\left[T_{\psi}(x,z)\right] - \log \left( \mathbb{E}_{p(x)\,p(z)}\left[e^{T_{\psi}(x,z)}\right] \right) \right\} \\ &amp;\approx \sup_{T_{\theta}} \left\{ \frac{1}{b} \sum_{i=1}^b\left[T_{\psi}(x^{(i)},z^{(i)})\right] - \log \left( \frac{1}{b} \sum_{i=1}^b\left[e^{T_{\psi}(x^{(i)},\tilde{z}^{(i)})}\right] \right) \right\} \end{align} \]</span> where <span class="math inline">\(x^{(i)}, z^{(i)} \sim p(x,z)\)</span>, and <span class="math inline">\(\tilde{z}^{(i)} \sim p(z)\)</span>. <span class="math inline">\(b\)</span> is the batch size.</p><p>The gradient of MINE estimator might have too large a scale, in which situation the <a href="/Deep_Learning/Optimization/Gradient_Tricks/#adaptive-clipping">Adaptive Clipping</a> might be used. Also, <span class="citation" data-cites="belghaziMineMutualInformation2018">Belghazi et al. (<a href="#ref-belghaziMineMutualInformation2018" role="doc-biblioref">2018</a>)</span> proposed to correct the bias of the gradient estimator by an additional moving average term.</p><h3 id="deep-infomax">Deep InfoMax</h3><p><span class="citation" data-cites="hjelmLearningDeepRepresentations2018">Hjelm et al. (<a href="#ref-hjelmLearningDeepRepresentations2018" role="doc-biblioref">2018</a>)</span> proposed a mutual information estimator based on the JSD estimator, via <a href="/Deep_Learning/Generative_Adversarial_Nets/f-GAN/">f-GAN</a> formulation: <span class="math display">\[ \mathcal{I}^{(JSD)}(X;Z) = \mathbb{E}_{p(x,z)}\left[ -\text{sp}(-T_{\psi}(x,z)) \right] - \mathbb{E}_{p(x)\,p(z)}\left[ \text{sp}(T_{\psi}(x,z)) \right] \]</span> where <span class="math inline">\(\text{sp}(a) = \log(1 + e^a)\)</span>.</p><p>For encoder architecture <span class="math inline">\(z = E_{\theta}(x)\)</span> and <span class="math inline">\(p(x) = p_d(x)\)</span>, it can also be formulated as: <span class="math display">\[ \begin{align} \mathcal{I}^{(JSD)}(X;Z) &amp;= \mathbb{E}_{\mathbb{P}}\left[ -\text{sp}(-T_{\psi}(x,E_{\theta}(x))) \right] - \mathbb{E}_{\mathbb{P}\times\tilde{\mathbb{P}}}\left[ \text{sp}(T_{\psi}(\tilde{x},E_{\theta}(x))) \right] \\ &amp;\approx \frac{1}{b} \sum_{i=1}^b \left[ -\text{sp}\left(-T_{\psi}(x^{(i)},E_{\theta}(x^{(i)}))\right) \right] - \frac{1}{b} \sum_{i=1}^b \left[ \text{sp}\left({T_{\psi}(\tilde{x}^{(i)},E_{\theta}(x^{(i)}))}\right) \right] \end{align} \]</span> where <span class="math inline">\(\mathbb{P} = \tilde{\mathbb{P}} = p(x)\)</span>. <span class="math inline">\(x^{(i)}\)</span> and <span class="math inline">\(\tilde{x}^{(i)}\)</span> are samples from <span class="math inline">\(\mathbb{P}\)</span> and <span class="math inline">\(\tilde{\mathbb{P}}\)</span>, respectively. <span class="math inline">\(b\)</span> is the batch size.</p><p><strong>Note: Deep InfoMax actually has much more content then summarized here. The architecture, the global/local deep information maximum and the prior matching techniques can be referred to the original paper.</strong></p><h2 id="mutual-information-as-regularizers">Mutual Information as Regularizers</h2><h3 id="avoid-mode-collapse-in-gan">Avoid Mode Collapse in GAN</h3><p>Maximizing the entropy <span class="math inline">\(H(X) = H(G(Z))\)</span> of a GAN generator could help avoid mode collapse. <span class="citation" data-cites="chenInfoGANInterpretableRepresentation2016 belghaziMineMutualInformation2018 kumarMaximumEntropyGenerators2019">(Chen et al. <a href="#ref-chenInfoGANInterpretableRepresentation2016" role="doc-biblioref">2016</a>; Belghazi et al. <a href="#ref-belghaziMineMutualInformation2018" role="doc-biblioref">2018</a>; Kumar et al. <a href="#ref-kumarMaximumEntropyGenerators2019" role="doc-biblioref">2019</a>)</span></p><p>Since <span class="math inline">\(X=G(Z)\)</span> is a deterministic mapping, we have <span class="math inline">\(H(G(Z)|Z) \equiv 0\)</span>, and therefore: <span class="math display">\[ H(G(Z)) = I(G(Z);Z) - H(G(Z)|Z) = I(G(Z);Z) \]</span></p><h3 id="bound-the-reconstruction-error">Bound the Reconstruction Error</h3><p>Given the encoder <span class="math inline">\(q(\mathbf{z}|\mathbf{x})\)</span> and decoder <span class="math inline">\(p(\mathbf{x}|\mathbf{z})\)</span>, and the prior distribution <span class="math inline">\(p(\mathbf{z})\)</span>, assuming <span class="math inline">\(q(\mathbf{x}) = p(\mathbf{x}) = p_d(\mathbf{x})\)</span>, then the reconstruction error <span class="math inline">\(\mathcal{R}\)</span> defined as: <span class="math display">\[ \mathcal{R} = \mathbb{E}_{p_d(\mathbf{x})} \mathbb{E}_{q(\mathbf{z}|\mathbf{x})}\left[ -\log p(\mathbf{x}|\mathbf{z}) \right] \]</span> can be decomposed as: <span class="math display">\[ \begin{align} \mathcal{R} &amp;= \mathbb{E}_{q(\mathbf{x},\mathbf{z})}\left[ -\log p(\mathbf{x}|\mathbf{z}) \right] \\ &amp;= \mathbb{E}_{q(\mathbf{x},\mathbf{z})}\left[ -\log p(\mathbf{x},\mathbf{z}) + \log p(\mathbf{z}) \right] \\ &amp;= \mathbb{E}_{q(\mathbf{x},\mathbf{z})}\left[ \log \frac{q(\mathbf{x},\mathbf{z})}{p(\mathbf{x},\mathbf{z})} - \log q(\mathbf{z},\mathbf{x}) + \log p(\mathbf{z}) \right] \\ &amp;= D_{\mathrm{KL}}(q(\mathbf{x},\mathbf{z})\,\|\,p(\mathbf{x},\mathbf{z})) + H_{q}(Z,X) + \mathbb{E}_{q(\mathbf{x},\mathbf{z})}\left[ \log p(\mathbf{z}) \right] \end{align} \]</span> where <span class="math display">\[ \begin{align} \mathbb{E}_{q(\mathbf{x},\mathbf{z})}\left[ \log p(\mathbf{z}) \right] &amp;= \iint q(\mathbf{x},\mathbf{z}) \log p(\mathbf{z}) \,\mathrm{d}\mathbf{z}\,\mathrm{d}\mathbf{x} \\ &amp;= \int \left( \int q(\mathbf{x},\mathbf{z}) \,\mathrm{d}\mathbf{x} \right)\log p(\mathbf{z}) \,\mathrm{d}\mathbf{z} \\ &amp;= \mathbb{E}_{q(\mathbf{z})}\left[ \log p(\mathbf{z}) \right] \\ &amp;= \mathbb{E}_{q(\mathbf{z})}\left[ -\log \frac{q(\mathbf{z})}{p(\mathbf{z})} + \log q(\mathbf{z}) \right] \\ &amp;= -D_{\mathrm{KL}}(q(\mathbf{z})\,\|\,p(\mathbf{z})) - H_{q}(Z) \end{align} \]</span> and since <span class="math display">\[ H_q(Z,X) - H_q(Z) = H_q(Z|X) = H_q(Z) - I_q(Z|X) \]</span> we have <span class="citation" data-cites="belghaziMineMutualInformation2018">(Belghazi et al. <a href="#ref-belghaziMineMutualInformation2018" role="doc-biblioref">2018</a>)</span>: <span class="math display">\[ \begin{align} \mathcal{R} &amp;= D_{\mathrm{KL}}(q(\mathbf{x},\mathbf{z})\,\|\,p(\mathbf{x},\mathbf{z})) + H_{q}(Z,X) - D_{\mathrm{KL}}(q(\mathbf{z})\,\|\,p(\mathbf{z})) - H_{q}(Z) \\ &amp;= D_{\mathrm{KL}}(q(\mathbf{x},\mathbf{z})\,\|\,p(\mathbf{x},\mathbf{z})) - D_{\mathrm{KL}}(q(\mathbf{z})\,\|\,p(\mathbf{z})) + H_q(Z) - I_q(Z|X) \end{align} \]</span></p><p>As long as <span class="math inline">\(q(\mathbf{z})\)</span> is trained to match <span class="math inline">\(p(\mathbf{z})\)</span>, maximizing <span class="math inline">\(I_q(Z|X)\)</span> can be an efficient way to bound the reconstruction loss.</p><h3 id="information-bottleneck">Information Bottleneck</h3><p>For a latent variable model <span class="math inline">\(X \to Z \to Y\)</span>, mutual information can be served as a regularizer to limit the amount of information passed through <span class="math inline">\(Z\)</span>, leaving only the most relevant part reaching the output variable <span class="math inline">\(Y\)</span>.</p><p>Minimizing the Information Bottleneck Lagrangian for encoder <span class="math inline">\(q(z|x)\)</span> can serve the constraint: <span class="math display">\[ \mathcal{L}(q(z|x)) = H(Y|Z) + \beta I(X,Z) \]</span></p><h1 id="bibliography" class="unnumbered">References</h1><div id="refs" class="references" role="doc-bibliography"><div id="ref-belghaziMineMutualInformation2018"><p>Belghazi, Mohamed Ishmael, Aristide Baratin, Sai Rajeswar, Sherjil Ozair, Yoshua Bengio, Aaron Courville, and R. Devon Hjelm. 2018. “Mine: Mutual Information Neural Estimation.” <em>arXiv Preprint arXiv:1801.04062</em>.</p></div><div id="ref-brakelLearningIndependentFeatures2017"><p>Brakel, Philemon, and Yoshua Bengio. 2017. “Learning Independent Features with Adversarial Nets for Non-Linear Ica.” <em>arXiv Preprint arXiv:1710.05050</em>.</p></div><div id="ref-chenInfoGANInterpretableRepresentation2016"><p>Chen, Xi, Yan Duan, Rein Houthooft, John Schulman, Ilya Sutskever, and Pieter Abbeel. 2016. “InfoGAN: Interpretable Representation Learning by Information Maximizing Generative Adversarial Nets.” In <em>Advances in Neural Information Processing Systems 29</em>, edited by D. D. Lee, M. Sugiyama, U. V. Luxburg, I. Guyon, and R. Garnett, 2172–80. Curran Associates, Inc.</p></div><div id="ref-donskerAsymptoticEvaluationCertain1983"><p>Donsker, Monroe D., and SR Srinivasa Varadhan. 1983. “Asymptotic Evaluation of Certain Markov Process Expectations for Large Time. IV.” <em>Communications on Pure and Applied Mathematics</em> 36 (2): 183–212.</p></div><div id="ref-hjelmLearningDeepRepresentations2018"><p>Hjelm, R. Devon, Alex Fedorov, Samuel Lavoie-Marchildon, Karan Grewal, Phil Bachman, Adam Trischler, and Yoshua Bengio. 2018. “Learning Deep Representations by Mutual Information Estimation and Maximization.” <em>arXiv Preprint arXiv:1808.06670</em>.</p></div><div id="ref-kumarMaximumEntropyGenerators2019"><p>Kumar, Rithesh, Anirudh Goyal, Aaron Courville, and Yoshua Bengio. 2019. “Maximum Entropy Generators for Energy-Based Models.” <em>arXiv:1901.08508 [Cs, Stat]</em>, January. <a href="http://arxiv.org/abs/1901.08508" target="_blank" rel="noopener">http://arxiv.org/abs/1901.08508</a>.</p></div></div></div><div style="height:10px"></div></div></article><nav id="page-nav"><a class="extend prev" rel="prev" href="/page/2/">&laquo; Prev</a><a class="page-number" href="/">1</a><a class="page-number" href="/page/2/">2</a><span class="page-number current">3</span><a class="page-number" href="/page/4/">4</a><a class="page-number" href="/page/5/">5</a><span class="space">&hellip;</span><a class="page-number" href="/page/14/">14</a><a class="extend next" rel="next" href="/page/4/">Next &raquo;</a></nav></section></div><footer id="footer"><div class="outer"><div id="footer-info" class="inner">Haowen Xu &copy; 2020 <a rel="license" href="http://creativecommons.org/licenses/by-nc-nd/4.0/"><img alt="Creative Commons License" style="border-width:0" src="/images/by-nc-nd-4.0-80x15.png"></a><br>Powered by <a href="http://hexo.io/" target="_blank">Hexo</a> &amp; theme <a href="https://github.com/zthxxx/hexo-theme-Wikitten">Wikitten</a></div></div></footer><script src="/libs/lightgallery/js/lightgallery.min.js"></script><script src="/libs/lightgallery/js/lg-thumbnail.min.js"></script><script src="/libs/lightgallery/js/lg-pager.min.js"></script><script src="/libs/lightgallery/js/lg-autoplay.min.js"></script><script src="/libs/lightgallery/js/lg-fullscreen.min.js"></script><script src="/libs/lightgallery/js/lg-zoom.min.js"></script><script src="/libs/lightgallery/js/lg-hash.min.js"></script><script src="/libs/lightgallery/js/lg-share.min.js"></script><script src="/libs/lightgallery/js/lg-video.min.js"></script><script src="/libs/justified-gallery/jquery.justifiedGallery.min.js"></script><script type="text/x-mathjax-config">MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ["$","$"], ["\\(","\\)"] ],
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
            processEscapes: true,
            TeX: {
                equationNumbers: {
                    autoNumber: 'AMS'
                },
                style: {
                    'font-family': 'serif'
                }
            }
        },
        'HTML-CSS': {
            //preferredFont: 'TeX',
            fonts: ['TeX']
        }
    });
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax();
        for (var i = 0; i < all.length; ++i)
            all[i].SourceElement().parentNode.className += ' has-jax';
    });</script><script async src="//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><script src="/js/main.js"></script></div></body>