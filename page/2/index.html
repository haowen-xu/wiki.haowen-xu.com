<!DOCTYPE html><html lang="en"><head><meta name="generator" content="Hexo 3.9.0"><meta charset="utf-8"><title>My Research Wiki</title><meta name="keywords" content="My Research Wiki"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=1"><meta property="og:type" content="website"><meta property="og:title" content="My Research Wiki"><meta property="og:url" content="https://wiki.haowen-xu.com/page/2/index.html"><meta property="og:site_name" content="My Research Wiki"><meta property="og:locale" content="en"><meta name="twitter:card" content="summary"><meta name="twitter:title" content="My Research Wiki"><link rel="alternate" href="/atom.xml" title="My Research Wiki" type="application/atom+xml"><link rel="icon" href="/favicon.ico"><link rel="stylesheet" href="/libs/font-awesome/css/font-awesome.min.css"><link rel="stylesheet" href="/libs/open-sans/styles.css"><link rel="stylesheet" href="/libs/source-code-pro/styles.css"><link rel="stylesheet" href="/css/style.css"><script src="/libs/jquery/2.1.3/jquery.min.js"></script><script src="/libs/jquery/plugins/cookie/1.4.1/jquery.cookie.js"></script><link rel="stylesheet" href="/libs/lightgallery/css/lightgallery.min.css"><link rel="stylesheet" href="/libs/justified-gallery/justifiedGallery.min.css"></head></html><body><div id="container"><header id="header"><div id="header-main" class="header-inner"><div class="outer"><a href="/" id="logo"><i class="logo"></i> <span class="site-title">My Research Wiki</span></a><nav id="main-nav"><a class="main-nav-link" href="/">Home</a> <a class="main-nav-link" href="/archives">Archives</a> <a class="main-nav-link" href="/categories">Categories</a></nav><div id="search-form-wrap"><form class="search-form"><input type="text" class="ins-search-input search-form-input" placeholder="Search"> <button type="submit" class="search-form-submit"></button></form><div class="ins-search"><div class="ins-search-mask"></div><div class="ins-search-container"><div class="ins-input-wrapper"><input type="text" class="ins-search-input" placeholder="Type something..."> <span class="ins-close ins-selectable"><i class="fa fa-times-circle"></i></span></div><div class="ins-section-wrapper"><div class="ins-section-container"></div></div></div></div><script>window.INSIGHT_CONFIG={TRANSLATION:{POSTS:"Posts",PAGES:"Pages",CATEGORIES:"Categories",TAGS:"Tags",UNTITLED:"(Untitled)"},ROOT_URL:"/",CONTENT_URL:"/content.json"}</script><script src="/js/insight.js"></script></div></div></div><div id="main-nav-mobile" class="header-sub header-inner"><table class="menu outer"><tr><td><a class="main-nav-link" href="/">Home</a></td><td><a class="main-nav-link" href="/archives">Archives</a></td><td><a class="main-nav-link" href="/categories">Categories</a></td><td><div class="search-form"><input type="text" class="ins-search-input search-form-input" placeholder="Search"></div></td></tr></table></div></header><div class="outer"><aside id="sidebar"><div class="widget-wrap" id="categories"><h3 class="widget-title"><span>categories</span> &nbsp; <a id="allExpand" href="#"><i class="fa fa-angle-double-down fa-2x"></i></a></h3><ul class="unstyled" id="tree"><li class="directory"><a href="#" data-role="directory"><i class="fa fa-folder"></i> &nbsp; Deep Learning</a><ul class="unstyled" id="tree"><li class="directory"><a href="#" data-role="directory"><i class="fa fa-folder"></i> &nbsp; CV</a><ul class="unstyled" id="tree"><li class="file"><a href="/Deep_Learning/CV/Image_Segmentation/">Image Segmentation</a></li></ul></li><li class="directory"><a href="#" data-role="directory"><i class="fa fa-folder"></i> &nbsp; Confronting Partition Function</a><ul class="unstyled" id="tree"><li class="file"><a href="/Deep_Learning/Confronting_Partition_Function/Overview/">Overview</a></li><li class="file"><a href="/Deep_Learning/Confronting_Partition_Function/Contrastive_Divergence/">Contrastive Divergence</a></li><li class="file"><a href="/Deep_Learning/Confronting_Partition_Function/Score_Matching/">Score Matching</a></li><li class="file"><a href="/Deep_Learning/Confronting_Partition_Function/Softmax_Speedup/">Softmax Speedup</a></li></ul></li><li class="directory"><a href="#" data-role="directory"><i class="fa fa-folder"></i> &nbsp; Energy Based Models</a><ul class="unstyled" id="tree"><li class="file"><a href="/Deep_Learning/Energy_Based_Models/Overview/">Overview</a></li><li class="file"><a href="/Deep_Learning/Energy_Based_Models/Energy_Function_in_Probabilistic_Models/">Energy Function in Probabilistic Models</a></li><li class="file"><a href="/Deep_Learning/Energy_Based_Models/Restricted_Boltzmann_Machine/">Restricted Boltzmann Machine</a></li></ul></li><li class="directory"><a href="#" data-role="directory"><i class="fa fa-folder"></i> &nbsp; Evaluation</a><ul class="unstyled" id="tree"><li class="file"><a href="/Deep_Learning/Evaluation/Evaluation_Metrics/">Evaluation Metrics</a></li><li class="file"><a href="/Deep_Learning/Evaluation/Visualizing_High_Dimensional_Space/">Visualizing High Dimensional Space</a></li></ul></li><li class="directory"><a href="#" data-role="directory"><i class="fa fa-folder"></i> &nbsp; Generative Adversarial Nets</a><ul class="unstyled" id="tree"><li class="file"><a href="/Deep_Learning/Generative_Adversarial_Nets/Overview/">Overview</a></li><li class="file"><a href="/Deep_Learning/Generative_Adversarial_Nets/f-GAN/">f-GAN</a></li><li class="file"><a href="/Deep_Learning/Generative_Adversarial_Nets/Energy_GAN/">Energy GAN</a></li></ul></li><li class="directory"><a href="#" data-role="directory"><i class="fa fa-folder"></i> &nbsp; Graph Neural Networks</a><ul class="unstyled" id="tree"><li class="file"><a href="/Deep_Learning/Graph_Neural_Networks/Node_Embedding/">Node Embedding</a></li><li class="file"><a href="/Deep_Learning/Graph_Neural_Networks/Graph_Convolution_Network/">Graph Convolution Network</a></li><li class="file"><a href="/Deep_Learning/Graph_Neural_Networks/Graph_Auto_Encoder/">Graph Auto-Encoder</a></li></ul></li><li class="directory"><a href="#" data-role="directory"><i class="fa fa-folder"></i> &nbsp; Information Theoretical</a><ul class="unstyled" id="tree"><li class="file"><a href="/Deep_Learning/Information_Theoretical/KL-Divergence/">KL-Divergence</a></li><li class="file"><a href="/Deep_Learning/Information_Theoretical/Mutual_Information/">Mutual Information</a></li></ul></li><li class="directory"><a href="#" data-role="directory"><i class="fa fa-folder"></i> &nbsp; Monte Carlo Methods</a><ul class="unstyled" id="tree"><li class="file"><a href="/Deep_Learning/Monte_Carlo_Methods/Overview/">Overview</a></li><li class="file"><a href="/Deep_Learning/Monte_Carlo_Methods/Monte_Carlo_Integration/">Monte Carlo Integration</a></li><li class="file"><a href="/Deep_Learning/Monte_Carlo_Methods/Accept_Reject_Sampling/">Accept-Reject Sampling</a></li><li class="file"><a href="/Deep_Learning/Monte_Carlo_Methods/Markov_Chain/">Markov Chain</a></li><li class="file"><a href="/Deep_Learning/Monte_Carlo_Methods/Metropolis_Hastings_Algorithm/">Metropolis-Hastings Algorithm</a></li><li class="file"><a href="/Deep_Learning/Monte_Carlo_Methods/Gibbs_Sampler/">Gibbs Sampler</a></li><li class="file"><a href="/Deep_Learning/Monte_Carlo_Methods/Hamiltonian_Dynamics/">Hamiltonian Dynamics</a></li><li class="file"><a href="/Deep_Learning/Monte_Carlo_Methods/Langevin_Dynamics/">Langevin Dynamics</a></li></ul></li><li class="directory"><a href="#" data-role="directory"><i class="fa fa-folder"></i> &nbsp; Optimization</a><ul class="unstyled" id="tree"><li class="file"><a href="/Deep_Learning/Optimization/Gradient_Tricks/">Gradient Tricks</a></li><li class="file"><a href="/Deep_Learning/Optimization/Loss_Surface_and_Generalization/">Loss Surface and Generalization</a></li><li class="file"><a href="/Deep_Learning/Optimization/Stochastic_Gradient_Descent/">Stochastic Gradient descent</a></li></ul></li><li class="directory"><a href="#" data-role="directory"><i class="fa fa-folder"></i> &nbsp; Variational Autoencoder</a><ul class="unstyled" id="tree"><li class="file"><a href="/Deep_Learning/Variational_Autoencoder/Overview/">Overview</a></li><li class="file"><a href="/Deep_Learning/Variational_Autoencoder/Sequential_VAE/">Sequential VAE</a></li><li class="file"><a href="/Deep_Learning/Variational_Autoencoder/Gradient_Estimators_for_Variational_Inference/">Gradient Estimators for Variational Inference</a></li><li class="file"><a href="/Deep_Learning/Variational_Autoencoder/Theoretical_Facts/">Theoretical Facts about VAEs</a></li></ul></li></ul></li><li class="directory"><a href="#" data-role="directory"><i class="fa fa-folder"></i> &nbsp; Mathematics</a><ul class="unstyled" id="tree"><li class="directory"><a href="#" data-role="directory"><i class="fa fa-folder"></i> &nbsp; Analysis</a><ul class="unstyled" id="tree"><li class="file"><a href="/Mathematics/Analysis/Linear_Space_vs_Functional_Space/">Linear space vs functional space</a></li></ul></li><li class="directory"><a href="#" data-role="directory"><i class="fa fa-folder"></i> &nbsp; Calculus</a><ul class="unstyled" id="tree"><li class="file"><a href="/Mathematics/Calculus/Calculus_of_Variations/">Calculus of Variations</a></li></ul></li><li class="directory"><a href="#" data-role="directory"><i class="fa fa-folder"></i> &nbsp; Differential Equations</a><ul class="unstyled" id="tree"><li class="file"><a href="/Mathematics/Differential_Equations/Probability_Distribution_Equations/">Differential Equations on Probability Distributions</a></li></ul></li><li class="directory"><a href="#" data-role="directory"><i class="fa fa-folder"></i> &nbsp; Optimization</a><ul class="unstyled" id="tree"><li class="file"><a href="/Mathematics/Optimization/Convex_Optimization/">Convex Optimization</a></li></ul></li></ul></li><li class="directory"><a href="#" data-role="directory"><i class="fa fa-folder"></i> &nbsp; Research Work</a><ul class="unstyled" id="tree"><li class="file"><a href="/Research_Work/Reading_List/">Reading List</a></li><li class="file"><a href="/Research_Work/Tracking_the_Concepts/">Tracking the Concepts</a></li><li class="file"><a href="/Research_Work/Directions_to_Explore/">Directions to Explore</a></li></ul></li></ul></div><script>$(document).ready(function(){var r="fa-folder-open",i="fa-folder",l="fa-angle-double-down",d="fa-angle-double-up";$(document).on("click",'#categories a[data-role="directory"]',function(a){a.preventDefault();var e=$(this).children(".fa"),s=e.hasClass(r),l=$(this).siblings("ul");e.removeClass(r).removeClass(i),s?(void 0!==l&&l.slideUp({duration:100}),e.addClass(i)):(void 0!==l&&l.slideDown({duration:100}),e.addClass(r))}),$('#categories a[data-role="directory"]').bind("contextmenu",function(a){a.preventDefault();var e=$(this).children(".fa"),s=e.hasClass(r),l=$(this).siblings("ul"),d=$.merge(l.find("li ul"),l),o=$.merge(l.find(".fa"),e);o.removeClass(r).removeClass(i),s?(d.slideUp({duration:100}),o.addClass(i)):(d.slideDown({duration:100}),o.addClass(r))}),$(document).on("click","#allExpand",function(a){a.preventDefault();var e=$(this).children(".fa"),s=e.hasClass(l);e.removeClass(l).removeClass(d),s?($("#sidebar .fa.fa-folder").removeClass("fa-folder").addClass("fa-folder-open"),$("#categories li ul").slideDown({duration:100}),e.addClass(d)):($("#sidebar .fa.fa-folder-open").removeClass("fa-folder-open").addClass("fa-folder"),$("#categories li ul").slideUp({duration:100}),e.addClass(l))})})</script><div id="toTop" class="fa fa-angle-up"></div></aside><section id="main"><article id="post-Deep_Learning/Generative_Adversarial_Nets/Overview" class="article article-type-post" itemscope itemprop="blogPost"><div class="article-inner"><header class="article-header"><div class="article-meta"><div class="article-category"><i class="fa fa-folder"></i> <a class="article-category-link" href="/categories/Deep-Learning/">Deep Learning</a><i class="fa fa-angle-right"></i><a class="article-category-link" href="/categories/Deep-Learning/Generative-Adversarial-Nets/">Generative Adversarial Nets</a></div><div class="article-date"><i class="fa fa-calendar"></i> <a href="/Deep_Learning/Generative_Adversarial_Nets/Overview/"><time datetime="2020-03-21T04:07:29.000Z" itemprop="datePublished">2020-03-21</time></a></div><div class="article-meta-button"><a href="https://github.com/haowen-xu/research-notes/raw/master/source/_posts/Deep_Learning/Generative_Adversarial_Nets/Overview.md">Source</a></div><div class="article-meta-button"><a href="https://github.com/haowen-xu/research-notes/edit/master/source/_posts/Deep_Learning/Generative_Adversarial_Nets/Overview.md">Edit</a></div><div class="article-meta-button"><a href="https://github.com/haowen-xu/research-notes/commits/master/source/_posts/Deep_Learning/Generative_Adversarial_Nets/Overview.md">History</a></div></div><h1 itemprop="name"><a class="article-title" href="/Deep_Learning/Generative_Adversarial_Nets/Overview/">Overview</a></h1></header><div class="article-entry" itemprop="articleBody"><h2 id="original-gan">Original GAN</h2><p><span class="citation" data-cites="goodfellowGenerativeAdversarialNets2014">Goodfellow et al. (<a href="#ref-goodfellowGenerativeAdversarialNets2014" role="doc-biblioref">2014</a>)</span> proposed the following first GAN architecture:</p><ul><li>Prior: <span class="math inline">\(p_g(\mathbf{z}) = \mathcal{N}(\mathbf{0},\mathbf{I})\)</span></li><li>Generator: <span class="math inline">\(G(\mathbf{z})\)</span></li><li>Discriminator: <span class="math inline">\(D(\mathbf{x}) \in [0, 1]\)</span></li></ul><p>The overall loss from their theory: <span class="math display">\[ \mathcal{L} = \min_G \max_D \left\{ \mathbb{E}_{p_d(\mathbf{x})}\left[ \log D(\mathbf{x}) \right] + \mathbb{E}_{p_g(\mathbf{z})}\left[ \log(1 - D(G(\mathbf{z}))) \right] \right\} \]</span> The discriminator loss (to <strong>maximize</strong>): <span class="math display">\[ \mathcal{L}_D = \mathbb{E}_{p_d(\mathbf{x})} \left[ \log D(\mathbf{x}) \right] + \mathbb{E}_{p_g(\mathbf{z})}\left[ \log(1 - D(G(\mathbf{z}))) \right] \]</span></p><p>The theoretical generator loss (to <strong>minimize</strong>): <span class="math display">\[ \mathcal{L}_G = \mathbb{E}_{p_g(\mathbf{z})}\left[ \log(1 - D(G(\mathbf{z}))) \right] \]</span> The actual generator loss (to <strong>maximize</strong>) in experiments, to avoid saturation in the early stage of training: <span class="math display">\[ \mathcal{L}_G = \mathbb{E}_{p_g(\mathbf{z})}\left[ \log(D(G(\mathbf{z}))) \right] \]</span></p><h3 id="gan-training-algorithm">GAN Training Algorithm</h3><p>The most widely adopted GAN training algorithm, which is proposed in this work, alternates between training the discriminator and the generator. That is, in each training iteration:</p><ul><li><p>Repeat for <em>n_critics</em> iterations</p><ul><li><p>Sample <span class="math inline">\(\mathbf{x}^{(1)}, \dots, \mathbf{x}^{(b)}\)</span> from <span class="math inline">\(p_d(\mathbf{x})\)</span>, <span class="math inline">\(\mathbf{z}^{(1)}, \dots, \mathbf{z}^{(b)}\)</span> from <span class="math inline">\(p_g(\mathbf{z})\)</span>.</p></li><li><p>Update the discriminator by: <span class="math display">\[ \theta_D = \theta_D + \eta \, \nabla_{\theta_D}\left( \frac{1}{b}\sum_{i=1}^b \left[ \log D(\mathbf{x}^{(i)}) \right] + \frac{1}{b}\sum_{i=1}^b \left[ \log(1 - D(G(\mathbf{z}^{(i)}))) \right] \right) \]</span></p></li></ul></li><li><p>Sample <span class="math inline">\(\mathbf{z}^{(1)}, \dots, \mathbf{z}^{(b)}\)</span> from <span class="math inline">\(p_g(\mathbf{z})\)</span>.</p></li><li><p>Update the generator by: <span class="math display">\[ \theta_G = \theta_G - \eta\,\nabla_{\theta_G}\left( \frac{1}{b} \sum_{i=1}^b \log(1 - D(G(\mathbf{z}^{(i)}))) \right) \]</span> or alternatively, <span class="math display">\[ \theta_G = \theta_G + \eta\,\nabla_{\theta_G}\left( \frac{1}{b} \sum_{i=1}^b \log(D(G(\mathbf{z}^{(i)}))) \right) \]</span></p></li></ul><h1 id="bibliography" class="unnumbered">References</h1><div id="refs" class="references" role="doc-bibliography"><div id="ref-goodfellowGenerativeAdversarialNets2014"><p>Goodfellow, Ian, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair, Aaron Courville, and Yoshua Bengio. 2014. “Generative Adversarial Nets.” In <em>Advances in Neural Information Processing Systems</em>, 2672–80.</p></div></div></div><div style="height:10px"></div></div></article><article id="post-Deep_Learning/Evaluation/Evaluation_Metrics" class="article article-type-post" itemscope itemprop="blogPost"><div class="article-inner"><header class="article-header"><div class="article-meta"><div class="article-category"><i class="fa fa-folder"></i> <a class="article-category-link" href="/categories/Deep-Learning/">Deep Learning</a><i class="fa fa-angle-right"></i><a class="article-category-link" href="/categories/Deep-Learning/Evaluation/">Evaluation</a></div><div class="article-date"><i class="fa fa-calendar"></i> <a href="/Deep_Learning/Evaluation/Evaluation_Metrics/"><time datetime="2020-03-20T18:07:18.000Z" itemprop="datePublished">2020-03-21</time></a></div><div class="article-meta-button"><a href="https://github.com/haowen-xu/research-notes/raw/master/source/_posts/Deep_Learning/Evaluation/Evaluation_Metrics.md">Source</a></div><div class="article-meta-button"><a href="https://github.com/haowen-xu/research-notes/edit/master/source/_posts/Deep_Learning/Evaluation/Evaluation_Metrics.md">Edit</a></div><div class="article-meta-button"><a href="https://github.com/haowen-xu/research-notes/commits/master/source/_posts/Deep_Learning/Evaluation/Evaluation_Metrics.md">History</a></div></div><h1 itemprop="name"><a class="article-title" href="/Deep_Learning/Evaluation/Evaluation_Metrics/">Evaluation Metrics</a></h1></header><div class="article-entry" itemprop="articleBody"><h2 id="likelihood">Likelihood</h2><h3 id="negative-log-likelihood">Negative Log-Likelihood</h3><p>The negative log-likelihood (NLL) for <span class="math inline">\(p_{\theta}(\mathbf{x})\)</span> is defined as:</p><p><span class="math display">\[ \begin{align} \text{NLL} &amp;= \mathbb{E}_{p_d(\mathbf{x})} \left[ -\log p_{\theta}(\mathbf{x}) \right] \end{align} \]</span></p><h4 id="find-the-original-nll-using-scaled-data">Find the Original NLL using Scaled Data</h4><p>If the original data <span class="math inline">\(\mathbf{x}\)</span> is <span class="math inline">\(k\)</span>-dimensional ,and is scaled by <span class="math inline">\(\frac{1}{\sigma}\)</span> at each of its dimensions, such that the data fed into the model is <span class="math inline">\(\tilde{\mathbf{x}} = \frac{1}{\sigma} \mathbf{x}\)</span>, then: <span class="math display">\[ \begin{align} p_d(\mathbf{x}) &amp;= \tilde{p}_d(\tilde{\mathbf{x}}) \left| \det\left( \frac{\mathrm{d}\tilde{\mathbf{x}}}{\mathrm{d}\mathbf{x}} \right) \right| = \tilde{p}_d(\tilde{\mathbf{x}})\left| \det\left( \frac{\mathrm{d}(\mathbf{x} / \sigma)}{\mathrm{d}\mathbf{x}} \right) \right| = \frac{1}{\sigma^k}\,\tilde{p}_d(\tilde{\mathbf{x}}) \\ p_{\theta}(\mathbf{x}) &amp;= \frac{1}{\sigma^k}\, \tilde{p}_{\theta}(\tilde{\mathbf{x}}) \end{align} \]</span> Thus the computed NLL for <span class="math inline">\(\mathbf{x}\)</span> and <span class="math inline">\(\tilde{\mathbf{x}}\)</span> has the following relationship: <span class="math display">\[ \begin{align} \text{NLL} &amp;= \mathbb{E}_{p_d(\mathbf{x})} \left[ -\log p_{\theta}(\mathbf{x}) \right] \\ &amp;= -\int p_d(\mathbf{x}) \log p_{\theta}(\mathbf{x})\,\mathrm{d}\mathbf{x} \\ &amp;= -\int \frac{1}{\sigma^k}\,\tilde{p}_{d}(\tilde{\mathbf{x}}) \log \left( \frac{1}{\sigma^k}\, \tilde{p}_{\theta}(\tilde{\mathbf{x}}) \right)\left| \det\left( \frac{\mathrm{d}\mathbf{x}}{\mathrm{d}\tilde{\mathbf{x}}} \right) \right|\mathrm{d}\tilde{\mathbf{x}} \\ &amp;= -\int \tilde{p}_{d}(\tilde{\mathbf{x}}) \left[ \log \tilde{p}_{\theta}(\tilde{\mathbf{x}}) - k\log \sigma \right]\mathrm{d}\tilde{\mathbf{x}} \\ &amp;= \mathbb{E}_{\tilde{p}_d(\mathbf{x})} \left[ -\log \tilde{p}_{\theta}(\mathbf{x}) \right] + k\log \sigma \\ &amp;= \widetilde{NLL} + k\log\sigma \end{align} \]</span></p><h4 id="continuous-nll-as-an-upper-bound-of-discrete-nll">Continuous NLL as an Upper-Bound of Discrete NLL</h4><p>To train a continuous model upon discrete data (e.g., images), one may add a uniform noise to the data, and obtain an upper-bound of the discrete data NLL with the augmented data.</p><p>For pixel integer-valued <span class="math inline">\(\mathbf{x}\)</span> ranging from 0 to 255, adding a uniform noise <span class="math inline">\(\mathbf{u} \sim \mathcal{U}[0, 1)\)</span>, such that <span class="math inline">\(\tilde{\mathbf{x}} = \mathbf{x} + \mathbf{u}\)</span>, we have <span class="citation" data-cites="theisNoteEvaluationGenerative2015">(Theis, Oord, and Bethge <a href="#ref-theisNoteEvaluationGenerative2015" role="doc-biblioref">2015</a>)</span>: <span class="math display">\[ \begin{align} -\int \tilde{p}_d(\tilde{\mathbf{x}}) \log \tilde{p}_{\theta}(\tilde{\mathbf{x}}) \,\mathrm{d}\tilde{\mathbf{x}} &amp;= -\sum_{\mathbf{x}} P_d(\mathbf{x}) \int \log \tilde{p}_{\theta}(\mathbf{x} + \mathbf{u}) \,\mathrm{d}\mathbf{u} \\ &amp;\geq -\sum_{\mathbf{x}} P_d(\mathbf{x}) \log \int \tilde{p}_{\theta}(\mathbf{x} + \mathbf{u}) \,\mathrm{d}\mathbf{u} \\ \\ &amp;= -\sum_{\mathbf{x}} P_d(\mathbf{x}) \log P_{\theta}(\mathbf{x}) \\ \end{align} \]</span> where we define the probability of the true discrete data to be: <span class="math display">\[ P_{\theta}(\mathbf{x}) = \int \tilde{p}_{\theta}(\mathbf{x} + \mathbf{u}) \,\mathrm{d}\mathbf{u} \]</span> That is to say, the NLL of the augmented continuous random variable <span class="math inline">\(\tilde{\mathbf{x}}\)</span> can serve as an upper-bound as the true discrete data NLL.</p><h2 id="image-quality">Image Quality</h2><h2 id="roc-and-auc">ROC and AUC</h2><p><span class="citation" data-cites="davisRelationshipPrecisionRecallROC2006">(Davis and Goadrich <a href="#ref-davisRelationshipPrecisionRecallROC2006" role="doc-biblioref">2006</a>)</span></p><ol type="1"><li><p>There is a one-to-one correspondence between the points on ROC and AUC curves.</p></li><li><p>A curve dominates the ROC (fpr-tpr curve) <span class="math inline">\(\Leftrightarrow\)</span> dominates the AUC (recall-precision curve).</p></li><li><p>Interpolation between two points <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span>:</p><ol type="1"><li><p>On ROC: linear interpolation.</p></li><li><p>On AUC: <span class="math display">\[ \left( \frac{TP_A + x}{\text{Total Pos}}, \frac{TP_A + x}{TP_A + x + FP_A + \frac{FP_B - FP_A}{TP_B - TP_A} x} \right) \]</span></p></li></ol></li><li><p>Compute the area: include the interpolation and use composite trapezoidal method.</p><ol type="1"><li>Incorrect interpoluation for computing AUC-PR will cause over-estimate.</li></ol></li><li><p>Optimize Area under ROC and AUC curves: not exactly the same. (especially when not one algorithm dominates the curve?)</p></li></ol><h1 id="bibliography" class="unnumbered">References</h1><div id="refs" class="references" role="doc-bibliography"><div id="ref-davisRelationshipPrecisionRecallROC2006"><p>Davis, Jesse, and Mark Goadrich. 2006. “The Relationship Between Precision-Recall and ROC Curves.” In <em>Proceedings of the 23rd International Conference on Machine Learning - ICML ’06</em>, 233–40. Pittsburgh, Pennsylvania: ACM Press. <a href="https://doi.org/10.1145/1143844.1143874" target="_blank" rel="noopener">https://doi.org/10.1145/1143844.1143874</a>.</p></div><div id="ref-theisNoteEvaluationGenerative2015"><p>Theis, Lucas, Aäron van den Oord, and Matthias Bethge. 2015. “A Note on the Evaluation of Generative Models.” <em>arXiv Preprint arXiv:1511.01844</em>.</p></div></div></div><div style="height:10px"></div></div></article><article id="post-Deep_Learning/Generative_Adversarial_Nets/Energy_GAN" class="article article-type-post" itemscope itemprop="blogPost"><div class="article-inner"><header class="article-header"><div class="article-meta"><div class="article-category"><i class="fa fa-folder"></i> <a class="article-category-link" href="/categories/Deep-Learning/">Deep Learning</a><i class="fa fa-angle-right"></i><a class="article-category-link" href="/categories/Deep-Learning/Generative-Adversarial-Nets/">Generative Adversarial Nets</a></div><div class="article-date"><i class="fa fa-calendar"></i> <a href="/Deep_Learning/Generative_Adversarial_Nets/Energy_GAN/"><time datetime="2020-03-19T20:46:25.000Z" itemprop="datePublished">2020-03-20</time></a></div><div class="article-meta-button"><a href="https://github.com/haowen-xu/research-notes/raw/master/source/_posts/Deep_Learning/Generative_Adversarial_Nets/Energy_GAN.md">Source</a></div><div class="article-meta-button"><a href="https://github.com/haowen-xu/research-notes/edit/master/source/_posts/Deep_Learning/Generative_Adversarial_Nets/Energy_GAN.md">Edit</a></div><div class="article-meta-button"><a href="https://github.com/haowen-xu/research-notes/commits/master/source/_posts/Deep_Learning/Generative_Adversarial_Nets/Energy_GAN.md">History</a></div></div><h1 itemprop="name"><a class="article-title" href="/Deep_Learning/Generative_Adversarial_Nets/Energy_GAN/">Energy GAN</a></h1></header><div class="article-entry" itemprop="articleBody"><h2 id="overview">Overview</h2><p>Given the discriminator <span class="math inline">\(E_{\theta}(\mathbf{x})\)</span>, a density function can be derived as: <span class="math display">\[ \begin{align} p_{\theta}(\mathbf{x}) &amp;= \frac{1}{Z_{\theta}} e^{-E_{\theta}(\mathbf{x})} \\ Z_{\theta} &amp;= \int e^{-E_{\theta}(\mathbf{x})}\,\mathrm{d}\mathbf{x} \end{align} \]</span></p><h2 id="maximum-entropy-generators-for-energy-based-models">Maximum Entropy Generators for Energy-Based Models</h2><p><span class="citation" data-cites="kumarMaximumEntropyGenerators2019">Kumar et al. (<a href="#ref-kumarMaximumEntropyGenerators2019" role="doc-biblioref">2019</a>)</span> proposed the following architecture:</p><ul><li>Prior: <span class="math inline">\(p_z(\mathbf{z})\)</span></li><li>Generator: <span class="math inline">\(G_{\omega}(\mathbf{z})\)</span></li><li>Discriminator: <span class="math inline">\(E_{\theta}(\mathbf{x}) \in (-\infty, \infty)\)</span>, the energy function<ul><li>The density function: <span class="math inline">\(p_{\theta}(\mathbf{x}) = \frac{1}{Z_{\theta}} e^{-E_{\theta}(\mathbf{x})}\)</span></li></ul></li><li>Discriminator for the mutual information estimator: <span class="math inline">\(T_{\phi}(\mathbf{x},\mathbf{z}) \in (-\infty,\infty)\)</span></li></ul><p>The discriminator loss (to <strong>minimize</strong>): <span class="math display">\[ \begin{align} \mathcal{L}_E &amp;= \mathbb{E}_{p_d(\mathbf{x})}\left[ E_{\theta}(\mathbf{x}) \right] - \mathbb{E}_{p_G(\mathbf{x})}\left[ E_{\theta}(\mathbf{x}) \right] + \Omega \\ \Omega &amp;= \lambda\,\mathbb{E}_{p_d(\mathbf{x})} \left[ \left\| \nabla_{\mathbf{x}} E_{\theta}(\mathbf{x}) \right\|^2 \right] \end{align} \]</span> The generator loss (to <strong>minimize</strong>) <span class="math display">\[ \begin{align} \mathcal{L}_G &amp;= \mathbb{E}_{p_z(\mathbf{z})}\left[ E_{\theta}(G_{\omega}(\mathbf{z})) \right] - H_{p_G}[X] \\ &amp;= \mathbb{E}_{p_z(\mathbf{z})}\left[ E_{\theta}(G_{\omega}(\mathbf{z})) \right] - I_{p_G}(X;Z) \end{align} \]</span> where <span class="math inline">\(H_{p_G}[X] = I_{p_G}(X;Z) + H(G_{\omega}(Z)|Z)\)</span>, and <span class="math inline">\(H(G_{\omega}(Z)|Z) \equiv 0\)</span> since <span class="math inline">\(G_{\omega}(\mathbf{z})\)</span> is a deterministic mapper.</p><p>The mutual information <span class="math inline">\(I_{p_G}(X;Z)\)</span> is estimated via the <a href="/Deep_Learning/Information_Theoretical/Mutual_Information/#deep-infomax">Deep InfoMax</a> estimator by <span class="citation" data-cites="kumarMaximumEntropyGenerators2019">Kumar et al. (<a href="#ref-kumarMaximumEntropyGenerators2019" role="doc-biblioref">2019</a>)</span>, formulated as: <span class="math display">\[ \begin{align} I_{p_G}(X;Z) &amp;= \mathbb{E}_{p_z(\mathbf{z})}\left[ -\text{sp}(-T_{\phi}(G_{\omega}(\mathbf{z}),\mathbf{z})) \right] - \mathbb{E}_{p_z(\mathbf{z})\times\tilde{p}_z(\tilde{\mathbf{z}})}\left[ \text{sp}(T_{\phi}(G_{\omega}(\mathbf{z}),\tilde{\mathbf{z}})) \right] \\ &amp;= \mathbb{E}_{p_z(\mathbf{z})}\left[ \log \sigma(T_{\phi}(G_{\omega}(\mathbf{z}),\mathbf{z})) \right] - \mathbb{E}_{p_z(\mathbf{z})\times\tilde{p}_z(\tilde{\mathbf{z}})}\left[ \log\left(1 - \sigma(T_{\phi}(G_{\omega}(\mathbf{z}),\tilde{\mathbf{z}}))\right) \right] \end{align} \]</span></p><p>where <span class="math inline">\(\text{sp}(a) = \log(1 + e^a)\)</span> is the <em>SoftPlus</em> function, and <span class="math inline">\(\sigma(a) = \frac{1}{1 + e^{-a}}\)</span> is the sigmoid function.</p><h3 id="training-algorithm">Training Algorithm</h3><p><span class="citation" data-cites="kumarMaximumEntropyGenerators2019">Kumar et al. (<a href="#ref-kumarMaximumEntropyGenerators2019" role="doc-biblioref">2019</a>)</span> proposed the following training algorithm:</p><ul><li><p>Repeat for <em>n_critics</em> Iterations</p><ul><li><p>Sample <span class="math inline">\(\mathbf{x}^{(1)}, \dots, \mathbf{x}^{(b)}\)</span> from <span class="math inline">\(p_d(\mathbf{x})\)</span>, <span class="math inline">\(\mathbf{z}^{(1)}, \dots, \mathbf{z}^{(b)}\)</span> from <span class="math inline">\(p_z(\mathbf{z})\)</span>.</p></li><li><p>Obtain <span class="math inline">\(\tilde{\mathbf{x}}^{(i)} = G_{\omega}(\mathbf{z}^{(i)})\)</span>.</p></li><li><p>Calculate: <span class="math display">\[ \mathcal{L}_E = \frac{1}{b} \left[ \sum_{i=1}^b E_{\theta}(\mathbf{x}^{(i)}) - \sum_{i=1}^b E_{\theta}(\tilde{\mathbf{x}}^{(i)}) + \lambda\sum_{i=1}^b \left\| \nabla_{\mathbf{x}} E_{\theta}(\mathbf{x}^{(i)}) \right\|^2 \right] \]</span></p></li><li><p>Gradient descent: <span class="math display">\[ \theta^{t+1} = \theta^{t} - \eta \, \nabla_{\theta} \mathcal{L}_E \]</span></p></li></ul></li><li><p>Sample <span class="math inline">\(\mathbf{z}^{(1)}, \dots, \mathbf{z}^{(b)}\)</span> from <span class="math inline">\(p_z(\mathbf{z})\)</span>.</p></li><li><p>Per-dimensional shuffle of <span class="math inline">\(\mathbf{z}\)</span>, yielding <span class="math inline">\(\tilde{\mathbf{z}}^{(1)}, \dots, \tilde{\mathbf{z}}^{(b)}\)</span>.</p><p><strong>(Is this really better than re-sampling from the prior <span class="math inline">\(p_z(\mathbf{z})\)</span>?)</strong></p></li><li><p>Obtain <span class="math inline">\(\tilde{\mathbf{x}}^{(i)} = G_{\omega}(\mathbf{z}^{(i)})\)</span>.</p></li><li><p>Calculate: <span class="math display">\[ \begin{align} \mathcal{L}_H &amp;= \frac{1}{b} \sum_{i=1}^b \left[ \log \sigma(T_{\phi}(\tilde{\mathbf{x}}^{(i)},\mathbf{z}^{(i)})) - \log\left(1 - \sigma(T_{\phi}(\tilde{\mathbf{x}}^{(i)},\tilde{\mathbf{z}}^{(i)}))\right) \right] \\ \mathcal{L}_G &amp;= \frac{1}{b} \sum_{i=1}^b \left[ E_{\theta}(\tilde{\mathbf{x}}^{(i)}) \right] - \mathcal{L}_H \end{align} \]</span></p></li><li><p>Gradient descent: <span class="math display">\[ \begin{align} \omega^{t+1} &amp;= \omega^{t} - \eta \, \nabla_{\omega} \mathcal{L}_G \\ \phi^{t+1} &amp;= \phi^{t} - \eta \, \nabla_{\phi} \mathcal{L}_H \\ \end{align} \]</span></p></li></ul><p>In summary, this algorithm:</p><ul><li>Minimize <span class="math inline">\(\theta\)</span> <em>w.r.t.</em> <span class="math inline">\(\mathcal{L}_E\)</span> =&gt;<ul><li>Minimizes <span class="math inline">\(E_{\theta}\)</span> in the discriminator loss <span class="math inline">\(\mathcal{L}_E\)</span>.</li></ul></li><li>Minimize <span class="math inline">\(\phi\)</span> <em>w.r.t.</em> <span class="math inline">\(L_H\)</span> =&gt;<ul><li>Minimizes <span class="math inline">\(T_{\phi}\)</span> in the mutual information regularizer <span class="math inline">\(I_{p_G}(X;Z)\)</span>.</li></ul></li><li>Minimize <span class="math inline">\(\omega\)</span> <em>w.r.t.</em> <span class="math inline">\(L_G\)</span> =&gt;<ul><li>Maximizes <span class="math inline">\(G_{\omega}\)</span> in the mutual information regularizer <span class="math inline">\(I_{p_G}(X;Z)\)</span>;</li><li>Minimizes <span class="math inline">\(G_{\omega}\)</span> in the generator loss <span class="math inline">\(\mathbb{E}_{p_z(\mathbf{z})}\left[ E_{\theta}(G_{\omega}(\mathbf{z})) \right]\)</span>.</li></ul></li></ul><h3 id="latent-space-mcmc">Latent Space MCMC</h3><p><span class="citation" data-cites="kumarMaximumEntropyGenerators2019">Kumar et al. (<a href="#ref-kumarMaximumEntropyGenerators2019" role="doc-biblioref">2019</a>)</span> also proposed an MCMC method to refine the <span class="math inline">\(\mathbf{z}\)</span> samples obtained from the prior <span class="math inline">\(p_z(\mathbf{z})\)</span>, according to the energy function on <span class="math inline">\(\mathbf{z}\)</span>, derived as: <span class="math display">\[ E(\mathbf{z}) = E_{\theta}(G_{\omega}(\mathbf{z})) \]</span> Then <a href="/Deep_Learning/Monte_Carlo_Methods/Langevin_Dynamics/">Metropolis-adjusted Langevin algorithm</a> is adopted to sample <span class="math inline">\(\mathbf{z}\)</span>:</p><ul><li><p>Langevin dynamics: <span class="math display">\[ \mathbf{z}^{(t+1)} = \mathbf{z}^{(t)} - \alpha \frac{\partial E_{\theta}(G_{\omega}(\mathbf{z}^{(t)}))}{\partial \mathbf{z}^{(t)}} + \epsilon \sqrt{2 * \alpha} \]</span> where <span class="math inline">\(\epsilon \sim \mathcal{N}(\mathbf{0},\mathbf{I})\)</span>.</p></li><li><p>Metropolis-Hastings Algorithm: <span class="math display">\[ \begin{align} r &amp;= \min\left\{ 1, \frac{p(\mathbf{z}^{(t+1)})}{p(\mathbf{z}^{(t)})} \cdot \frac{q(\mathbf{z}^{(t)}|\mathbf{z}^{(t+1)})}{q(\mathbf{z}^{(t+1)}|\mathbf{z}^{(t)})} \right\} \\ p(\mathbf{z}^{(t)}) &amp;\propto \exp\left\{ -E_{\theta}(G_{\omega}(\mathbf{z}^{(t)})) \right\} \\ q(\mathbf{z}^{(t+1)}|\mathbf{z}^{(t)}) &amp;\propto \exp\left( -\frac{1}{4 \alpha}\left\| \mathbf{z}^{(t+1)} - \mathbf{z}^{(t)} + \alpha \frac{\partial E_{\theta}(G_{\omega}(\mathbf{z}^{(t)}))}{\partial \mathbf{z}^{(t)}} \right\|^2_2 \right) \end{align} \]</span></p></li></ul><h1 id="bibliography" class="unnumbered">References</h1><div id="refs" class="references" role="doc-bibliography"><div id="ref-kumarMaximumEntropyGenerators2019"><p>Kumar, Rithesh, Anirudh Goyal, Aaron Courville, and Yoshua Bengio. 2019. “Maximum Entropy Generators for Energy-Based Models.” <em>arXiv:1901.08508 [Cs, Stat]</em>, January. <a href="http://arxiv.org/abs/1901.08508" target="_blank" rel="noopener">http://arxiv.org/abs/1901.08508</a>.</p></div></div></div><div style="height:10px"></div></div></article><nav id="page-nav"><a class="extend prev" rel="prev" href="/">&laquo; Prev</a><a class="page-number" href="/">1</a><span class="page-number current">2</span><a class="page-number" href="/page/3/">3</a><a class="page-number" href="/page/4/">4</a><span class="space">&hellip;</span><a class="page-number" href="/page/14/">14</a><a class="extend next" rel="next" href="/page/3/">Next &raquo;</a></nav></section></div><footer id="footer"><div class="outer"><div id="footer-info" class="inner">Haowen Xu &copy; 2020 <a rel="license" href="http://creativecommons.org/licenses/by-nc-nd/4.0/"><img alt="Creative Commons License" style="border-width:0" src="/images/by-nc-nd-4.0-80x15.png"></a><br>Powered by <a href="http://hexo.io/" target="_blank">Hexo</a> &amp; theme <a href="https://github.com/zthxxx/hexo-theme-Wikitten">Wikitten</a></div></div></footer><script src="/libs/lightgallery/js/lightgallery.min.js"></script><script src="/libs/lightgallery/js/lg-thumbnail.min.js"></script><script src="/libs/lightgallery/js/lg-pager.min.js"></script><script src="/libs/lightgallery/js/lg-autoplay.min.js"></script><script src="/libs/lightgallery/js/lg-fullscreen.min.js"></script><script src="/libs/lightgallery/js/lg-zoom.min.js"></script><script src="/libs/lightgallery/js/lg-hash.min.js"></script><script src="/libs/lightgallery/js/lg-share.min.js"></script><script src="/libs/lightgallery/js/lg-video.min.js"></script><script src="/libs/justified-gallery/jquery.justifiedGallery.min.js"></script><script type="text/x-mathjax-config">MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ["$","$"], ["\\(","\\)"] ],
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
            processEscapes: true,
            TeX: {
                equationNumbers: {
                    autoNumber: 'AMS'
                },
                style: {
                    'font-family': 'serif'
                }
            }
        },
        'HTML-CSS': {
            //preferredFont: 'TeX',
            fonts: ['TeX']
        }
    });
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax();
        for (var i = 0; i < all.length; ++i)
            all[i].SourceElement().parentNode.className += ' has-jax';
    });</script><script async src="//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><script src="/js/main.js"></script></div></body>