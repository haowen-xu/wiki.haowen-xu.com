<!DOCTYPE html><html lang="en"><head><meta name="generator" content="Hexo 3.9.0"><meta charset="utf-8"><title>My Research Wiki</title><meta name="keywords" content="My Research Wiki"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=1"><meta property="og:type" content="website"><meta property="og:title" content="My Research Wiki"><meta property="og:url" content="https://wiki.haowen-xu.com/page/6/index.html"><meta property="og:site_name" content="My Research Wiki"><meta property="og:locale" content="en"><meta name="twitter:card" content="summary"><meta name="twitter:title" content="My Research Wiki"><link rel="alternate" href="/atom.xml" title="My Research Wiki" type="application/atom+xml"><link rel="icon" href="/favicon.ico"><link rel="stylesheet" href="/libs/font-awesome/css/font-awesome.min.css"><link rel="stylesheet" href="/libs/open-sans/styles.css"><link rel="stylesheet" href="/libs/source-code-pro/styles.css"><link rel="stylesheet" href="/css/style.css"><script src="/libs/jquery/2.1.3/jquery.min.js"></script><script src="/libs/jquery/plugins/cookie/1.4.1/jquery.cookie.js"></script><link rel="stylesheet" href="/libs/lightgallery/css/lightgallery.min.css"><link rel="stylesheet" href="/libs/justified-gallery/justifiedGallery.min.css"></head></html><body><div id="container"><header id="header"><div id="header-main" class="header-inner"><div class="outer"><a href="/" id="logo"><i class="logo"></i> <span class="site-title">My Research Wiki</span></a><nav id="main-nav"><a class="main-nav-link" href="/">Home</a> <a class="main-nav-link" href="/archives">Archives</a> <a class="main-nav-link" href="/categories">Categories</a></nav><div id="search-form-wrap"><form class="search-form"><input type="text" class="ins-search-input search-form-input" placeholder="Search"> <button type="submit" class="search-form-submit"></button></form><div class="ins-search"><div class="ins-search-mask"></div><div class="ins-search-container"><div class="ins-input-wrapper"><input type="text" class="ins-search-input" placeholder="Type something..."> <span class="ins-close ins-selectable"><i class="fa fa-times-circle"></i></span></div><div class="ins-section-wrapper"><div class="ins-section-container"></div></div></div></div><script>window.INSIGHT_CONFIG={TRANSLATION:{POSTS:"Posts",PAGES:"Pages",CATEGORIES:"Categories",TAGS:"Tags",UNTITLED:"(Untitled)"},ROOT_URL:"/",CONTENT_URL:"/content.json"}</script><script src="/js/insight.js"></script></div></div></div><div id="main-nav-mobile" class="header-sub header-inner"><table class="menu outer"><tr><td><a class="main-nav-link" href="/">Home</a></td><td><a class="main-nav-link" href="/archives">Archives</a></td><td><a class="main-nav-link" href="/categories">Categories</a></td><td><div class="search-form"><input type="text" class="ins-search-input search-form-input" placeholder="Search"></div></td></tr></table></div></header><div class="outer"><aside id="sidebar"><div class="widget-wrap" id="categories"><h3 class="widget-title"><span>categories</span> &nbsp; <a id="allExpand" href="#"><i class="fa fa-angle-double-down fa-2x"></i></a></h3><ul class="unstyled" id="tree"><li class="directory"><a href="#" data-role="directory"><i class="fa fa-folder"></i> &nbsp; Deep Learning</a><ul class="unstyled" id="tree"><li class="directory"><a href="#" data-role="directory"><i class="fa fa-folder"></i> &nbsp; CV</a><ul class="unstyled" id="tree"><li class="file"><a href="/Deep_Learning/CV/Image_Segmentation/">Image Segmentation</a></li></ul></li><li class="directory"><a href="#" data-role="directory"><i class="fa fa-folder"></i> &nbsp; Confronting Partition Function</a><ul class="unstyled" id="tree"><li class="file"><a href="/Deep_Learning/Confronting_Partition_Function/Overview/">Overview</a></li><li class="file"><a href="/Deep_Learning/Confronting_Partition_Function/Contrastive_Divergence/">Contrastive Divergence</a></li><li class="file"><a href="/Deep_Learning/Confronting_Partition_Function/Score_Matching/">Score Matching</a></li><li class="file"><a href="/Deep_Learning/Confronting_Partition_Function/Softmax_Speedup/">Softmax Speedup</a></li></ul></li><li class="directory"><a href="#" data-role="directory"><i class="fa fa-folder"></i> &nbsp; Energy Based Models</a><ul class="unstyled" id="tree"><li class="file"><a href="/Deep_Learning/Energy_Based_Models/Overview/">Overview</a></li><li class="file"><a href="/Deep_Learning/Energy_Based_Models/Energy_Function_in_Probabilistic_Models/">Energy Function in Probabilistic Models</a></li><li class="file"><a href="/Deep_Learning/Energy_Based_Models/Restricted_Boltzmann_Machine/">Restricted Boltzmann Machine</a></li></ul></li><li class="directory"><a href="#" data-role="directory"><i class="fa fa-folder"></i> &nbsp; Evaluation</a><ul class="unstyled" id="tree"><li class="file"><a href="/Deep_Learning/Evaluation/Evaluation_Metrics/">Evaluation Metrics</a></li><li class="file"><a href="/Deep_Learning/Evaluation/Visualizing_High_Dimensional_Space/">Visualizing High Dimensional Space</a></li></ul></li><li class="directory"><a href="#" data-role="directory"><i class="fa fa-folder"></i> &nbsp; Generative Adversarial Nets</a><ul class="unstyled" id="tree"><li class="file"><a href="/Deep_Learning/Generative_Adversarial_Nets/Overview/">Overview</a></li><li class="file"><a href="/Deep_Learning/Generative_Adversarial_Nets/f-GAN/">f-GAN</a></li><li class="file"><a href="/Deep_Learning/Generative_Adversarial_Nets/Energy_GAN/">Energy GAN</a></li></ul></li><li class="directory"><a href="#" data-role="directory"><i class="fa fa-folder"></i> &nbsp; Graph Neural Networks</a><ul class="unstyled" id="tree"><li class="file"><a href="/Deep_Learning/Graph_Neural_Networks/Node_Embedding/">Node Embedding</a></li><li class="file"><a href="/Deep_Learning/Graph_Neural_Networks/Graph_Convolution_Network/">Graph Convolution Network</a></li><li class="file"><a href="/Deep_Learning/Graph_Neural_Networks/Graph_Auto_Encoder/">Graph Auto-Encoder</a></li></ul></li><li class="directory"><a href="#" data-role="directory"><i class="fa fa-folder"></i> &nbsp; Information Theoretical</a><ul class="unstyled" id="tree"><li class="file"><a href="/Deep_Learning/Information_Theoretical/KL-Divergence/">KL-Divergence</a></li><li class="file"><a href="/Deep_Learning/Information_Theoretical/Mutual_Information/">Mutual Information</a></li></ul></li><li class="directory"><a href="#" data-role="directory"><i class="fa fa-folder"></i> &nbsp; Monte Carlo Methods</a><ul class="unstyled" id="tree"><li class="file"><a href="/Deep_Learning/Monte_Carlo_Methods/Overview/">Overview</a></li><li class="file"><a href="/Deep_Learning/Monte_Carlo_Methods/Monte_Carlo_Integration/">Monte Carlo Integration</a></li><li class="file"><a href="/Deep_Learning/Monte_Carlo_Methods/Accept_Reject_Sampling/">Accept-Reject Sampling</a></li><li class="file"><a href="/Deep_Learning/Monte_Carlo_Methods/Markov_Chain/">Markov Chain</a></li><li class="file"><a href="/Deep_Learning/Monte_Carlo_Methods/Metropolis_Hastings_Algorithm/">Metropolis-Hastings Algorithm</a></li><li class="file"><a href="/Deep_Learning/Monte_Carlo_Methods/Gibbs_Sampler/">Gibbs Sampler</a></li><li class="file"><a href="/Deep_Learning/Monte_Carlo_Methods/Hamiltonian_Dynamics/">Hamiltonian Dynamics</a></li><li class="file"><a href="/Deep_Learning/Monte_Carlo_Methods/Langevin_Dynamics/">Langevin Dynamics</a></li></ul></li><li class="directory"><a href="#" data-role="directory"><i class="fa fa-folder"></i> &nbsp; Optimization</a><ul class="unstyled" id="tree"><li class="file"><a href="/Deep_Learning/Optimization/Gradient_Tricks/">Gradient Tricks</a></li><li class="file"><a href="/Deep_Learning/Optimization/Loss_Surface_and_Generalization/">Loss Surface and Generalization</a></li><li class="file"><a href="/Deep_Learning/Optimization/Stochastic_Gradient_Descent/">Stochastic Gradient descent</a></li></ul></li><li class="directory"><a href="#" data-role="directory"><i class="fa fa-folder"></i> &nbsp; Variational Autoencoder</a><ul class="unstyled" id="tree"><li class="file"><a href="/Deep_Learning/Variational_Autoencoder/Overview/">Overview</a></li><li class="file"><a href="/Deep_Learning/Variational_Autoencoder/Sequential_VAE/">Sequential VAE</a></li><li class="file"><a href="/Deep_Learning/Variational_Autoencoder/Gradient_Estimators_for_Variational_Inference/">Gradient Estimators for Variational Inference</a></li><li class="file"><a href="/Deep_Learning/Variational_Autoencoder/Theoretical_Facts/">Theoretical Facts about VAEs</a></li></ul></li></ul></li><li class="directory"><a href="#" data-role="directory"><i class="fa fa-folder"></i> &nbsp; Mathematics</a><ul class="unstyled" id="tree"><li class="directory"><a href="#" data-role="directory"><i class="fa fa-folder"></i> &nbsp; Analysis</a><ul class="unstyled" id="tree"><li class="file"><a href="/Mathematics/Analysis/Linear_Space_vs_Functional_Space/">Linear space vs functional space</a></li></ul></li><li class="directory"><a href="#" data-role="directory"><i class="fa fa-folder"></i> &nbsp; Calculus</a><ul class="unstyled" id="tree"><li class="file"><a href="/Mathematics/Calculus/Calculus_of_Variations/">Calculus of Variations</a></li></ul></li><li class="directory"><a href="#" data-role="directory"><i class="fa fa-folder"></i> &nbsp; Differential Equations</a><ul class="unstyled" id="tree"><li class="file"><a href="/Mathematics/Differential_Equations/Probability_Distribution_Equations/">Differential Equations on Probability Distributions</a></li></ul></li><li class="directory"><a href="#" data-role="directory"><i class="fa fa-folder"></i> &nbsp; Optimization</a><ul class="unstyled" id="tree"><li class="file"><a href="/Mathematics/Optimization/Convex_Optimization/">Convex Optimization</a></li></ul></li></ul></li><li class="directory"><a href="#" data-role="directory"><i class="fa fa-folder"></i> &nbsp; Research Work</a><ul class="unstyled" id="tree"><li class="file"><a href="/Research_Work/Reading_List/">Reading List</a></li><li class="file"><a href="/Research_Work/Tracking_the_Concepts/">Tracking the Concepts</a></li><li class="file"><a href="/Research_Work/Directions_to_Explore/">Directions to Explore</a></li></ul></li></ul></div><script>$(document).ready(function(){var r="fa-folder-open",i="fa-folder",l="fa-angle-double-down",d="fa-angle-double-up";$(document).on("click",'#categories a[data-role="directory"]',function(a){a.preventDefault();var e=$(this).children(".fa"),s=e.hasClass(r),l=$(this).siblings("ul");e.removeClass(r).removeClass(i),s?(void 0!==l&&l.slideUp({duration:100}),e.addClass(i)):(void 0!==l&&l.slideDown({duration:100}),e.addClass(r))}),$('#categories a[data-role="directory"]').bind("contextmenu",function(a){a.preventDefault();var e=$(this).children(".fa"),s=e.hasClass(r),l=$(this).siblings("ul"),d=$.merge(l.find("li ul"),l),o=$.merge(l.find(".fa"),e);o.removeClass(r).removeClass(i),s?(d.slideUp({duration:100}),o.addClass(i)):(d.slideDown({duration:100}),o.addClass(r))}),$(document).on("click","#allExpand",function(a){a.preventDefault();var e=$(this).children(".fa"),s=e.hasClass(l);e.removeClass(l).removeClass(d),s?($("#sidebar .fa.fa-folder").removeClass("fa-folder").addClass("fa-folder-open"),$("#categories li ul").slideDown({duration:100}),e.addClass(d)):($("#sidebar .fa.fa-folder-open").removeClass("fa-folder-open").addClass("fa-folder"),$("#categories li ul").slideUp({duration:100}),e.addClass(l))})})</script><div id="toTop" class="fa fa-angle-up"></div></aside><section id="main"><article id="post-Deep_Learning/Confronting_Partition_Function/Softmax_Speedup" class="article article-type-post" itemscope itemprop="blogPost"><div class="article-inner"><header class="article-header"><div class="article-meta"><div class="article-category"><i class="fa fa-folder"></i> <a class="article-category-link" href="/categories/Deep-Learning/">Deep Learning</a><i class="fa fa-angle-right"></i><a class="article-category-link" href="/categories/Deep-Learning/Confronting-Partition-Function/">Confronting Partition Function</a></div><div class="article-date"><i class="fa fa-calendar"></i> <a href="/Deep_Learning/Confronting_Partition_Function/Softmax_Speedup/"><time datetime="2020-03-04T02:59:36.000Z" itemprop="datePublished">2020-03-04</time></a></div><div class="article-meta-button"><a href="https://github.com/haowen-xu/research-notes/raw/master/source/_posts/Deep_Learning/Confronting_Partition_Function/Softmax_Speedup.md">Source</a></div><div class="article-meta-button"><a href="https://github.com/haowen-xu/research-notes/edit/master/source/_posts/Deep_Learning/Confronting_Partition_Function/Softmax_Speedup.md">Edit</a></div><div class="article-meta-button"><a href="https://github.com/haowen-xu/research-notes/commits/master/source/_posts/Deep_Learning/Confronting_Partition_Function/Softmax_Speedup.md">History</a></div></div><h1 itemprop="name"><a class="article-title" href="/Deep_Learning/Confronting_Partition_Function/Softmax_Speedup/">Softmax Speedup</a></h1></header><div class="article-entry" itemprop="articleBody"><h2 id="problem-statement">Problem Statement</h2><p>To optimize <span class="math inline">\(\theta\)</span> for a softmax classification model <span class="math inline">\(p(y|\mathbf{x};\theta)\)</span> (or formulated as <span class="math inline">\(p(w|\mathbf{c};\theta)\)</span> in many NLP literature) without estimating the partition function <span class="math inline">\(Z(\theta)\)</span>:</p><p><span class="math display">\[ \begin{align} p(y=i|\mathbf{x};\theta) &amp;= \frac{\tilde{p}(y=i|\mathbf{x};\theta)}{Z(\theta)} \\ Z(\mathbf{x};\theta) &amp;= \sum_{j=1}^m \tilde{p}(y=j|\mathbf{x};\theta) \end{align} \]</span> where the unnormalized <span class="math inline">\(\tilde{p}(y|\mathbf{x};\theta)\)</span> is typically formulated as <span class="math inline">\(\tilde{p}(y=i|\mathbf{x};\theta)=\exp\left( u_i(\mathbf{x},y;\theta) \right)\)</span>, where <span class="math inline">\(i=1 \dots m\)</span> is the <span class="math inline">\(k\)</span> classes.</p><h2 id="hierarchical-softmax">Hierarchical Softmax</h2><p>Encode each class <span class="math inline">\(y\)</span> by a binary sequence <span class="math inline">\(b_1(y), b_2(y), \dots, b_k(y)\)</span> , where <span class="math inline">\(b_i(y) \in \{0, 1\}\)</span>, and decompose <span class="math inline">\(p(y|\mathbf{x};\theta)\)</span> as: <span class="math display">\[ p(y|\mathbf{x};\theta) = \prod_{i=1}^k p(b_i(y)|b_{i-1}(y),\dots,b_1(y),\mathbf{x};\theta) \]</span> such that each of the decomposed term is a binary classifier.</p><h3 id="further-speedup">Further Speedup</h3><p>Hoffman coding can be used to construct the binary tree, such that more frequently visited classes <span class="math inline">\(y\)</span> can have a shorter binary sequence.</p><h2 id="noise-contrastive-estimation">Noise Contrastive Estimation</h2><p>The NCE method starts by choosing a noise distribution <span class="math inline">\(q(y)\)</span>, and modify the original <span class="math inline">\(m\)</span>-target classification problem as a binary classfication problem.</p><p>The binary classifier is defined as: <span class="math display">\[ \begin{align} p(D=1|\mathbf{x},y;\theta) &amp;= \frac{p(y|\mathbf{x};\theta)}{p(y|\mathbf{x};\theta) + k\, q(y)} = \frac{\tilde{p}(y|\mathbf{x};\theta) / Z(\mathbf{x};\theta)}{\tilde{p}(y|\mathbf{x};\theta) / Z(\mathbf{x};\theta) + k\, q(y)} \\ p(D=0|\mathbf{x},y;\theta) &amp;= \frac{k\, q(y)}{p(y|\mathbf{x};\theta) + k\, q(y)} = \frac{k\, q(y)}{\tilde{p}(y|\mathbf{x};\theta)/Z(\mathbf{x};\theta) + k\, q(y)} \end{align} \]</span> and the NCE objective (which should be <strong>maximized</strong>) is defined as: <span class="math display">\[ \begin{align} \mathcal{L}_{\mathrm{NCE}} &amp;= \mathbb{E}_{(\mathbf{x},y) \sim p_d(\mathbf{x},y)} \left[ \log p(D=1|\mathbf{x},y;\theta) + k\, \mathbb{E}_{\bar{y} \sim q(y)}\left[ \log p(D=0|\mathbf{x},\bar{y}) \right] \right] \\ &amp;\approx \sum_{\mathbf{x},y } \left[ \log p(D=1|\mathbf{x},y;\theta) + k\cdot\frac{1}{k}\sum_{j = 1 \dots k \\ \bar{y}_j \sim q(y)} \log p(D=0|\mathbf{x},\bar{y}_j;\theta) \right] \\ &amp;= \sum_{\mathbf{x},y } \left[ \log p(D=1|\mathbf{x},y;\theta) + \sum_{j = 1}^k \log p(D=0|\mathbf{x},\bar{y}_j;\theta) \right] \end{align} \]</span> where <span class="math inline">\(\sum_{\mathbf{x},y}\)</span> is a summation over the train data in a mini-batch, and <span class="math inline">\(\frac{1}{k}\sum_{j = 1 \dots k \\ \bar{y}_j \sim q(y)}\)</span> is a Monte Carlo estimator of <span class="math inline">\(\mathbb{E}_{\bar{y} \sim q(y)}\)</span>.</p><p>A necessary condition for NCE to work is that, <span class="math inline">\(q(y) \neq 0\)</span> wherever <span class="math inline">\(p(y|\mathbf{x};\theta) \neq 0\)</span>.</p><h3 id="the-gradient-of-nce-loss">The Gradient of NCE Loss</h3><p><span class="math display">\[ \begin{align} \frac{\partial \mathcal{L}_{\mathrm{NCE}}}{\partial \theta} &amp;= \frac{\partial}{\partial \theta} \mathbb{E}_{p_d(\mathbf{x},y)} \left[ \log \frac{p(y|\mathbf{x};\theta)}{p(y|\mathbf{x};\theta) + k\, q(y)} + k\, \mathbb{E}_{q(y)}\left[ \log \frac{k\, q(y)}{p(y|\mathbf{x};\theta) + k\, q(y)} \right] \right] \\ &amp;= \frac{\partial}{\partial \theta} \mathbb{E}_{p_d(\mathbf{x})} \left[ \mathbb{E}_{p_d(y|\mathbf{x})} \left[ \log \frac{p(y|\mathbf{x};\theta)}{p(y|\mathbf{x};\theta) + k\, q(y)} \right] + k\, \mathbb{E}_{q(y)}\left[ \log \frac{k\, q(y)}{p(y|\mathbf{x};\theta) + k\, q(y)} \right] \right] \\ &amp;= \mathbb{E}_{p_d(\mathbf{x})} \left[ \mathbb{E}_{p_d(y|\mathbf{x})} \left[ \frac{1}{p(y|\mathbf{x};\theta)} \cdot \frac{k\,q(y)}{p(y|\mathbf{x};\theta) + k\, q(y)} \cdot \frac{\partial p(y|\mathbf{x};\theta)}{\partial \theta} \right] - k\, \mathbb{E}_{q(y)}\left[ \frac{1}{p(y|\mathbf{x};\theta) + k\, q(y)} \cdot \frac{\partial p(y|\mathbf{x};\theta)}{\partial \theta} \right] \right] \\ &amp;= \mathbb{E}_{p_d(\mathbf{x})} \left[ \mathbb{E}_{p_d(y|\mathbf{x})} \left[ \frac{k\,q(y)}{p(y|\mathbf{x};\theta) + k\, q(y)} \cdot \frac{\partial \log p(y|\mathbf{x};\theta)}{\partial \theta} \right] - k\, \mathbb{E}_{q(y)}\left[ \frac{p(y|\mathbf{x};\theta)}{p(y|\mathbf{x};\theta) + k\, q(y)} \cdot \frac{\partial \log p(y|\mathbf{x};\theta)}{\partial \theta} \right] \right] \\ &amp;= \mathbb{E}_{p_d(\mathbf{x})} \sum_y \left[ \frac{k\,q(y)}{p(y|\mathbf{x};\theta) + k\, q(y)} \cdot \bigg( p_d(y|\mathbf{x}) - p(y|\mathbf{x};\theta) \bigg) \cdot \frac{\partial \log p(y|\mathbf{x};\theta)}{\partial \theta} \right] \end{align} \]</span></p><p>Note that:</p><p><span class="math display">\[ \sum_y \left[ p(y|\mathbf{x};\theta) \cdot \frac{\partial \log p(y|\mathbf{x};\theta)}{\partial \theta} \right] = \sum_y \frac{\partial p(y|\mathbf{x};\theta)}{\partial \theta} = \frac{\partial}{\partial \theta} \sum_y p(y|\mathbf{x};\theta) = \frac{\partial 1}{\partial \theta} = 0 \]</span></p><p>Thus, when <span class="math inline">\(k \to \infty\)</span>, <span class="math inline">\(\frac{\partial \mathcal{L}_{\mathrm{NCE}}}{\partial \theta}\)</span> equals to <span class="math inline">\(\frac{\partial}{\partial \theta} \mathbb{E}_{p_d(\mathbf{x},y)}\left[ \log p(y|\mathbf{x};\theta) \right]\)</span>, which is the gradient for the original classification problem.</p><h3 id="the-global-optimum-of-nce-loss">The Global Optimum of NCE Loss</h3><p><em>(This section is added by me. The original NCE paper <span class="citation" data-cites="gutmannNoisecontrastiveEstimationNew2010">(Gutmann and Hyvärinen <a href="#ref-gutmannNoisecontrastiveEstimationNew2010" role="doc-biblioref">2010</a>)</span> has a similar theorem, but did not give the proof. I use Euler's formula from Calculus of Variations, but in fact the condition of using this theorem is not strictly satisfied. Thus this proof may only be seen as a discussion.)</em> <span class="math display">\[ \begin{align} \frac{\partial \mathcal{L}_{\mathrm{NCE}}}{\partial p(y|\mathbf{x};\theta)} &amp;= \mathbb{E}_{p_d(\mathbf{x})} \sum_y \left[ \frac{k\,q(y)}{p(y|\mathbf{x};\theta) + k\,q(y)} \cdot \bigg( p_d(y|\mathbf{x}) - p(y|\mathbf{x};\theta) \bigg) \cdot \frac{1}{p(y|\mathbf{x};\theta)} \right] \end{align} \]</span> According to Euler's formula: <span class="math display">\[ \begin{align} \frac{\partial \mathcal{L}_{\mathrm{NCE}}}{\partial p(y|\mathbf{x};\theta)} = 0 &amp;\Leftrightarrow \frac{k\,q(y)}{p(y|\mathbf{x};\theta) + k\,q(y)} \cdot \bigg( p_d(y|\mathbf{x}) - p(y|\mathbf{x};\theta) \bigg) \cdot \frac{1}{p(y|\mathbf{x};\theta)} = 0 \end{align} \]</span> Since <span class="math inline">\(q(y)\)</span> is arbitrary, the only solution for <span class="math inline">\(\mathcal{L}_{\mathrm{NCE}}\)</span> to attains its global optimum is: <span class="math display">\[ p(y|\mathbf{x};\theta) \equiv p_d(y|\mathbf{x}) \]</span></p><h3 id="dealing-with-zmathbfxtheta">Dealing with <span class="math inline">\(Z(\mathbf{x};\theta)\)</span></h3><p>For NCE, <span class="math inline">\(Z(\mathbf{x};\theta)\)</span> can be learned instead of estimated. To avoid having extra free parameters, <span class="citation" data-cites="mnihFastSimpleAlgorithm2012">Mnih and Teh (<a href="#ref-mnihFastSimpleAlgorithm2012" role="doc-biblioref">2012</a>)</span> suggested to let <span class="math inline">\(Z(\mathbf{x};\theta) \equiv 1\)</span>, and found it works well. Having a fixed <span class="math inline">\(Z(\mathbf{x};\theta) \equiv 1\)</span> will likely to induce a normalized <span class="math inline">\(p(y|\mathbf{x};\theta)\)</span>.</p><h2 id="negative-sampling">Negative Sampling</h2><p>Negative sampling <span class="citation" data-cites="mikolovDistributedRepresentationsWords2013">(Mikolov et al. <a href="#ref-mikolovDistributedRepresentationsWords2013" role="doc-biblioref">2013</a>)</span> can be seen as a simplified version of noise contrastive estimation. The binary classifier is defined as: <span class="math display">\[ \begin{align} p(D=1|\mathbf{x},y;\theta) &amp;= \frac{p(y|\mathbf{x};\theta)}{p(y|\mathbf{x};\theta) + 1} \\ p(D=0|\mathbf{x},y;\theta) &amp;= \frac{1}{p(y|\mathbf{x};\theta) + 1} \end{align} \]</span> that is, <span class="math inline">\(q(y) \equiv \frac{1}{k}\)</span>. The loss is derived as: <span class="math display">\[ \begin{align} \mathcal{L}_{\mathrm{NEG}} &amp;= \mathbb{E}_{(\mathbf{x},y) \sim p_d(\mathbf{x},y)} \left[ \log p(D=1|\mathbf{x},y;\theta) + \mathbb{E}_{\bar{y} \sim q(y)}\left[ \log p(D=0|\mathbf{x},\bar{y}) \right] \right] \\ &amp;= \mathbb{E}_{p_d(\mathbf{x})} \left[ \mathbb{E}_{ p(y|\mathbf{x};\theta)}\left[ \log \frac{p(y|\mathbf{x};\theta)}{p(y|\mathbf{x};\theta) + 1} \right] + k\,\mathbb{E}_{q(y)}\left[ \log \frac{1}{p(y|\mathbf{x};\theta) + 1} \right] \right] \\ &amp;\approx \frac{1}{N} \sum_{\mathbf{x},y } \left[ \log \frac{p(y|\mathbf{x};\theta)}{p(y|\mathbf{x};\theta) + 1} + \sum_{j = 1}^k \log \frac{1}{p(\bar{y}_j|\mathbf{x};\theta) + 1} \right] \end{align} \]</span></p><h3 id="the-normalizing-factor">The Normalizing Factor</h3><p>The negative sampling does not train a properly normalized <span class="math inline">\(p(y|\mathbf{x};\theta)\)</span> <span class="citation" data-cites="dyerNotesNoiseContrastive2014">(Dyer <a href="#ref-dyerNotesNoiseContrastive2014" role="doc-biblioref">2014</a>)</span>, unless <span class="math inline">\(k = m\)</span>, where <span class="math inline">\(q(y) \equiv \frac{1}{m}\)</span> is a normalized uniform distribution, since: <span class="math display">\[ \begin{align} \mathcal{L}_{\mathrm{NEG}} &amp;= \mathbb{E}_{p_d(\mathbf{x})} \left[ \mathbb{E}_{ p_d(y|\mathbf{x})}\left[ \log \frac{p(y|\mathbf{x};\theta)}{p(y|\mathbf{x};\theta) + 1} \right] + k\,\mathbb{E}_{q(y)}\left[ \log \frac{1}{p(y|\mathbf{x};\theta) + 1} \right] \right] \\ &amp;= \mathbb{E}_{p_d(\mathbf{x})} \left[ \mathbb{E}_{ p_d(y|\mathbf{x}) }\left[ \log \frac{p(y|\mathbf{x};\theta) / \frac{m}{k}}{p(y|\mathbf{x};\theta) / \frac{m}{k} + k \cdot \left( \frac{1}{k} \cdot \frac{k}{m} \right)} \right] + k\,\mathbb{E}_{q(y)}\left[ \log \frac{k \cdot \left( \frac{1}{k} \cdot \frac{k}{m} \right)}{p(y|\mathbf{x};\theta) / \frac{m}{k} + k \cdot \left( \frac{1}{k} \cdot \frac{k}{m} \right)} \right] \right] \end{align} \]</span> <em>If we believe <span class="math inline">\(q(y) \equiv \frac{1}{m}\)</span> (which is often indeed the case for uniform sampling of the noise samples), then this should be a standard NCE loss, and the learned "probability distribution" <span class="math inline">\(p(y|\mathbf{x};\theta)\)</span> could potentially be converted into a truely normalized distribution, by scaling it with the normalizing factor <span class="math inline">\(Z(\mathbf{x};\theta) \equiv \frac{m}{k}\)</span>. (This assertion is made by me)</em></p><h1 id="bibliography" class="unnumbered">References</h1><div id="refs" class="references" role="doc-bibliography"><div id="ref-dyerNotesNoiseContrastive2014"><p>Dyer, Chris. 2014. “Notes on Noise Contrastive Estimation and Negative Sampling.” <em>arXiv Preprint arXiv:1410.8251</em>.</p></div><div id="ref-gutmannNoisecontrastiveEstimationNew2010"><p>Gutmann, Michael, and Aapo Hyvärinen. 2010. “Noise-Contrastive Estimation: A New Estimation Principle for Unnormalized Statistical Models.” In <em>Proceedings of the Thirteenth International Conference on Artificial Intelligence and Statistics</em>, 297–304.</p></div><div id="ref-mikolovDistributedRepresentationsWords2013"><p>Mikolov, Tomas, Ilya Sutskever, Kai Chen, Greg S. Corrado, and Jeff Dean. 2013. “Distributed Representations of Words and Phrases and Their Compositionality.” In <em>Advances in Neural Information Processing Systems</em>, 3111–9.</p></div><div id="ref-mnihFastSimpleAlgorithm2012"><p>Mnih, Andriy, and Yee Whye Teh. 2012. “A Fast and Simple Algorithm for Training Neural Probabilistic Language Models.” <em>arXiv:1206.6426 [Cs]</em>, June. <a href="http://arxiv.org/abs/1206.6426" target="_blank" rel="noopener">http://arxiv.org/abs/1206.6426</a>.</p></div></div></div><div style="height:10px"></div></div></article><article id="post-Deep_Learning/Energy_Based_Models/Energy_Function_in_Probabilistic_Models" class="article article-type-post" itemscope itemprop="blogPost"><div class="article-inner"><header class="article-header"><div class="article-meta"><div class="article-category"><i class="fa fa-folder"></i> <a class="article-category-link" href="/categories/Deep-Learning/">Deep Learning</a><i class="fa fa-angle-right"></i><a class="article-category-link" href="/categories/Deep-Learning/Energy-Based-Models/">Energy Based Models</a></div><div class="article-date"><i class="fa fa-calendar"></i> <a href="/Deep_Learning/Energy_Based_Models/Energy_Function_in_Probabilistic_Models/"><time datetime="2020-02-28T22:43:51.000Z" itemprop="datePublished">2020-02-29</time></a></div><div class="article-meta-button"><a href="https://github.com/haowen-xu/research-notes/raw/master/source/_posts/Deep_Learning/Energy_Based_Models/Energy_Function_in_Probabilistic_Models.md">Source</a></div><div class="article-meta-button"><a href="https://github.com/haowen-xu/research-notes/edit/master/source/_posts/Deep_Learning/Energy_Based_Models/Energy_Function_in_Probabilistic_Models.md">Edit</a></div><div class="article-meta-button"><a href="https://github.com/haowen-xu/research-notes/commits/master/source/_posts/Deep_Learning/Energy_Based_Models/Energy_Function_in_Probabilistic_Models.md">History</a></div></div><h1 itemprop="name"><a class="article-title" href="/Deep_Learning/Energy_Based_Models/Energy_Function_in_Probabilistic_Models/">Energy Function in Probabilistic Models</a></h1></header><div class="article-entry" itemprop="articleBody"><p>This post summarizes the relationship between energy function and the deduced probabilistic model by a specified energy function.</p><h2 id="common-formulation">Common Formulation</h2><p>The probabilistic model deduced from an energy function can have the following formulations.</p><h3 id="gibbs-distribution">Gibbs Distribution</h3><p>Given an energy function <span class="math inline">\(U(\mathbf{x};\theta)\)</span> with parameters <span class="math inline">\(\theta\)</span>, the probability distribution can be deduced as: <span class="math display">\[ \begin{align} p(\mathbf{x};\theta) &amp;= \frac{1}{Z(\theta)}\,\exp\left( -U(\mathbf{x};\theta) \right) \\ Z(\theta) &amp;= \int \exp\left( -U(\mathbf{x};\theta) \right)\,\mathrm{d}\mathbf{x} \end{align} \]</span> The gradient of <span class="math inline">\(\mathbb{E}_{p_D(\mathbf{x})}\left[ -\log p(\mathbf{x};\theta) \right]\)</span> (i.e., the expectation of the negative log-likelihood <span class="math inline">\(-\log p(\mathbf{x})\)</span> over data distribution <span class="math inline">\(p_D(\mathbf{x})\)</span>) is then derived as: <span class="math display">\[ \begin{align} \nabla \mathbb{E}_{p_D(\mathbf{x};\theta)}\left[ -\log p(\mathbf{x};\theta) \right] &amp;= \mathbb{E}_{p_D(\mathbf{x})}\left[ -\nabla \log p(\mathbf{x};\theta) \right] \\ &amp;= \mathbb{E}_{p_D(\mathbf{x})} \left[ \nabla U(\mathbf{x};\theta) + \nabla \log Z(\theta) \right] \\ &amp;= \mathbb{E}_{p_D(\mathbf{x})} \left[ \nabla U(\mathbf{x};\theta) \right] + \nabla \log Z(\theta) \end{align} \]</span></p><p>where <span class="math inline">\(\nabla \log Z(\theta)\)</span> is: <span class="math display">\[ \begin{align} \nabla \log Z(\theta) &amp;= \frac{\nabla Z(\theta)}{Z(\theta)} \\ &amp;= \frac{1}{Z(\theta)} \int \nabla \exp\left( -U(\mathbf{x};\theta) \right)\,\mathrm{d}\mathbf{x} \\ &amp;= \int \frac{\exp\left( -U(\mathbf{x};\theta) \right) / Z(\theta)}{\exp\left( -U(\mathbf{x};\theta) \right)} \nabla \exp\left( -U(\mathbf{x};\theta) \right) \,\mathrm{d}\mathbf{x} \\ &amp;= \int p(\mathbf{x};\theta) \, \nabla \log \exp\left( -U(\mathbf{x};\theta) \right) \,\mathrm{d}\mathbf{x} \\ &amp;= -\int p(\mathbf{x};\theta) \, \nabla U(\mathbf{x};\theta) \,\mathrm{d}\mathbf{x} \\ &amp;= -\mathbb{E}_{p(\mathbf{x};\theta)} \left[ \nabla U(\mathbf{x};\theta) \right] \end{align} \]</span> thus the final gradient can be derived as: <span class="math display">\[ \nabla \mathbb{E}_{p_D(\mathbf{x};\theta)}\left[ -\log p(\mathbf{x};\theta) \right] = \mathbb{E}_{p_D(\mathbf{x})} \left[ \nabla U(\mathbf{x};\theta) \right] - \mathbb{E}_{p(\mathbf{x};\theta)} \left[ \nabla U(\mathbf{x};\theta) \right] \]</span></p><h4 id="positive-and-negative-phase">Positive and Negative Phase</h4><p>The above gradient consists of the positive phase term <span class="math inline">\(\mathbb{E}_{p_D(\mathbf{x})} \left[ \nabla U(\mathbf{x};\theta) \right]\)</span>, and the negative phase term <span class="math inline">\(\mathbb{E}_{p(\mathbf{x};\theta)} \left[ \nabla U(\mathbf{x};\theta) \right]\)</span>. The gradient reaches zero (which indicates a local minima) when these two terms are equal.</p><p><em>If the path of the gradient to <span class="math inline">\(\mathbb{E}_{p(\mathbf{x};\theta)}\)</span> is blocked (this sentence is added by me)</em>, then the positive phase term can be seen as minimizing the energy on "positive samples" from data distribution, and the negative phase can be seen as maximizing the energy on "negative samples" from model distribution. <span class="citation" data-cites="kimDeepDirectedGenerative2016">(Kim and Bengio <a href="#ref-kimDeepDirectedGenerative2016" role="doc-biblioref">2016</a>)</span></p><p>Sampling from <span class="math inline">\(\mathbb{E}_{p(\mathbf{x};\theta)}\)</span> often requires MCMC techniques, for example, the <a href="/Deep_Learning/Confronting_Partition_Function/Contrastive_Divergence/">Contrastive Divergence</a> algorithm.</p><h2 id="conditional-and-independence">Conditional and Independence</h2><h3 id="definition">Definition</h3><p>The distribution <span class="math inline">\(p(\mathbf{x},\mathbf{y},\mathbf{z})\)</span> deduced by energy function <span class="math inline">\(U(\mathbf{x},\mathbf{y},\mathbf{z})\)</span>: <span class="math display">\[ p(\mathbf{x},\mathbf{y},\mathbf{z}) = \frac{\exp\left( -U(\mathbf{x},\mathbf{y},\mathbf{z}) \right)}{\iiint \exp\left( -U(\mathbf{x}^*,\mathbf{y}^*,\mathbf{z}^*) \right) \, \mathrm{d}\mathbf{z}^* \,\mathrm{d}\mathbf{y}^* \,\mathrm{d}\mathbf{x}^*} \]</span> Also, the conditional distribution <span class="math inline">\(p(\mathbf{y},\mathbf{z}|\mathbf{x})\)</span> is defined as: <span class="math display">\[ p(\mathbf{y},\mathbf{z}|\mathbf{x}) = \frac{\exp\left( -U(\mathbf{x},\mathbf{y},\mathbf{z}) \right)}{\iint \exp\left( -U(\mathbf{x},\mathbf{y}^*,\mathbf{z}^*) \right) \, \mathrm{d}\mathbf{z}^* \,\mathrm{d}\mathbf{y}^*} \]</span></p><h3 id="theorem-1">Theorem 1</h3><p>If <span class="math inline">\(U(\mathbf{x},\mathbf{y},\mathbf{z}) = f(\mathbf{x},\mathbf{y}) + g(\mathbf{x},\mathbf{z}) + h(\mathbf{x})\)</span>, then: <span class="math display">\[ \begin{align} p(\mathbf{y}|\mathbf{x}) &amp;= \frac{\exp\left( -f(\mathbf{x},\mathbf{y}) \right)}{\int \exp\left( -f(\mathbf{x},\mathbf{y}^*) \right) \,\mathrm{d}\mathbf{y}^*} \\ p(\mathbf{z}|\mathbf{x}) &amp;= \frac{\exp\left( -g(\mathbf{x},\mathbf{z}) \right)}{\int \exp\left( -g(\mathbf{x},\mathbf{z}^*) \right) \,\mathrm{d}\mathbf{z}^*} \end{align} \]</span> <em>Proof</em>: <span class="math display">\[ \begin{align} p(\mathbf{y}|\mathbf{x}) &amp;= \int p(\mathbf{x},\mathbf{y},\mathbf{z})\,\mathrm{d}\mathbf{z} \\ &amp;= \int \frac{\exp\left( -U(\mathbf{x},\mathbf{y},\mathbf{z}) \right)}{\iint \exp\left( -U(\mathbf{x},\mathbf{y}^*,\mathbf{z}^*) \right) \, \mathrm{d}\mathbf{z}^* \,\mathrm{d}\mathbf{y}^*}\,\mathrm{d}\mathbf{z} \\ &amp;= \frac{\exp\left( -h(\mathbf{x}) \right)\cdot\exp\left( -f(\mathbf{x},\mathbf{y}) \right) \int \exp\left( -g(\mathbf{x},\mathbf{z}) \right)\,\mathrm{d}\mathbf{z}}{\iint \exp\left( -h(\mathbf{x}) \right)\cdot\exp\left( -f(\mathbf{x},\mathbf{y}^*)\right) \cdot\exp\left( -g(\mathbf{x},\mathbf{z}^*) \right)\,\mathrm{d}\mathbf{z}^*\,\mathrm{d}\mathbf{y}^*} \\ &amp;= \frac{\exp\left( -h(\mathbf{x}) \right)\cdot\exp\left( -f(\mathbf{x},\mathbf{y}) \right) \int \exp\left( -g(\mathbf{x},\mathbf{z}) \right)\,\mathrm{d}\mathbf{z}}{\exp\left( -h(\mathbf{x}) \right)\cdot\left( \int \exp\left( -f(\mathbf{x},\mathbf{y}^*)\right)\,\mathrm{d}\mathbf{y}^* \right) \cdot \left( \int \exp\left( -g(\mathbf{x},\mathbf{z}^*) \right)\,\mathrm{d}\mathbf{z}^* \right)} \\ &amp;= \frac{\exp\left( -f(\mathbf{x},\mathbf{y}) \right)}{\int \exp\left( -f(\mathbf{x},\mathbf{y}^*)\right)\,\mathrm{d}\mathbf{y}^*} \end{align} \]</span> <span class="math inline">\(p(\mathbf{z}|\mathbf{x}) = \frac{\exp\left( -g(\mathbf{x},\mathbf{z}) \right)}{\int \exp\left( -g(\mathbf{x},\mathbf{z}^*) \right) \,\mathrm{d}\mathbf{z}^*}\)</span> can be proven in the same way.</p><h4 id="collary-1">Collary 1</h4><p>If <span class="math inline">\(U(\mathbf{x},\mathbf{y},\mathbf{z}) = f(\mathbf{x},\mathbf{y}) + g(\mathbf{x},\mathbf{z}) + h(\mathbf{x})\)</span>, then <span class="math inline">\(\mathbf{y} \perp\!\!\!\perp \mathbf{z} \mid \mathbf{x}\)</span>.</p><p><em>Proof</em>: <span class="math display">\[ \begin{align} p(\mathbf{y},\mathbf{z}|\mathbf{x}) &amp;= \frac{\exp\left( -U(\mathbf{x},\mathbf{y},\mathbf{z}) \right)}{\iint \exp\left( -U(\mathbf{x},\mathbf{y}^*,\mathbf{z}^*) \right) \, \mathrm{d}\mathbf{z}^* \,\mathrm{d}\mathbf{y}^*} \\ &amp;= \frac{\exp\left( -f(\mathbf{x},\mathbf{y}) \right)}{\int \exp\left( -f(\mathbf{x},\mathbf{y}^*) \right) \,\mathrm{d}\mathbf{y}^*} \cdot \frac{\exp\left( -g(\mathbf{x},\mathbf{z}) \right)}{\int \exp\left( -g(\mathbf{x},\mathbf{z}^*) \right) \,\mathrm{d}\mathbf{z}^*} \\ &amp;= p(\mathbf{y}|\mathbf{x}) \cdot p(\mathbf{z}|\mathbf{x}) \end{align} \]</span> which implies <span class="math inline">\(\mathbf{y} \perp\!\!\!\perp \mathbf{z} \mid \mathbf{x}\)</span>.</p><h4 id="collary-2">Collary 2</h4><p>If <span class="math inline">\(U(\mathbf{y},\mathbf{z}) = f(\mathbf{y}) + g(\mathbf{z})\)</span>, then: <span class="math display">\[ \begin{align} p(\mathbf{y}) &amp;= \frac{\exp\left( -f(\mathbf{y}) \right)}{\int \exp\left( -f(\mathbf{y}^*) \right) \,\mathrm{d}\mathbf{y}^*} \\ p(\mathbf{z}) &amp;= \frac{\exp\left( -g(\mathbf{z}) \right)}{\int \exp\left( -g(\mathbf{z}^*) \right) \,\mathrm{d}\mathbf{z}^*} \end{align} \]</span> <em>Proof</em>: similar to Theorem 1.</p><h4 id="collary-3">Collary 3</h4><p>If <span class="math inline">\(U(\mathbf{y},\mathbf{z}) = f(\mathbf{y}) + g(\mathbf{z})\)</span>, then <span class="math inline">\(\mathbf{y} \perp\!\!\!\perp \mathbf{z}\)</span>.</p><p><em>Proof</em>: according to Collary 2, and similar to Collary 1.</p><h1 id="bibliography" class="unnumbered">References</h1><div id="refs" class="references" role="doc-bibliography"><div id="ref-kimDeepDirectedGenerative2016"><p>Kim, Taesup, and Yoshua Bengio. 2016. “Deep Directed Generative Models with Energy-Based Probability Estimation.” <em>arXiv Preprint arXiv:1606.03439</em>.</p></div></div></div><div style="height:10px"></div></div></article><article id="post-Deep_Learning/Energy_Based_Models/Restricted_Boltzmann_Machine" class="article article-type-post" itemscope itemprop="blogPost"><div class="article-inner"><header class="article-header"><div class="article-meta"><div class="article-category"><i class="fa fa-folder"></i> <a class="article-category-link" href="/categories/Deep-Learning/">Deep Learning</a><i class="fa fa-angle-right"></i><a class="article-category-link" href="/categories/Deep-Learning/Energy-Based-Models/">Energy Based Models</a></div><div class="article-date"><i class="fa fa-calendar"></i> <a href="/Deep_Learning/Energy_Based_Models/Restricted_Boltzmann_Machine/"><time datetime="2020-02-28T18:56:31.000Z" itemprop="datePublished">2020-02-29</time></a></div><div class="article-meta-button"><a href="https://github.com/haowen-xu/research-notes/raw/master/source/_posts/Deep_Learning/Energy_Based_Models/Restricted_Boltzmann_Machine.md">Source</a></div><div class="article-meta-button"><a href="https://github.com/haowen-xu/research-notes/edit/master/source/_posts/Deep_Learning/Energy_Based_Models/Restricted_Boltzmann_Machine.md">Edit</a></div><div class="article-meta-button"><a href="https://github.com/haowen-xu/research-notes/commits/master/source/_posts/Deep_Learning/Energy_Based_Models/Restricted_Boltzmann_Machine.md">History</a></div></div><h1 itemprop="name"><a class="article-title" href="/Deep_Learning/Energy_Based_Models/Restricted_Boltzmann_Machine/">Restricted Boltzmann Machine</a></h1></header><div class="article-entry" itemprop="articleBody"><h2 id="standard-rbm">Standard RBM</h2><p>The formuation of a standard Restricted Boltzmann Machine (RBM) consists of an observed binary variable <span class="math inline">\(\mathbf{v}\)</span> and a latent binary variable <span class="math inline">\(\mathbf{h}\)</span>, as well as an energy function defined as: <span class="math display">\[ E(\mathbf{v},\mathbf{h}) = -\mathbf{a}^{\top} \mathbf{v} - \mathbf{b}^{\top}\mathbf{h}-\mathbf{v}^{\top}\mathbf{W}\,\mathbf{h} \]</span> the probability of the model is defined as: <span class="math display">\[ P(\mathbf{v},\mathbf{h}) = \frac{1}{Z} \, \exp\left( -E(\mathbf{v},\mathbf{h}) \right) \]</span> where <span class="math inline">\(Z\)</span> is the partition function.</p><p>The conditional distributions are: <span class="math display">\[ \begin{align} P(\mathbf{v}|\mathbf{h}) &amp;= \frac{1}{Z(\mathbf{h})} \, \exp\left(\left( \mathbf{a} + \mathbf{W}\mathbf{h} \right)^{\top}\,\mathbf{v}\right) \\ P(\mathbf{h}|\mathbf{v}) &amp;= \frac{1}{Z(\mathbf{v})} \, \exp\left(\left( \mathbf{b}^{\top} + \mathbf{v}^{\top}\mathbf{W} \right)\mathbf{h}\right) \end{align} \]</span></p><p>It is easy to verify that <span class="math inline">\(h_i\)</span> is independent of <span class="math inline">\(h_j\)</span>, for <span class="math inline">\(i \neq j\)</span>, given an observed <span class="math inline">\(\mathbf{v}\)</span>. This is also true for <span class="math inline">\(v_i\)</span>, <span class="math inline">\(v_j\)</span> given <span class="math inline">\(\mathbf{h}\)</span>. Thus sampling from <span class="math inline">\(P(\mathbf{v},\mathbf{h})\)</span> could be achieved by sampling from the two conditional distributions alternatively (i.e., a block Gibbs sampler).</p><p>The parameters <span class="math inline">\(\mathbf{a},\mathbf{b},\mathbf{W}\)</span> of <span class="math inline">\(E(\mathbf{v},\mathbf{h})\)</span> can be optimized by <a href="/Deep_Learning/Confronting_Partition_Function/Contrastive_Divergence/">Contrastive Divergence</a> algorithm, with the energy function <span class="math inline">\(U(\mathbf{z})\)</span> for <span class="math inline">\(\mathbf{v}\)</span>, satisfying <span class="math inline">\(U(\mathbf{v}) + \log Z = \log P(\mathbf{v})\)</span>. Whereas it is more simply to deduce the energy function <span class="math inline">\(U(\mathbf{v})\)</span> if we consider the conditional independence of <span class="math inline">\(h_i\)</span>, <span class="math inline">\(h_j\)</span> beforehand, and use the element-wise notations, I provide here the deduction using vector notation.</p><h3 id="deduction-of-umathbfv-using-vector-notation">Deduction of <span class="math inline">\(U(\mathbf{v})\)</span> using Vector Notation</h3><p>The marginal distribution <span class="math inline">\(P(\mathbf{v})\)</span> for the training data is: <span class="math display">\[ P(\mathbf{v}) = \sum_{\mathbf{h}} P(\mathbf{v},\mathbf{h}) = \frac{1}{Z} \, \exp\left( \mathbf{a}^{\top}\mathbf{v} \right) \cdot \sum_{\mathbf{h}} \exp\left( \left( \mathbf{b}^{\top}+\mathbf{v}^{\top}\mathbf{W} \right)\mathbf{h} \right) \]</span> which results in the following energy function for <span class="math inline">\(\mathbf{v}\)</span>: <span class="math display">\[ U(\mathbf{v}) = \log P(\mathbf{v}) = \mathbf{a}^{\top}\mathbf{v} + \log\sum_{\mathbf{h}}\exp\left( \left( \mathbf{b}^{\top}+\mathbf{v}^{\top}\mathbf{W} \right)\mathbf{h} \right) \]</span> If the number of elements of the vector <span class="math inline">\(\mathbf{h}\)</span> is k, we can further get: <span class="math display">\[ \begin{align} \sum_{\mathbf{h}}\exp\left( \left( \mathbf{b}^{\top}+\mathbf{v}^{\top}\mathbf{W} \right)\mathbf{h} \right) &amp;= \sum_{h_1,h_2,\dots,h_k} \exp\left( \sum_{j=1}^k(b_j + \mathbf{v}^{\top} \mathbf{W}_j)\,h_j \right) \\ &amp;= \sum_{h_1,h_2,\dots,h_k} \prod_{j=1}^k \exp\left( (b_j+\mathbf{v}^{\top} \mathbf{W}_j) \,h_j \right) \\ &amp;= \prod_{j=1}^k \sum_{h_j} \exp\left( (b_j+\mathbf{v}^{\top} \mathbf{W}_j) \,h_j \right) \end{align} \]</span> where <span class="math inline">\(\mathbf{W}_j\)</span> is the <span class="math inline">\(j\)</span>-th column of the matrix <span class="math inline">\(\mathbf{W}\)</span>. We then have: <span class="math display">\[ U(\mathbf{v}) = \mathbf{a}^{\top}\mathbf{v} + \sum_{j=1}^k \log \sum_{h_j} \exp\left( (b_j+\mathbf{v}^{\top} \mathbf{W}_j) \,h_j \right) \]</span> Given that <span class="math inline">\(h_j\)</span> is a binary variable, <span class="math inline">\(\sum_{h_j}\)</span> can be it further deduced into: <span class="math display">\[ U(\mathbf{v}) = \mathbf{a}^{\top}\mathbf{v} + \sum_{j=1}^k \log \left( 1 + \exp\left( b_j+\mathbf{v}^{\top} \mathbf{W}_j \right) \right) \]</span></p></div><div style="height:10px"></div></div></article><nav id="page-nav"><a class="extend prev" rel="prev" href="/page/5/">&laquo; Prev</a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/4/">4</a><a class="page-number" href="/page/5/">5</a><span class="page-number current">6</span><a class="page-number" href="/page/7/">7</a><a class="page-number" href="/page/8/">8</a><span class="space">&hellip;</span><a class="page-number" href="/page/14/">14</a><a class="extend next" rel="next" href="/page/7/">Next &raquo;</a></nav></section></div><footer id="footer"><div class="outer"><div id="footer-info" class="inner">Haowen Xu &copy; 2020 <a rel="license" href="http://creativecommons.org/licenses/by-nc-nd/4.0/"><img alt="Creative Commons License" style="border-width:0" src="/images/by-nc-nd-4.0-80x15.png"></a><br>Powered by <a href="http://hexo.io/" target="_blank">Hexo</a> &amp; theme <a href="https://github.com/zthxxx/hexo-theme-Wikitten">Wikitten</a></div></div></footer><script src="/libs/lightgallery/js/lightgallery.min.js"></script><script src="/libs/lightgallery/js/lg-thumbnail.min.js"></script><script src="/libs/lightgallery/js/lg-pager.min.js"></script><script src="/libs/lightgallery/js/lg-autoplay.min.js"></script><script src="/libs/lightgallery/js/lg-fullscreen.min.js"></script><script src="/libs/lightgallery/js/lg-zoom.min.js"></script><script src="/libs/lightgallery/js/lg-hash.min.js"></script><script src="/libs/lightgallery/js/lg-share.min.js"></script><script src="/libs/lightgallery/js/lg-video.min.js"></script><script src="/libs/justified-gallery/jquery.justifiedGallery.min.js"></script><script type="text/x-mathjax-config">MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ["$","$"], ["\\(","\\)"] ],
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
            processEscapes: true,
            TeX: {
                equationNumbers: {
                    autoNumber: 'AMS'
                },
                style: {
                    'font-family': 'serif'
                }
            }
        },
        'HTML-CSS': {
            //preferredFont: 'TeX',
            fonts: ['TeX']
        }
    });
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax();
        for (var i = 0; i < all.length; ++i)
            all[i].SourceElement().parentNode.className += ' has-jax';
    });</script><script async src="//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><script src="/js/main.js"></script></div></body>