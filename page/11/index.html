<!DOCTYPE html><html lang="en"><head><meta name="generator" content="Hexo 3.9.0"><meta charset="utf-8"><title>My Research Wiki</title><meta name="keywords" content="My Research Wiki"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=1"><meta property="og:type" content="website"><meta property="og:title" content="My Research Wiki"><meta property="og:url" content="https://wiki.haowen-xu.com/page/11/index.html"><meta property="og:site_name" content="My Research Wiki"><meta property="og:locale" content="en"><meta name="twitter:card" content="summary"><meta name="twitter:title" content="My Research Wiki"><link rel="alternate" href="/atom.xml" title="My Research Wiki" type="application/atom+xml"><link rel="icon" href="/favicon.ico"><link rel="stylesheet" href="/libs/font-awesome/css/font-awesome.min.css"><link rel="stylesheet" href="/libs/open-sans/styles.css"><link rel="stylesheet" href="/libs/source-code-pro/styles.css"><link rel="stylesheet" href="/css/style.css"><script src="/libs/jquery/2.1.3/jquery.min.js"></script><script src="/libs/jquery/plugins/cookie/1.4.1/jquery.cookie.js"></script><link rel="stylesheet" href="/libs/lightgallery/css/lightgallery.min.css"><link rel="stylesheet" href="/libs/justified-gallery/justifiedGallery.min.css"></head></html><body><div id="container"><header id="header"><div id="header-main" class="header-inner"><div class="outer"><a href="/" id="logo"><i class="logo"></i> <span class="site-title">My Research Wiki</span></a><nav id="main-nav"><a class="main-nav-link" href="/">Home</a> <a class="main-nav-link" href="/archives">Archives</a> <a class="main-nav-link" href="/categories">Categories</a></nav><div id="search-form-wrap"><form class="search-form"><input type="text" class="ins-search-input search-form-input" placeholder="Search"> <button type="submit" class="search-form-submit"></button></form><div class="ins-search"><div class="ins-search-mask"></div><div class="ins-search-container"><div class="ins-input-wrapper"><input type="text" class="ins-search-input" placeholder="Type something..."> <span class="ins-close ins-selectable"><i class="fa fa-times-circle"></i></span></div><div class="ins-section-wrapper"><div class="ins-section-container"></div></div></div></div><script>window.INSIGHT_CONFIG={TRANSLATION:{POSTS:"Posts",PAGES:"Pages",CATEGORIES:"Categories",TAGS:"Tags",UNTITLED:"(Untitled)"},ROOT_URL:"/",CONTENT_URL:"/content.json"}</script><script src="/js/insight.js"></script></div></div></div><div id="main-nav-mobile" class="header-sub header-inner"><table class="menu outer"><tr><td><a class="main-nav-link" href="/">Home</a></td><td><a class="main-nav-link" href="/archives">Archives</a></td><td><a class="main-nav-link" href="/categories">Categories</a></td><td><div class="search-form"><input type="text" class="ins-search-input search-form-input" placeholder="Search"></div></td></tr></table></div></header><div class="outer"><aside id="sidebar"><div class="widget-wrap" id="categories"><h3 class="widget-title"><span>categories</span> &nbsp; <a id="allExpand" href="#"><i class="fa fa-angle-double-down fa-2x"></i></a></h3><ul class="unstyled" id="tree"><li class="directory"><a href="#" data-role="directory"><i class="fa fa-folder"></i> &nbsp; Deep Learning</a><ul class="unstyled" id="tree"><li class="directory"><a href="#" data-role="directory"><i class="fa fa-folder"></i> &nbsp; CV</a><ul class="unstyled" id="tree"><li class="file"><a href="/Deep_Learning/CV/Image_Segmentation/">Image Segmentation</a></li></ul></li><li class="directory"><a href="#" data-role="directory"><i class="fa fa-folder"></i> &nbsp; Confronting Partition Function</a><ul class="unstyled" id="tree"><li class="file"><a href="/Deep_Learning/Confronting_Partition_Function/Overview/">Overview</a></li><li class="file"><a href="/Deep_Learning/Confronting_Partition_Function/Contrastive_Divergence/">Contrastive Divergence</a></li><li class="file"><a href="/Deep_Learning/Confronting_Partition_Function/Score_Matching/">Score Matching</a></li><li class="file"><a href="/Deep_Learning/Confronting_Partition_Function/Softmax_Speedup/">Softmax Speedup</a></li></ul></li><li class="directory"><a href="#" data-role="directory"><i class="fa fa-folder"></i> &nbsp; Energy Based Models</a><ul class="unstyled" id="tree"><li class="file"><a href="/Deep_Learning/Energy_Based_Models/Overview/">Overview</a></li><li class="file"><a href="/Deep_Learning/Energy_Based_Models/Energy_Function_in_Probabilistic_Models/">Energy Function in Probabilistic Models</a></li><li class="file"><a href="/Deep_Learning/Energy_Based_Models/Restricted_Boltzmann_Machine/">Restricted Boltzmann Machine</a></li></ul></li><li class="directory"><a href="#" data-role="directory"><i class="fa fa-folder"></i> &nbsp; Evaluation</a><ul class="unstyled" id="tree"><li class="file"><a href="/Deep_Learning/Evaluation/Evaluation_Metrics/">Evaluation Metrics</a></li><li class="file"><a href="/Deep_Learning/Evaluation/Visualizing_High_Dimensional_Space/">Visualizing High Dimensional Space</a></li></ul></li><li class="directory"><a href="#" data-role="directory"><i class="fa fa-folder"></i> &nbsp; Generative Adversarial Nets</a><ul class="unstyled" id="tree"><li class="file"><a href="/Deep_Learning/Generative_Adversarial_Nets/Overview/">Overview</a></li><li class="file"><a href="/Deep_Learning/Generative_Adversarial_Nets/f-GAN/">f-GAN</a></li><li class="file"><a href="/Deep_Learning/Generative_Adversarial_Nets/Energy_GAN/">Energy GAN</a></li></ul></li><li class="directory"><a href="#" data-role="directory"><i class="fa fa-folder"></i> &nbsp; Graph Neural Networks</a><ul class="unstyled" id="tree"><li class="file"><a href="/Deep_Learning/Graph_Neural_Networks/Node_Embedding/">Node Embedding</a></li><li class="file"><a href="/Deep_Learning/Graph_Neural_Networks/Graph_Convolution_Network/">Graph Convolution Network</a></li><li class="file"><a href="/Deep_Learning/Graph_Neural_Networks/Graph_Auto_Encoder/">Graph Auto-Encoder</a></li></ul></li><li class="directory"><a href="#" data-role="directory"><i class="fa fa-folder"></i> &nbsp; Information Theoretical</a><ul class="unstyled" id="tree"><li class="file"><a href="/Deep_Learning/Information_Theoretical/KL-Divergence/">KL-Divergence</a></li><li class="file"><a href="/Deep_Learning/Information_Theoretical/Mutual_Information/">Mutual Information</a></li></ul></li><li class="directory"><a href="#" data-role="directory"><i class="fa fa-folder"></i> &nbsp; Monte Carlo Methods</a><ul class="unstyled" id="tree"><li class="file"><a href="/Deep_Learning/Monte_Carlo_Methods/Overview/">Overview</a></li><li class="file"><a href="/Deep_Learning/Monte_Carlo_Methods/Monte_Carlo_Integration/">Monte Carlo Integration</a></li><li class="file"><a href="/Deep_Learning/Monte_Carlo_Methods/Accept_Reject_Sampling/">Accept-Reject Sampling</a></li><li class="file"><a href="/Deep_Learning/Monte_Carlo_Methods/Markov_Chain/">Markov Chain</a></li><li class="file"><a href="/Deep_Learning/Monte_Carlo_Methods/Metropolis_Hastings_Algorithm/">Metropolis-Hastings Algorithm</a></li><li class="file"><a href="/Deep_Learning/Monte_Carlo_Methods/Gibbs_Sampler/">Gibbs Sampler</a></li><li class="file"><a href="/Deep_Learning/Monte_Carlo_Methods/Hamiltonian_Dynamics/">Hamiltonian Dynamics</a></li><li class="file"><a href="/Deep_Learning/Monte_Carlo_Methods/Langevin_Dynamics/">Langevin Dynamics</a></li></ul></li><li class="directory"><a href="#" data-role="directory"><i class="fa fa-folder"></i> &nbsp; Optimization</a><ul class="unstyled" id="tree"><li class="file"><a href="/Deep_Learning/Optimization/Gradient_Tricks/">Gradient Tricks</a></li><li class="file"><a href="/Deep_Learning/Optimization/Loss_Surface_and_Generalization/">Loss Surface and Generalization</a></li><li class="file"><a href="/Deep_Learning/Optimization/Stochastic_Gradient_Descent/">Stochastic Gradient descent</a></li></ul></li><li class="directory"><a href="#" data-role="directory"><i class="fa fa-folder"></i> &nbsp; Variational Autoencoder</a><ul class="unstyled" id="tree"><li class="file"><a href="/Deep_Learning/Variational_Autoencoder/Overview/">Overview</a></li><li class="file"><a href="/Deep_Learning/Variational_Autoencoder/Sequential_VAE/">Sequential VAE</a></li><li class="file"><a href="/Deep_Learning/Variational_Autoencoder/Gradient_Estimators_for_Variational_Inference/">Gradient Estimators for Variational Inference</a></li><li class="file"><a href="/Deep_Learning/Variational_Autoencoder/Theoretical_Facts/">Theoretical Facts about VAEs</a></li></ul></li></ul></li><li class="directory"><a href="#" data-role="directory"><i class="fa fa-folder"></i> &nbsp; Mathematics</a><ul class="unstyled" id="tree"><li class="directory"><a href="#" data-role="directory"><i class="fa fa-folder"></i> &nbsp; Analysis</a><ul class="unstyled" id="tree"><li class="file"><a href="/Mathematics/Analysis/Linear_Space_vs_Functional_Space/">Linear space vs functional space</a></li></ul></li><li class="directory"><a href="#" data-role="directory"><i class="fa fa-folder"></i> &nbsp; Calculus</a><ul class="unstyled" id="tree"><li class="file"><a href="/Mathematics/Calculus/Calculus_of_Variations/">Calculus of Variations</a></li></ul></li><li class="directory"><a href="#" data-role="directory"><i class="fa fa-folder"></i> &nbsp; Differential Equations</a><ul class="unstyled" id="tree"><li class="file"><a href="/Mathematics/Differential_Equations/Probability_Distribution_Equations/">Differential Equations on Probability Distributions</a></li></ul></li><li class="directory"><a href="#" data-role="directory"><i class="fa fa-folder"></i> &nbsp; Optimization</a><ul class="unstyled" id="tree"><li class="file"><a href="/Mathematics/Optimization/Convex_Optimization/">Convex Optimization</a></li></ul></li></ul></li><li class="directory"><a href="#" data-role="directory"><i class="fa fa-folder"></i> &nbsp; Research Work</a><ul class="unstyled" id="tree"><li class="file"><a href="/Research_Work/Reading_List/">Reading List</a></li><li class="file"><a href="/Research_Work/Tracking_the_Concepts/">Tracking the Concepts</a></li><li class="file"><a href="/Research_Work/Directions_to_Explore/">Directions to Explore</a></li></ul></li></ul></div><script>$(document).ready(function(){var r="fa-folder-open",i="fa-folder",l="fa-angle-double-down",d="fa-angle-double-up";$(document).on("click",'#categories a[data-role="directory"]',function(a){a.preventDefault();var e=$(this).children(".fa"),s=e.hasClass(r),l=$(this).siblings("ul");e.removeClass(r).removeClass(i),s?(void 0!==l&&l.slideUp({duration:100}),e.addClass(i)):(void 0!==l&&l.slideDown({duration:100}),e.addClass(r))}),$('#categories a[data-role="directory"]').bind("contextmenu",function(a){a.preventDefault();var e=$(this).children(".fa"),s=e.hasClass(r),l=$(this).siblings("ul"),d=$.merge(l.find("li ul"),l),o=$.merge(l.find(".fa"),e);o.removeClass(r).removeClass(i),s?(d.slideUp({duration:100}),o.addClass(i)):(d.slideDown({duration:100}),o.addClass(r))}),$(document).on("click","#allExpand",function(a){a.preventDefault();var e=$(this).children(".fa"),s=e.hasClass(l);e.removeClass(l).removeClass(d),s?($("#sidebar .fa.fa-folder").removeClass("fa-folder").addClass("fa-folder-open"),$("#categories li ul").slideDown({duration:100}),e.addClass(d)):($("#sidebar .fa.fa-folder-open").removeClass("fa-folder-open").addClass("fa-folder"),$("#categories li ul").slideUp({duration:100}),e.addClass(l))})})</script><div id="toTop" class="fa fa-angle-up"></div></aside><section id="main"><article id="post-Deep_Learning/Monte_Carlo_Methods/Overview" class="article article-type-post" itemscope itemprop="blogPost"><div class="article-inner"><header class="article-header"><div class="article-meta"><div class="article-category"><i class="fa fa-folder"></i> <a class="article-category-link" href="/categories/Deep-Learning/">Deep Learning</a><i class="fa fa-angle-right"></i><a class="article-category-link" href="/categories/Deep-Learning/Monte-Carlo-Methods/">Monte Carlo Methods</a></div><div class="article-date"><i class="fa fa-calendar"></i> <a href="/Deep_Learning/Monte_Carlo_Methods/Overview/"><time datetime="2019-10-18T06:03:00.000Z" itemprop="datePublished">2019-10-18</time></a></div><div class="article-meta-button"><a href="https://github.com/haowen-xu/research-notes/raw/master/source/_posts/Deep_Learning/Monte_Carlo_Methods/Overview.md">Source</a></div><div class="article-meta-button"><a href="https://github.com/haowen-xu/research-notes/edit/master/source/_posts/Deep_Learning/Monte_Carlo_Methods/Overview.md">Edit</a></div><div class="article-meta-button"><a href="https://github.com/haowen-xu/research-notes/commits/master/source/_posts/Deep_Learning/Monte_Carlo_Methods/Overview.md">History</a></div></div><h1 itemprop="name"><a class="article-title" href="/Deep_Learning/Monte_Carlo_Methods/Overview/">Overview</a></h1></header><div class="article-entry" itemprop="articleBody"><p>Monte Carlo methods are simulation methods to estimate quantities based on, or take random samples from, a given distribution <span class="math inline">\(p(x)\)</span>, where the exact form of <span class="math inline">\(p(x)\)</span> may be either known or unknown. The latter case may typically require Markov Chain Monte Carlo (MCMC) methods.</p><h2 id="simple-monte-carlo-methods">Simple Monte Carlo Methods</h2><ul><li>Estimating <span class="math inline">\(\mathbb{E}_{p(x)}\left[ f(x) \right]\)</span><ul><li><a href="/Deep_Learning/Monte_Carlo_Methods/Monte_Carlo_Integration/">Monte Carlo Integration</a></li></ul></li><li>Sampling from <span class="math inline">\(p(x)\)</span><ul><li><a href="/Deep_Learning/Monte_Carlo_Methods/Accept_Reject_Sampling/">Accept-Reject Sampling</a></li></ul></li></ul><h2 id="markov-chain-monte-carlo-methods">Markov Chain Monte Carlo methods</h2><ul><li><a href="/Deep_Learning/Monte_Carlo_Methods/Markov_Chain/">Markov Chain</a></li><li>Sampling from <span class="math inline">\(p(x)\)</span><ul><li><a href="/Deep_Learning/Monte_Carlo_Methods/Metropolis_Hastings_Algorithm/">Metropolis-Hastings Algorithm</a></li><li><a href="/Deep_Learning/Monte_Carlo_Methods/Gibbs_Sampler/">Gibbs Sampler</a></li><li><a href="/Deep_Learning/Monte_Carlo_Methods/Hamiltonian_Dynamics/">Hamiltonian Dynamics</a></li><li><a href="/Deep_Learning/Monte_Carlo_Methods/Langevin_Dynamics/">Langevin Dynamics</a></li></ul></li></ul></div><div style="height:10px"></div></div></article><article id="post-Deep_Learning/Confronting_Partition_Function/Score_Matching" class="article article-type-post" itemscope itemprop="blogPost"><div class="article-inner"><header class="article-header"><div class="article-meta"><div class="article-category"><i class="fa fa-folder"></i> <a class="article-category-link" href="/categories/Deep-Learning/">Deep Learning</a><i class="fa fa-angle-right"></i><a class="article-category-link" href="/categories/Deep-Learning/Confronting-Partition-Function/">Confronting Partition Function</a></div><div class="article-date"><i class="fa fa-calendar"></i> <a href="/Deep_Learning/Confronting_Partition_Function/Score_Matching/"><time datetime="2019-10-16T08:05:00.000Z" itemprop="datePublished">2019-10-16</time></a></div><div class="article-meta-button"><a href="https://github.com/haowen-xu/research-notes/raw/master/source/_posts/Deep_Learning/Confronting_Partition_Function/Score_Matching.md">Source</a></div><div class="article-meta-button"><a href="https://github.com/haowen-xu/research-notes/edit/master/source/_posts/Deep_Learning/Confronting_Partition_Function/Score_Matching.md">Edit</a></div><div class="article-meta-button"><a href="https://github.com/haowen-xu/research-notes/commits/master/source/_posts/Deep_Learning/Confronting_Partition_Function/Score_Matching.md">History</a></div></div><h1 itemprop="name"><a class="article-title" href="/Deep_Learning/Confronting_Partition_Function/Score_Matching/">Score Matching</a></h1></header><div class="article-entry" itemprop="articleBody"><h2 id="problem-statement">Problem Statement</h2><p>To find the optimum <span class="math inline">\(\theta\)</span> that minimizes <span class="math inline">\(U(\mathbf{X};\theta)\)</span> <em>w.r.t.</em> the given dataset <span class="math inline">\(\mathbf{X} = \{\mathbf{x}_1,\dots,\mathbf{x}_N\}\)</span> without estimating <span class="math inline">\(Z(\theta)\)</span>:</p><p><span class="math display">\[ \begin{align} U(\mathbf{X};\theta) &amp;= -\frac{1}{N} \sum_{i=1}^N \log p_m(\mathbf{x}_i;\theta) = \log Z(\theta) - \frac{1}{N} \sum_{i=1}^N \log \tilde{p}_m(\mathbf{x}_i;\theta) \\ p_m(\mathbf{x};\theta) &amp;= \frac{1}{Z(\theta)} \, \tilde{p}_m(\mathbf{x};\theta) \\ Z(\theta) &amp;= \int \tilde{p}_m(\mathbf{x};\theta)\,\mathrm{d}\mathbf{x} \end{align} \]</span></p><h2 id="score-matching">Score Matching</h2><p>Suppose each <span class="math inline">\(\mathbf{x}\)</span> is a <span class="math inline">\(k\)</span>-dimensional vector. The score function of the model <span class="math inline">\(p_m(\mathbf{x};\theta)\)</span> is defined as: <span class="math display">\[ \mathbf{s}(\mathbf{x};\theta) = \begin{pmatrix} \frac{\partial \log p_m(\mathbf{x};\theta)}{\partial x_1} \\ \vdots \\ \frac{\partial \log p_m(\mathbf{x};\theta)}{\partial x_k} \end{pmatrix} = \begin{pmatrix} \mathbf{s}_1(\mathbf{x};\theta) \\ \vdots \\ \mathbf{s}_k(\mathbf{x};\theta) \end{pmatrix} = \nabla_{\mathbf{x}} \log p_m(\mathbf{x};\theta) \]</span> It is easy to see that <span class="math inline">\(\mathbf{s}(\mathbf{x};\theta) = \nabla_{\mathbf{x}} \log \tilde{p}_m(\mathbf{x};\theta)\)</span>, since: <span class="math display">\[ \begin{align} \mathbf{s}(\mathbf{x};\theta) &amp;= \nabla_{\mathbf{x}} \log p_m(\mathbf{x};\theta) = \frac{1}{p_m(\mathbf{x};\theta)} \nabla_{\mathbf{x}} p_m(\mathbf{x};\theta) \\ &amp;= \frac{1}{\tilde{p}_m(\mathbf{x};\theta) / Z(\theta)} \cdot \nabla_{\mathbf{x}} \frac{\tilde{p}_m(\mathbf{x};\theta)}{Z(\theta)} = \frac{1}{\tilde{p}_m(\mathbf{x};\theta)} \nabla_{\mathbf{x}} \tilde{p}_m(\mathbf{x};\theta) = \nabla_{\mathbf{x}} \log \tilde{p}_m(\mathbf{x};\theta) \end{align} \]</span></p><p>And if we denote the score function for the empirical distribution <span class="math inline">\(p_d(\mathbf{x})\)</span> as <span class="math inline">\(\mathbf{s}_d(\mathbf{x})\)</span>, then the objective function is to match <span class="math inline">\(\mathbf{s}(\mathbf{x};\theta)\)</span> against <span class="math inline">\(\mathbf{s}_d(\mathbf{x})\)</span>, using squared loss: <span class="math display">\[ J(\theta) = \frac{1}{2} \int p_d(\mathbf{x}) \, \left\| \mathbf{s}(\mathbf{x};\theta) - \mathbf{s}_d(\mathbf{x}) \right\|_2^2 \,d\mathbf{x} \]</span></p><p>where, under some weak regularity conditions, <span class="math inline">\(J(\theta)\)</span> can be expressed as: <span class="math display">\[ \begin{align} &amp; J(\theta) = \int p_d(\mathbf{x})\sum_{i=1}^k \left[ \frac{\partial \mathbf{s}_i(\mathbf{x};\theta)}{\partial x_i} + \frac{1}{2} \mathbf{s}_i(\mathbf{x};\theta)^2 \right]\,d\mathbf{x} + const \\ &amp; \text{where} \;\, \frac{\partial \mathbf{s}_i(\mathbf{x};\theta)}{\partial x_i} = \frac{\partial^2 \log \tilde{p}_m(\mathbf{x};\theta)}{\partial x_i^2} \end{align} \]</span> or equivalently, using expectation and matrix notation: <span class="math display">\[ \begin{align} &amp; J(\theta) = \mathbb{E}_{p_d(\mathbf{x})}\left[ \operatorname{tr}\left( \nabla_{\mathbf{x}} \mathbf{s}(\mathbf{x};\theta) \right) + \frac{1}{2} \left\| \mathbf{s}(\mathbf{x};\theta) \right\|^2_2 \right] \\ &amp; \text{where} \;\, \nabla_{\mathbf{x}} \mathbf{s}(\mathbf{x};\theta) = \nabla^2_{\mathbf{x}} \log \tilde{p}_m(\mathbf{x};\theta) \;\, \text{is the Hessian matrix} \end{align} \]</span></p><p>For further materials, see <span class="citation" data-cites="hyvarinenEstimationNonnormalizedStatistical2005">Hyvärinen (<a href="#ref-hyvarinenEstimationNonnormalizedStatistical2005" role="doc-biblioref">2005</a>)</span>.</p><h3 id="score-estimation-in-implicit-generative-models">Score Estimation in Implicit Generative Models</h3><p>In implicit generative models (<em>i.e., GANs</em>), the sampling process may be explicitly given by:</p><p><span class="math display">\[ \mathbf{x} = g(\boldsymbol{\epsilon};\theta) \]</span></p><p>where <span class="math inline">\(\boldsymbol{\epsilon}\)</span> is a random variable independent of <span class="math inline">\(\theta\)</span>. The true density <span class="math inline">\(p_m(\mathbf{x};\theta)\)</span> is not tractable.</p><p>In this case, the score <span class="math inline">\(\nabla_{\mathbf{x}} \log p_m(\mathbf{x};\theta)\)</span> can be estimated by a dedicated score network <span class="math inline">\(\mathbf{s}(\mathbf{x};\phi)\)</span>, trained by minimizing the score-matching objective: <span class="math display">\[ J(\phi) = \mathbb{E}_{p_m(\mathbf{x};\theta)}\left[ \operatorname{tr}\left( \nabla_{\mathbf{x}} \mathbf{s}(\mathbf{x};\phi) \right) + \frac{1}{2} \left\| \mathbf{s}(\mathbf{x};\phi) \right\|^2_2 \right] \]</span> The learned score network can be used to estimate certain quantities involving the score <span class="math inline">\(\nabla_{\mathbf{x}} \log p_m(\mathbf{x};\theta)\)</span>. For example, the gradient of the entropy of <span class="math inline">\(p_m(\mathbf{x};\theta)\)</span>, *i.e., <span class="math inline">\(\nabla_{\theta} H\left(p_m(\mathbf{x};\theta)\right)\)</span>: <span class="math display">\[ \begin{align} \nabla_{\theta} H\left( p_m(\mathbf{x};\theta) \right) &amp;= -\nabla_{\theta} \mathbb{E}_{p_m(\mathbf{x};\theta)}\left[ \log p_m(\mathbf{x};\theta) \right] = -\nabla_{\theta} \mathbb{E}_{p(\boldsymbol{\epsilon})}\left[ \log p_m(g(\boldsymbol{\epsilon};\theta);\theta) \right] \\ &amp;= -\mathbb{E}_{p(\boldsymbol{\epsilon})}\left[ \nabla_{\theta} \log p_m(\mathbf{x};\theta) + \nabla_{\mathbf{x}} \log p_m(\mathbf{x};\theta)\big|_{\mathbf{x}=g(\boldsymbol{\epsilon;\theta})} \cdot \nabla_{\theta} g(\boldsymbol{\epsilon};\theta) \right] \\ &amp;= -\mathbb{E}_{p_m(\mathbf{x};\theta)}\left[ \nabla_{\theta} \log p_m(\mathbf{x};\theta) \right] - \mathbb{E}_{p(\boldsymbol{\epsilon})}\left[ \nabla_{\mathbf{x}} \log p_m(\mathbf{x};\theta)\big|_{\mathbf{x}=g(\boldsymbol{\epsilon;\theta})} \cdot \nabla_{\theta} g(\boldsymbol{\epsilon};\theta) \right] \\ &amp;= - \mathbb{E}_{p(\boldsymbol{\epsilon})}\left[ \nabla_{\mathbf{x}} \log p_m(\mathbf{x};\theta)\big|_{\mathbf{x}=g(\boldsymbol{\epsilon;\theta})} \cdot \nabla_{\theta} g(\boldsymbol{\epsilon};\theta) \right] \end{align} \]</span> where <span class="math inline">\(\mathbb{E}_{p_m(\mathbf{x};\theta)}\left[ \nabla_{\theta} \log p_m(\mathbf{x};\theta) \right]=0\)</span>, since: <span class="math display">\[ \begin{align} \mathbb{E}_{p_m(\mathbf{x};\theta)}\left[ \nabla_{\theta} \log p_m(\mathbf{x};\theta) \right] &amp;= \int p_m(\mathbf{x};\theta) \cdot {\nabla_{\theta} p_m(\mathbf{x};\theta) \over p_m(\mathbf{x};\theta)} \,d\mathbf{x} \\ = \int \nabla_{\theta} p_m(\mathbf{x};\theta)\,d\mathbf{x} &amp;= \nabla_{\theta} \int p_m(\mathbf{x};\theta)\,d\mathbf{x} = \nabla_{\theta} 1 = 0 \end{align} \]</span></p><p>For further materials, see <span class="citation" data-cites="liGradientEstimatorsImplicit2017">Li and Turner (<a href="#ref-liGradientEstimatorsImplicit2017" role="doc-biblioref">2017</a>)</span>.</p><h2 id="reducing-computation-cost">Reducing Computation Cost</h2><p><span class="math inline">\(\nabla_{\mathbf{x}} \mathbf{s}(\mathbf{x};\theta)\)</span> is the Hessian matrix of <span class="math inline">\(\log \tilde{p}_m(\mathbf{x};\theta)\)</span>,</p><h1 id="bibliography" class="unnumbered">References</h1><div id="refs" class="references" role="doc-bibliography"><div id="ref-hyvarinenEstimationNonnormalizedStatistical2005"><p>Hyvärinen, Aapo. 2005. “Estimation of Non-Normalized Statistical Models by Score Matching.” <em>Journal of Machine Learning Research</em> 6 (Apr): 695–709.</p></div><div id="ref-liGradientEstimatorsImplicit2017"><p>Li, Yingzhen, and Richard E. Turner. 2017. “Gradient Estimators for Implicit Models.” <em>arXiv:1705.07107 [Cs, Stat]</em>, May. <a href="http://arxiv.org/abs/1705.07107" target="_blank" rel="noopener">http://arxiv.org/abs/1705.07107</a>.</p></div></div></div><div style="height:10px"></div></div></article><article id="post-Deep_Learning/Confronting_Partition_Function/Contrastive_Divergence" class="article article-type-post" itemscope itemprop="blogPost"><div class="article-inner"><header class="article-header"><div class="article-meta"><div class="article-category"><i class="fa fa-folder"></i> <a class="article-category-link" href="/categories/Deep-Learning/">Deep Learning</a><i class="fa fa-angle-right"></i><a class="article-category-link" href="/categories/Deep-Learning/Confronting-Partition-Function/">Confronting Partition Function</a></div><div class="article-date"><i class="fa fa-calendar"></i> <a href="/Deep_Learning/Confronting_Partition_Function/Contrastive_Divergence/"><time datetime="2019-10-16T07:56:00.000Z" itemprop="datePublished">2019-10-16</time></a></div><div class="article-meta-button"><a href="https://github.com/haowen-xu/research-notes/raw/master/source/_posts/Deep_Learning/Confronting_Partition_Function/Contrastive_Divergence.md">Source</a></div><div class="article-meta-button"><a href="https://github.com/haowen-xu/research-notes/edit/master/source/_posts/Deep_Learning/Confronting_Partition_Function/Contrastive_Divergence.md">Edit</a></div><div class="article-meta-button"><a href="https://github.com/haowen-xu/research-notes/commits/master/source/_posts/Deep_Learning/Confronting_Partition_Function/Contrastive_Divergence.md">History</a></div></div><h1 itemprop="name"><a class="article-title" href="/Deep_Learning/Confronting_Partition_Function/Contrastive_Divergence/">Contrastive Divergence</a></h1></header><div class="article-entry" itemprop="articleBody"><h2 id="problem-statement">Problem Statement</h2><p>To find the optimum <span class="math inline">\(\theta\)</span> that minimizes <span class="math inline">\(U(\mathbf{X};\theta)\)</span> <em>w.r.t.</em> the given dataset <span class="math inline">\(\mathbf{X} = \{\mathbf{x}_1,\dots,\mathbf{x}_N\}\)</span> without estimating <span class="math inline">\(Z(\theta)\)</span>:</p><p><span class="math display">\[ \begin{align} U(\mathbf{X};\theta) &amp;= -\frac{1}{N} \sum_{i=1}^N \log p_m(\mathbf{x}_i;\theta) = \log Z(\theta) - \frac{1}{N} \sum_{i=1}^N \log \tilde{p}_m(\mathbf{x}_i;\theta) \\ p_m(\mathbf{x};\theta) &amp;= \frac{1}{Z(\theta)} \, \tilde{p}_m(\mathbf{x};\theta) \\ Z(\theta) &amp;= \int \tilde{p}_m(\mathbf{x};\theta)\,\mathrm{d}\mathbf{x} \end{align} \]</span></p><h2 id="contrastive-divergence">Contrastive Divergence</h2><p>The gradient for <span class="math inline">\(U(\mathbf{X};\theta)\)</span> is: <span class="math display">\[ \begin{align} \frac{\partial U(\mathbf{X};\theta)}{\partial \theta} &amp;= \frac{\partial \log Z(\theta)}{\partial \theta} - \frac{1}{N} \sum_{i=1}^N \frac{\partial \log \tilde{p}_m(\mathbf{x}_i;\theta)}{\partial \theta} \end{align} \]</span></p><p>The first term, <span class="math inline">\(\frac{\partial \log Z(\theta)}{\partial \theta}\)</span>, can be derived as:</p><p><span class="math display">\[ \begin{align} \frac{\partial \log Z(\theta)}{\partial \theta} &amp;= \frac{1}{Z(\theta)} \cdot \frac{\partial Z(\theta)}{\partial \theta} = \frac{1}{Z(\theta)} \cdot \int \frac{\partial \tilde{p}_m(\mathbf{x};\theta)}{\partial \theta}\,\mathrm{d}\mathbf{x} = \frac{1}{Z(\theta)} \cdot \int \tilde{p}_m(\mathbf{x};\theta)\,\frac{\partial \log \tilde{p}_m(\mathbf{x};\theta)}{\partial \theta}\,\mathrm{d}\mathbf{x} \\ &amp;= \int p_m(\mathbf{x};\theta)\,\frac{\partial \log \tilde{p}_m(\mathbf{x};\theta)}{\partial \theta}\,\mathrm{d}\mathbf{x} = \mathbb{E}_{p_m(\mathbf{x};\theta)}\left[\frac{\partial \log \tilde{p}_m(\mathbf{x};\theta)}{\partial \theta}\right] = \left&lt;\frac{\partial \log \tilde{p}_m(\mathbf{x};\theta)}{\partial \theta}\right&gt;_{\mathbf{X}} \end{align} \]</span></p><p>where <span class="math inline">\(\left&lt;\frac{\partial \log \tilde{p}_m(\mathbf{x};\theta)}{\partial \theta}\right&gt; _ {\mathbf{X}}\)</span> is the expectation of <span class="math inline">\(\frac{\partial \log \tilde{p}_m(\mathbf{x};\theta)}{\partial \theta}\)</span> over <span class="math inline">\(p_m(\mathbf{x};\theta)\)</span>. Also see <a href="/Deep_Learning/Energy_Based_Models/Energy_Function_in_Probabilistic_Models/#gibbs-distribution">Energy Function in Probabilistic Models</a> for another deduction.</p><p>Unfortunately, directly sampling from <span class="math inline">\(p_m(\mathbf{x};\theta)\)</span> is generally not possible. Thus, Hinton suggested to start with the empirical distribution (<em>i.e.</em>, dataset <span class="math inline">\(\mathbf{X}\)</span>), and use MCMC chain to approach <span class="math inline">\(p_m(\mathbf{x};\theta)\)</span>. Let <span class="math inline">\(\mathbf{X}^0 \equiv \mathbf{X}\)</span> be the samples from the empirical distribution <span class="math inline">\(p_d(\mathbf{x})\)</span>, <span class="math inline">\(\mathbf{X}^k\)</span> be the samples derived by <span class="math inline">\(k\)</span>-cycle MCMC chain, and <span class="math inline">\(\mathbf{X}^{\infty}\)</span> be the samples from the limit distribution of MCMC chain (<em>i.e.</em>, <span class="math inline">\(p_m(\mathbf{x};\theta)\)</span>), we then have: <span class="math display">\[ \begin{align} \frac{\partial U(\mathbf{X};\theta)}{\partial \theta} &amp;= \left&lt;\frac{\partial \log \tilde{p}_m(\mathbf{x};\theta)}{\partial \theta}\right&gt;_{\mathbf{X}^{\infty}} - \left&lt;\frac{\partial \log \tilde{p}_m(\mathbf{x};\theta)}{\partial \theta}\right&gt;_{\mathbf{X}^0} \\ &amp;\approx \left&lt;\frac{\partial \log \tilde{p}_m(\mathbf{x};\theta)}{\partial \theta}\right&gt;_{\mathbf{X}^k} - \left&lt;\frac{\partial \log \tilde{p}_m(\mathbf{x};\theta)}{\partial \theta}\right&gt;_{\mathbf{X}^0} \end{align} \]</span></p><p>This algorithm is called <em>CD-k</em> algorithm when using <span class="math inline">\(k\)</span>-cycle MCMC chain. For further materials, see <span class="citation" data-cites="woodfordNotesContrastiveDivergence">Woodford (<a href="#ref-woodfordNotesContrastiveDivergence" role="doc-biblioref">n.d.</a>)</span>.</p><p><span class="citation" data-cites="hintonTrainingProductsExperts2002">Hinton (<a href="#ref-hintonTrainingProductsExperts2002" role="doc-biblioref">2002</a>)</span> has found that even with 1-cycle MCMC chain, it is sufficient for the training to converge.</p><p>Interestingly, although the 1-cycle MCMC chain (or few cycles MCMC chain) is not expected to be a good estimator of the true <span class="math inline">\(p_m(\mathbf{x};\theta)\)</span>, it can be viewed as a neighborhood of a particular given training data <span class="math inline">\(\mathbf{x}\)</span> with relatively high log-likelihood (since by design, the chain starts from a given training data). Then optimizing the contrastive divergence loss can be viewed as <strong>"pull-down"</strong> the <em>energy</em> of some energy function <span class="math inline">\(E(\mathbf{x};\theta)\)</span> at the given train data, and <strong>"pull-up"</strong> the energy at the sampled neighborhood data, if we can write <span class="math inline">\(p_{m}(\mathbf{x};\theta) = \frac{\exp(-\beta E(\mathbf{x};\theta))}{\int \exp(-\beta E(\mathbf{x'};\theta))\,dx'}\)</span>. In this perspective, the CD-k algorithm can be viewed as a form of energy based learning, with approximated constrastive samples (see <a href="/Deep_Learning/Energy_Based_Models/Overview/#contrastive-divergence">Energy Based Models</a>).</p><h2 id="persistent-contrastive-divergence">Persistent Contrastive Divergence</h2><p><span class="citation" data-cites="tielemanTrainingRestrictedBoltzmann2008">Tieleman (<a href="#ref-tielemanTrainingRestrictedBoltzmann2008" role="doc-biblioref">2008</a>)</span> proposed to use the final samples from the previous MCMC chain at each mini-batch instead of the training points, as the initial state of the MCMC chain at each mini-batch.</p><h1 id="bibliography" class="unnumbered">References</h1><div id="refs" class="references" role="doc-bibliography"><div id="ref-hintonTrainingProductsExperts2002"><p>Hinton, Geoffrey E. 2002. “Training Products of Experts by Minimizing Contrastive Divergence.” <em>Neural Computation</em> 14 (8): 1771–1800.</p></div><div id="ref-tielemanTrainingRestrictedBoltzmann2008"><p>Tieleman, Tijmen. 2008. “Training Restricted Boltzmann Machines Using Approximations to the Likelihood Gradient.” In <em>Proceedings of the 25th International Conference on Machine Learning - ICML ’08</em>, 1064–71. Helsinki, Finland: ACM Press. <a href="https://doi.org/10.1145/1390156.1390290" target="_blank" rel="noopener">https://doi.org/10.1145/1390156.1390290</a>.</p></div><div id="ref-woodfordNotesContrastiveDivergence"><p>Woodford, Oliver. n.d. “Notes on Contrastive Divergence,” 3.</p></div></div></div><div style="height:10px"></div></div></article><nav id="page-nav"><a class="extend prev" rel="prev" href="/page/10/">&laquo; Prev</a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/9/">9</a><a class="page-number" href="/page/10/">10</a><span class="page-number current">11</span><a class="page-number" href="/page/12/">12</a><a class="page-number" href="/page/13/">13</a><a class="page-number" href="/page/14/">14</a><a class="extend next" rel="next" href="/page/12/">Next &raquo;</a></nav></section></div><footer id="footer"><div class="outer"><div id="footer-info" class="inner">Haowen Xu &copy; 2020 <a rel="license" href="http://creativecommons.org/licenses/by-nc-nd/4.0/"><img alt="Creative Commons License" style="border-width:0" src="/images/by-nc-nd-4.0-80x15.png"></a><br>Powered by <a href="http://hexo.io/" target="_blank">Hexo</a> &amp; theme <a href="https://github.com/zthxxx/hexo-theme-Wikitten">Wikitten</a></div></div></footer><script src="/libs/lightgallery/js/lightgallery.min.js"></script><script src="/libs/lightgallery/js/lg-thumbnail.min.js"></script><script src="/libs/lightgallery/js/lg-pager.min.js"></script><script src="/libs/lightgallery/js/lg-autoplay.min.js"></script><script src="/libs/lightgallery/js/lg-fullscreen.min.js"></script><script src="/libs/lightgallery/js/lg-zoom.min.js"></script><script src="/libs/lightgallery/js/lg-hash.min.js"></script><script src="/libs/lightgallery/js/lg-share.min.js"></script><script src="/libs/lightgallery/js/lg-video.min.js"></script><script src="/libs/justified-gallery/jquery.justifiedGallery.min.js"></script><script type="text/x-mathjax-config">MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ["$","$"], ["\\(","\\)"] ],
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
            processEscapes: true,
            TeX: {
                equationNumbers: {
                    autoNumber: 'AMS'
                },
                style: {
                    'font-family': 'serif'
                }
            }
        },
        'HTML-CSS': {
            //preferredFont: 'TeX',
            fonts: ['TeX']
        }
    });
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax();
        for (var i = 0; i < all.length; ++i)
            all[i].SourceElement().parentNode.className += ' has-jax';
    });</script><script async src="//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><script src="/js/main.js"></script></div></body>