<!DOCTYPE html><html lang="en"><head><meta name="generator" content="Hexo 3.9.0"><meta charset="utf-8"><title>My Research Wiki</title><meta name="keywords" content="My Research Wiki"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=1"><meta property="og:type" content="website"><meta property="og:title" content="My Research Wiki"><meta property="og:url" content="https://wiki.haowen-xu.com/page/10/index.html"><meta property="og:site_name" content="My Research Wiki"><meta property="og:locale" content="en"><meta name="twitter:card" content="summary"><meta name="twitter:title" content="My Research Wiki"><link rel="alternate" href="/atom.xml" title="My Research Wiki" type="application/atom+xml"><link rel="icon" href="/favicon.ico"><link rel="stylesheet" href="/libs/font-awesome/css/font-awesome.min.css"><link rel="stylesheet" href="/libs/open-sans/styles.css"><link rel="stylesheet" href="/libs/source-code-pro/styles.css"><link rel="stylesheet" href="/css/style.css"><script src="/libs/jquery/2.1.3/jquery.min.js"></script><script src="/libs/jquery/plugins/cookie/1.4.1/jquery.cookie.js"></script><link rel="stylesheet" href="/libs/lightgallery/css/lightgallery.min.css"><link rel="stylesheet" href="/libs/justified-gallery/justifiedGallery.min.css"></head></html><body><div id="container"><header id="header"><div id="header-main" class="header-inner"><div class="outer"><a href="/" id="logo"><i class="logo"></i> <span class="site-title">My Research Wiki</span></a><nav id="main-nav"><a class="main-nav-link" href="/">Home</a> <a class="main-nav-link" href="/archives">Archives</a> <a class="main-nav-link" href="/categories">Categories</a></nav><div id="search-form-wrap"><form class="search-form"><input type="text" class="ins-search-input search-form-input" placeholder="Search"> <button type="submit" class="search-form-submit"></button></form><div class="ins-search"><div class="ins-search-mask"></div><div class="ins-search-container"><div class="ins-input-wrapper"><input type="text" class="ins-search-input" placeholder="Type something..."> <span class="ins-close ins-selectable"><i class="fa fa-times-circle"></i></span></div><div class="ins-section-wrapper"><div class="ins-section-container"></div></div></div></div><script>window.INSIGHT_CONFIG={TRANSLATION:{POSTS:"Posts",PAGES:"Pages",CATEGORIES:"Categories",TAGS:"Tags",UNTITLED:"(Untitled)"},ROOT_URL:"/",CONTENT_URL:"/content.json"}</script><script src="/js/insight.js"></script></div></div></div><div id="main-nav-mobile" class="header-sub header-inner"><table class="menu outer"><tr><td><a class="main-nav-link" href="/">Home</a></td><td><a class="main-nav-link" href="/archives">Archives</a></td><td><a class="main-nav-link" href="/categories">Categories</a></td><td><div class="search-form"><input type="text" class="ins-search-input search-form-input" placeholder="Search"></div></td></tr></table></div></header><div class="outer"><aside id="sidebar"><div class="widget-wrap" id="categories"><h3 class="widget-title"><span>categories</span> &nbsp; <a id="allExpand" href="#"><i class="fa fa-angle-double-down fa-2x"></i></a></h3><ul class="unstyled" id="tree"><li class="directory"><a href="#" data-role="directory"><i class="fa fa-folder"></i> &nbsp; Deep Learning</a><ul class="unstyled" id="tree"><li class="directory"><a href="#" data-role="directory"><i class="fa fa-folder"></i> &nbsp; CV</a><ul class="unstyled" id="tree"><li class="file"><a href="/Deep_Learning/CV/Image_Segmentation/">Image Segmentation</a></li></ul></li><li class="directory"><a href="#" data-role="directory"><i class="fa fa-folder"></i> &nbsp; Confronting Partition Function</a><ul class="unstyled" id="tree"><li class="file"><a href="/Deep_Learning/Confronting_Partition_Function/Overview/">Overview</a></li><li class="file"><a href="/Deep_Learning/Confronting_Partition_Function/Contrastive_Divergence/">Contrastive Divergence</a></li><li class="file"><a href="/Deep_Learning/Confronting_Partition_Function/Score_Matching/">Score Matching</a></li><li class="file"><a href="/Deep_Learning/Confronting_Partition_Function/Softmax_Speedup/">Softmax Speedup</a></li></ul></li><li class="directory"><a href="#" data-role="directory"><i class="fa fa-folder"></i> &nbsp; Energy Based Models</a><ul class="unstyled" id="tree"><li class="file"><a href="/Deep_Learning/Energy_Based_Models/Overview/">Overview</a></li><li class="file"><a href="/Deep_Learning/Energy_Based_Models/Energy_Function_in_Probabilistic_Models/">Energy Function in Probabilistic Models</a></li><li class="file"><a href="/Deep_Learning/Energy_Based_Models/Restricted_Boltzmann_Machine/">Restricted Boltzmann Machine</a></li></ul></li><li class="directory"><a href="#" data-role="directory"><i class="fa fa-folder"></i> &nbsp; Evaluation</a><ul class="unstyled" id="tree"><li class="file"><a href="/Deep_Learning/Evaluation/Evaluation_Metrics/">Evaluation Metrics</a></li><li class="file"><a href="/Deep_Learning/Evaluation/Visualizing_High_Dimensional_Space/">Visualizing High Dimensional Space</a></li></ul></li><li class="directory"><a href="#" data-role="directory"><i class="fa fa-folder"></i> &nbsp; Generative Adversarial Nets</a><ul class="unstyled" id="tree"><li class="file"><a href="/Deep_Learning/Generative_Adversarial_Nets/Overview/">Overview</a></li><li class="file"><a href="/Deep_Learning/Generative_Adversarial_Nets/f-GAN/">f-GAN</a></li><li class="file"><a href="/Deep_Learning/Generative_Adversarial_Nets/Energy_GAN/">Energy GAN</a></li></ul></li><li class="directory"><a href="#" data-role="directory"><i class="fa fa-folder"></i> &nbsp; Graph Neural Networks</a><ul class="unstyled" id="tree"><li class="file"><a href="/Deep_Learning/Graph_Neural_Networks/Node_Embedding/">Node Embedding</a></li><li class="file"><a href="/Deep_Learning/Graph_Neural_Networks/Graph_Convolution_Network/">Graph Convolution Network</a></li><li class="file"><a href="/Deep_Learning/Graph_Neural_Networks/Graph_Auto_Encoder/">Graph Auto-Encoder</a></li></ul></li><li class="directory"><a href="#" data-role="directory"><i class="fa fa-folder"></i> &nbsp; Information Theoretical</a><ul class="unstyled" id="tree"><li class="file"><a href="/Deep_Learning/Information_Theoretical/KL-Divergence/">KL-Divergence</a></li><li class="file"><a href="/Deep_Learning/Information_Theoretical/Mutual_Information/">Mutual Information</a></li></ul></li><li class="directory"><a href="#" data-role="directory"><i class="fa fa-folder"></i> &nbsp; Monte Carlo Methods</a><ul class="unstyled" id="tree"><li class="file"><a href="/Deep_Learning/Monte_Carlo_Methods/Overview/">Overview</a></li><li class="file"><a href="/Deep_Learning/Monte_Carlo_Methods/Monte_Carlo_Integration/">Monte Carlo Integration</a></li><li class="file"><a href="/Deep_Learning/Monte_Carlo_Methods/Accept_Reject_Sampling/">Accept-Reject Sampling</a></li><li class="file"><a href="/Deep_Learning/Monte_Carlo_Methods/Markov_Chain/">Markov Chain</a></li><li class="file"><a href="/Deep_Learning/Monte_Carlo_Methods/Metropolis_Hastings_Algorithm/">Metropolis-Hastings Algorithm</a></li><li class="file"><a href="/Deep_Learning/Monte_Carlo_Methods/Gibbs_Sampler/">Gibbs Sampler</a></li><li class="file"><a href="/Deep_Learning/Monte_Carlo_Methods/Hamiltonian_Dynamics/">Hamiltonian Dynamics</a></li><li class="file"><a href="/Deep_Learning/Monte_Carlo_Methods/Langevin_Dynamics/">Langevin Dynamics</a></li></ul></li><li class="directory"><a href="#" data-role="directory"><i class="fa fa-folder"></i> &nbsp; Optimization</a><ul class="unstyled" id="tree"><li class="file"><a href="/Deep_Learning/Optimization/Gradient_Tricks/">Gradient Tricks</a></li><li class="file"><a href="/Deep_Learning/Optimization/Loss_Surface_and_Generalization/">Loss Surface and Generalization</a></li><li class="file"><a href="/Deep_Learning/Optimization/Stochastic_Gradient_Descent/">Stochastic Gradient descent</a></li></ul></li><li class="directory"><a href="#" data-role="directory"><i class="fa fa-folder"></i> &nbsp; Variational Autoencoder</a><ul class="unstyled" id="tree"><li class="file"><a href="/Deep_Learning/Variational_Autoencoder/Overview/">Overview</a></li><li class="file"><a href="/Deep_Learning/Variational_Autoencoder/Sequential_VAE/">Sequential VAE</a></li><li class="file"><a href="/Deep_Learning/Variational_Autoencoder/Gradient_Estimators_for_Variational_Inference/">Gradient Estimators for Variational Inference</a></li><li class="file"><a href="/Deep_Learning/Variational_Autoencoder/Theoretical_Facts/">Theoretical Facts about VAEs</a></li></ul></li></ul></li><li class="directory"><a href="#" data-role="directory"><i class="fa fa-folder"></i> &nbsp; Mathematics</a><ul class="unstyled" id="tree"><li class="directory"><a href="#" data-role="directory"><i class="fa fa-folder"></i> &nbsp; Analysis</a><ul class="unstyled" id="tree"><li class="file"><a href="/Mathematics/Analysis/Linear_Space_vs_Functional_Space/">Linear space vs functional space</a></li></ul></li><li class="directory"><a href="#" data-role="directory"><i class="fa fa-folder"></i> &nbsp; Calculus</a><ul class="unstyled" id="tree"><li class="file"><a href="/Mathematics/Calculus/Calculus_of_Variations/">Calculus of Variations</a></li></ul></li><li class="directory"><a href="#" data-role="directory"><i class="fa fa-folder"></i> &nbsp; Differential Equations</a><ul class="unstyled" id="tree"><li class="file"><a href="/Mathematics/Differential_Equations/Probability_Distribution_Equations/">Differential Equations on Probability Distributions</a></li></ul></li><li class="directory"><a href="#" data-role="directory"><i class="fa fa-folder"></i> &nbsp; Optimization</a><ul class="unstyled" id="tree"><li class="file"><a href="/Mathematics/Optimization/Convex_Optimization/">Convex Optimization</a></li></ul></li></ul></li><li class="directory"><a href="#" data-role="directory"><i class="fa fa-folder"></i> &nbsp; Research Work</a><ul class="unstyled" id="tree"><li class="file"><a href="/Research_Work/Reading_List/">Reading List</a></li><li class="file"><a href="/Research_Work/Tracking_the_Concepts/">Tracking the Concepts</a></li><li class="file"><a href="/Research_Work/Directions_to_Explore/">Directions to Explore</a></li></ul></li></ul></div><script>$(document).ready(function(){var r="fa-folder-open",i="fa-folder",l="fa-angle-double-down",d="fa-angle-double-up";$(document).on("click",'#categories a[data-role="directory"]',function(a){a.preventDefault();var e=$(this).children(".fa"),s=e.hasClass(r),l=$(this).siblings("ul");e.removeClass(r).removeClass(i),s?(void 0!==l&&l.slideUp({duration:100}),e.addClass(i)):(void 0!==l&&l.slideDown({duration:100}),e.addClass(r))}),$('#categories a[data-role="directory"]').bind("contextmenu",function(a){a.preventDefault();var e=$(this).children(".fa"),s=e.hasClass(r),l=$(this).siblings("ul"),d=$.merge(l.find("li ul"),l),o=$.merge(l.find(".fa"),e);o.removeClass(r).removeClass(i),s?(d.slideUp({duration:100}),o.addClass(i)):(d.slideDown({duration:100}),o.addClass(r))}),$(document).on("click","#allExpand",function(a){a.preventDefault();var e=$(this).children(".fa"),s=e.hasClass(l);e.removeClass(l).removeClass(d),s?($("#sidebar .fa.fa-folder").removeClass("fa-folder").addClass("fa-folder-open"),$("#categories li ul").slideDown({duration:100}),e.addClass(d)):($("#sidebar .fa.fa-folder-open").removeClass("fa-folder-open").addClass("fa-folder"),$("#categories li ul").slideUp({duration:100}),e.addClass(l))})})</script><div id="toTop" class="fa fa-angle-up"></div></aside><section id="main"><article id="post-Deep_Learning/Monte_Carlo_Methods/Markov_Chain" class="article article-type-post" itemscope itemprop="blogPost"><div class="article-inner"><header class="article-header"><div class="article-meta"><div class="article-category"><i class="fa fa-folder"></i> <a class="article-category-link" href="/categories/Deep-Learning/">Deep Learning</a><i class="fa fa-angle-right"></i><a class="article-category-link" href="/categories/Deep-Learning/Monte-Carlo-Methods/">Monte Carlo Methods</a></div><div class="article-date"><i class="fa fa-calendar"></i> <a href="/Deep_Learning/Monte_Carlo_Methods/Markov_Chain/"><time datetime="2019-10-18T09:11:00.000Z" itemprop="datePublished">2019-10-18</time></a></div><div class="article-meta-button"><a href="https://github.com/haowen-xu/research-notes/raw/master/source/_posts/Deep_Learning/Monte_Carlo_Methods/Markov_Chain.md">Source</a></div><div class="article-meta-button"><a href="https://github.com/haowen-xu/research-notes/edit/master/source/_posts/Deep_Learning/Monte_Carlo_Methods/Markov_Chain.md">Edit</a></div><div class="article-meta-button"><a href="https://github.com/haowen-xu/research-notes/commits/master/source/_posts/Deep_Learning/Monte_Carlo_Methods/Markov_Chain.md">History</a></div></div><h1 itemprop="name"><a class="article-title" href="/Deep_Learning/Monte_Carlo_Methods/Markov_Chain/">Markov Chain</a></h1></header><div class="article-entry" itemprop="articleBody"><h2 id="elements-of-markov-chain">Elements of Markov Chain</h2><ul><li>A measurable state space <span class="math inline">\(\mathcal{X}\)</span>.</li><li>A transition kernel <span class="math inline">\(T: \mathcal{X} \mapsto \mathcal{X}\)</span>.</li></ul><p>For discrete state space <span class="math inline">\(\mathcal{X}\)</span>, the transition kernel can also be written as a transition matrix, where <span class="math inline">\(P_{ij}\)</span> is the probability of state <span class="math inline">\(i\)</span> transit to state <span class="math inline">\(j\)</span>.</p><p>Given an initial state distribution <span class="math inline">\(\pi_0(x)\)</span>, the distribution after <span class="math inline">\(k\)</span>-cycle MCMC transition is <span class="math inline">\(\pi_k(x)\)</span>, defined as: <span class="math display">\[ \pi_k(x) = (T \pi_{k-1})(x) = \int_{\mathcal{X}} \pi_{k-1}(y) \,T(y, x)\,dy \]</span> We shall use <span class="math inline">\(T^k\)</span> to denote such a <span class="math inline">\(k\)</span>-cycle transition, such that: <span class="math display">\[ \pi_k(x) = (T^k \pi_0)(x) = \int_{\mathcal{X}} \pi_0(y) \,T^k(y, x)\,dy \]</span></p><ul><li>Stationary distribution: if there exists <span class="math inline">\(\pi(x)\)</span> such that <span class="math inline">\(\pi = T\pi\)</span>, then <span class="math inline">\(\pi\)</span> is a <em>stationary distribution</em> of the Markov chain derived by <span class="math inline">\(T\)</span>, denoted as <span class="math inline">\(\pi^{\star}(x)\)</span>.</li></ul><h2 id="ergodicity-of-markov-chain">Ergodicity of Markov Chain</h2><p><strong>TODO</strong>: Write about ergodicity, instead of separated "irreducible" and "aperiodic".</p><blockquote><p>A state <em>i</em> is said to be <em>ergodic</em> if it is aperiodic and positive recurrent.</p><p>-- https://en.wikipedia.org/wiki/Markov_chain#Ergodicity</p></blockquote><h2 id="existence-and-uniqueness-of-the-stationary-distribution">Existence and Uniqueness of the Stationary Distribution</h2><p>The necessary condition for a unique stationary distribution <span class="math inline">\(\pi^{\star}(x)\)</span> of a Markov chain to exist is that the chain is <em>irreducible</em> and <em>aperiodic</em>.</p><ul><li>Irreducible:<ul><li>A Markov chain is irreducible if <span class="math inline">\(\forall x,\,y\)</span>, there exists <span class="math inline">\(k \in \mathbb{N}\)</span>, such that <span class="math inline">\(T^k(x,y) &gt; 0\)</span>.</li></ul></li><li>Aperiodic:<ul><li>The period of a state <span class="math inline">\(x\)</span> is defined as: <span class="math inline">\(\mathrm{gcd}\left\{k &gt; 0 : T^k(x,x) &gt; 0\right\}\)</span>.</li><li>A state <span class="math inline">\(x\)</span> is aperiodic if the period of <span class="math inline">\(x\)</span> is 1.</li><li>A Markov chain is aperiodic if every state of this chain is aperiodic.</li><li>If there is an aperiodic state in an irreducible Markov chain, then all states of this Markov chain is aperiodic.</li></ul></li></ul><h2 id="detailed-balance-condition">Detailed Balance Condition</h2><p>In practice, the transition kernel is often chosen to satisfy the <em>detailed balance condition</em>. If there exists a state distribution <span class="math inline">\(\pi(x)\)</span>, such that <span class="math inline">\(\forall x, \, y\)</span>, <span class="math display">\[ \pi(x) \, T(x,y) = \pi(y) \, T(y, x) \]</span></p><p>We say that <span class="math inline">\(T\)</span> satisfies the detailed balance condition. Furthermore, in such situation, <span class="math inline">\(\pi\)</span> is the stationary distribution of the Markov chain, and the chain is reversible.</p><p>If the Markov chain is further irreducible and aperiodic, then <span class="math inline">\(\pi\)</span> is the unique stationary distribution.</p><h2 id="hybird-markov-chain">Hybird Markov Chain</h2><p>If <span class="math inline">\(T_1\)</span> and <span class="math inline">\(T_2\)</span> are two kernels with the same stationary distribution <span class="math inline">\(\pi^{\star}\)</span>, and if <span class="math inline">\(T_1\)</span> produces an irreducible Markov chain, then the mixture kernel: <span class="math display">\[ T = \alpha T_1 + (1-\alpha) T_2 \qquad\qquad (0 &lt; \alpha &lt; 1) \]</span> is also irreducible.</p></div><div style="height:10px"></div></div></article><article id="post-Deep_Learning/Monte_Carlo_Methods/Accept_Reject_Sampling" class="article article-type-post" itemscope itemprop="blogPost"><div class="article-inner"><header class="article-header"><div class="article-meta"><div class="article-category"><i class="fa fa-folder"></i> <a class="article-category-link" href="/categories/Deep-Learning/">Deep Learning</a><i class="fa fa-angle-right"></i><a class="article-category-link" href="/categories/Deep-Learning/Monte-Carlo-Methods/">Monte Carlo Methods</a></div><div class="article-date"><i class="fa fa-calendar"></i> <a href="/Deep_Learning/Monte_Carlo_Methods/Accept_Reject_Sampling/"><time datetime="2019-10-18T06:15:01.000Z" itemprop="datePublished">2019-10-18</time></a></div><div class="article-meta-button"><a href="https://github.com/haowen-xu/research-notes/raw/master/source/_posts/Deep_Learning/Monte_Carlo_Methods/Accept_Reject_Sampling.md">Source</a></div><div class="article-meta-button"><a href="https://github.com/haowen-xu/research-notes/edit/master/source/_posts/Deep_Learning/Monte_Carlo_Methods/Accept_Reject_Sampling.md">Edit</a></div><div class="article-meta-button"><a href="https://github.com/haowen-xu/research-notes/commits/master/source/_posts/Deep_Learning/Monte_Carlo_Methods/Accept_Reject_Sampling.md">History</a></div></div><h1 itemprop="name"><a class="article-title" href="/Deep_Learning/Monte_Carlo_Methods/Accept_Reject_Sampling/">Accept-Reject Sampling</a></h1></header><div class="article-entry" itemprop="articleBody"><h2 id="problem-statement">Problem Statement</h2><p>To sample from <span class="math inline">\(p(x)\)</span>, where <span class="math inline">\(p(x)\)</span> is not easy to sample from, but given a sample <span class="math inline">\(x\)</span>, the density of <span class="math inline">\(p(x)\)</span> is easy to evaluate.</p><h2 id="accept-reject-sampling">Accept-Reject Sampling</h2><p>Given that <span class="math inline">\(p(x) \leq M q(x)\)</span> for <span class="math inline">\(0 &lt; M &lt; \infty\)</span>, we can sample <span class="math inline">\(x \sim p(x)\)</span> by:</p><ol type="1"><li>Sample <span class="math inline">\(X \sim q(x)\)</span>, <span class="math inline">\(U \sim \mathcal{U}[0,1]\)</span>.</li><li>Accept <span class="math inline">\(Y=X\)</span> if <span class="math inline">\(U &lt; p(X) / M q(X)\)</span>.</li><li>Return to 1 otherwise.</li></ol><p>The correctness of this method can be proven by:</p><p><span class="math display">\[ \begin{aligned} P(Y\leq y) &amp;= P\left(X \leq y \,\Big|\, U \leq \frac{p(X)}{M q(X)}\right) = \frac{P\left(X \leq y, U \leq \frac{p(X)}{M q(X)}\right)}{P\left(U \leq \frac{p(X)}{M q(X)}\right)} \\ &amp;= \frac{\int_{-\infty}^y \int_0^{p(x)/M q(x)} \mathrm{d}{u}\,q(x)\,\mathrm{d}{x}} {\int_{-\infty}^{\infty} \int_0^{p(x)/M q(x)} \mathrm{d}{u}\,q(x)\,\mathrm{d}{x}} = \frac{\frac{1}{M}\,\int_{-\infty}^y p(x)\,\mathrm{d}{x}} {\frac{1}{M}\,\int_{-\infty}^{\infty} p(x)\,\mathrm{d}{x}} = \int_{-\infty}^y p(x)\,\mathrm{d}{x} \end{aligned} \]</span></p><p>The average acceptance rate <span class="math inline">\(\propto 1/M\)</span>, so a smaller <span class="math inline">\(M\)</span> can lead to lower time consumption. On the other hand, the target distribution <span class="math inline">\(p(x)\)</span> need not be normalized; <span class="math inline">\(M\)</span> can be often estimated again by sampling from <span class="math inline">\(q(x)\)</span> in applications, by <span class="math inline">\(M = \max p(x) / q(x)\)</span>.</p></div><div style="height:10px"></div></div></article><article id="post-Deep_Learning/Monte_Carlo_Methods/Monte_Carlo_Integration" class="article article-type-post" itemscope itemprop="blogPost"><div class="article-inner"><header class="article-header"><div class="article-meta"><div class="article-category"><i class="fa fa-folder"></i> <a class="article-category-link" href="/categories/Deep-Learning/">Deep Learning</a><i class="fa fa-angle-right"></i><a class="article-category-link" href="/categories/Deep-Learning/Monte-Carlo-Methods/">Monte Carlo Methods</a></div><div class="article-date"><i class="fa fa-calendar"></i> <a href="/Deep_Learning/Monte_Carlo_Methods/Monte_Carlo_Integration/"><time datetime="2019-10-18T06:15:00.000Z" itemprop="datePublished">2019-10-18</time></a></div><div class="article-meta-button"><a href="https://github.com/haowen-xu/research-notes/raw/master/source/_posts/Deep_Learning/Monte_Carlo_Methods/Monte_Carlo_Integration.md">Source</a></div><div class="article-meta-button"><a href="https://github.com/haowen-xu/research-notes/edit/master/source/_posts/Deep_Learning/Monte_Carlo_Methods/Monte_Carlo_Integration.md">Edit</a></div><div class="article-meta-button"><a href="https://github.com/haowen-xu/research-notes/commits/master/source/_posts/Deep_Learning/Monte_Carlo_Methods/Monte_Carlo_Integration.md">History</a></div></div><h1 itemprop="name"><a class="article-title" href="/Deep_Learning/Monte_Carlo_Methods/Monte_Carlo_Integration/">Monte Carlo Integration</a></h1></header><div class="article-entry" itemprop="articleBody"><h2 id="problem-statement">Problem Statement</h2><p>To estimate <span class="math inline">\(\mathbb{E}_{p(x)}\left[ f(x) \right]\)</span>.</p><h2 id="naive-estimator">Naive Estimator</h2><p>When <span class="math inline">\(p(x)\)</span> are easy to sample from, it is straightforward to estimate <span class="math inline">\(\mathbb{E}_{p(x)}\left[ f(x) \right]\)</span> by: <span class="math display">\[ \mathbb{E}_{p(x)}\left[ f(x) \right] \approx \frac{1}{K} \sum_{i=1}^K f(x^{(i)}) \]</span> where <span class="math inline">\(x^{(i)}, \, i = 1 \dots K\)</span> are <em>i.i.d.</em> samples from <span class="math inline">\(p(x)\)</span>.</p><h2 id="sec:importance_sampling">Importance Sampling</h2><p>When <span class="math inline">\(p(x)\)</span> is not easy to sample from, or when the above estimator has too large variance, one may use the importance sampling estimator: <span class="math display">\[ \begin{align} \mathbb{E}_{p(x)}\left[ f(x) \right] = \mathbb{E}_{q(x)}\left[ \frac{f(x)\,p(x)}{q(x)} \right] \approx \frac{1}{K} \sum_{i=1}^K \frac{f(x^{(i)})\,p(x^{(i)})}{q(x^{(i)})} \end{align} \]</span> where <span class="math inline">\(x^{(i)}, \, i = 1 \dots K\)</span> are <em>i.i.d.</em> samples from <span class="math inline">\(q(x)\)</span>, the <em>proposal distribution</em>. The theoretical optimal proposal distribution <span class="math inline">\(q^{\star}(x)\)</span>, which gives the smallest variance to the estimator, is given by: <span class="math display">\[ q^{\star}(x) = \frac{\left| f(x) \right|\,p(x)}{\int \left| f(\xi) \right|\,p(\xi)\,d\xi} \]</span></p><p>Note the following condition must hold: <span class="math display">\[ q(x) \neq 0, \;\, \forall x \;\, \text{satisfying} \;\, p(x) \neq 0 \]</span></p></div><div style="height:10px"></div></div></article><nav id="page-nav"><a class="extend prev" rel="prev" href="/page/9/">&laquo; Prev</a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/8/">8</a><a class="page-number" href="/page/9/">9</a><span class="page-number current">10</span><a class="page-number" href="/page/11/">11</a><a class="page-number" href="/page/12/">12</a><span class="space">&hellip;</span><a class="page-number" href="/page/14/">14</a><a class="extend next" rel="next" href="/page/11/">Next &raquo;</a></nav></section></div><footer id="footer"><div class="outer"><div id="footer-info" class="inner">Haowen Xu &copy; 2020 <a rel="license" href="http://creativecommons.org/licenses/by-nc-nd/4.0/"><img alt="Creative Commons License" style="border-width:0" src="/images/by-nc-nd-4.0-80x15.png"></a><br>Powered by <a href="http://hexo.io/" target="_blank">Hexo</a> &amp; theme <a href="https://github.com/zthxxx/hexo-theme-Wikitten">Wikitten</a></div></div></footer><script src="/libs/lightgallery/js/lightgallery.min.js"></script><script src="/libs/lightgallery/js/lg-thumbnail.min.js"></script><script src="/libs/lightgallery/js/lg-pager.min.js"></script><script src="/libs/lightgallery/js/lg-autoplay.min.js"></script><script src="/libs/lightgallery/js/lg-fullscreen.min.js"></script><script src="/libs/lightgallery/js/lg-zoom.min.js"></script><script src="/libs/lightgallery/js/lg-hash.min.js"></script><script src="/libs/lightgallery/js/lg-share.min.js"></script><script src="/libs/lightgallery/js/lg-video.min.js"></script><script src="/libs/justified-gallery/jquery.justifiedGallery.min.js"></script><script type="text/x-mathjax-config">MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ["$","$"], ["\\(","\\)"] ],
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
            processEscapes: true,
            TeX: {
                equationNumbers: {
                    autoNumber: 'AMS'
                },
                style: {
                    'font-family': 'serif'
                }
            }
        },
        'HTML-CSS': {
            //preferredFont: 'TeX',
            fonts: ['TeX']
        }
    });
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax();
        for (var i = 0; i < all.length; ++i)
            all[i].SourceElement().parentNode.className += ' has-jax';
    });</script><script async src="//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><script src="/js/main.js"></script></div></body>